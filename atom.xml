<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Aoki&#39;s Blog</title>
  
  <subtitle>“吾生也有涯，而知无涯”</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wanqbin.xyz/"/>
  <updated>2019-11-19T16:26:14.105Z</updated>
  <id>http://wanqbin.xyz/</id>
  
  <author>
    <name>Aoki</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Docker和容器</title>
    <link href="http://wanqbin.xyz/2019/11/20/Docker%E5%92%8C%E5%AE%B9%E5%99%A8/"/>
    <id>http://wanqbin.xyz/2019/11/20/Docker和容器/</id>
    <published>2019-11-19T16:25:00.000Z</published>
    <updated>2019-11-19T16:26:14.105Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Docker是什么？"><a href="#一、Docker是什么？" class="headerlink" title="一、Docker是什么？"></a>一、Docker是什么？</h2><p>Docker是容器的一种，容器是一种轻量级的虚拟技术，和容器对应的更为重量级的虚拟技术是虚拟机。虚拟机是一种基于硬件的虚拟技术，它采用指令级的模拟，完全模拟一整套物理主机。容器是一种基于操作系统的虚拟技术，它运行在操作系统之上的用户空间，所有的容器都共用一个系统内核，甚至是公共库，容器引擎提供进程级别的隔离，让每个容器都像运行在单独的系统之上，但又能共享很多底层资源。</p><h2 id="二、Docker的组件"><a href="#二、Docker的组件" class="headerlink" title="二、Docker的组件"></a>二、Docker的组件</h2><p>Docker采用C/S架构。Docker客户端，即Docker可执行程序，可以通过命令行和API的形式与Docker守候程序进行通信，Docker守候程序提供Docker服务。</p><p>Docker包含三大核心组件——镜像，容器和库。</p><ul><li>镜像：是一个只读的静态模板。它保存着容器需要的环境和应用的执行代码，可以把镜像看成是容器的代码，当代码运行起来后就成了容器。镜像采用分层机制，每个镜像都是只读的，但是可以将写数据的层通过联合文件系统附加在原有的镜像之上。这种增量式修改使得镜像非常容器存储、传输和更新。</li><li>容器：是一个运行时环境，它是一个镜像的运行状态，想到对于静态的镜像而言，容器是镜像执行的动态表现。</li><li>库：Docker采用注册服务器来存储和共享用户的镜像，库是某个特定用户存储镜像的目录。通常，一个用户可以建立多个库来保存自己的镜像。如Docker官方的Docker Hub。</li></ul><h2 id="三、容器的管理操作"><a href="#三、容器的管理操作" class="headerlink" title="三、容器的管理操作"></a>三、容器的管理操作</h2><ol><li><h3 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h3><ul><li><p>docker create</p><p> 创建的容器处于停止状态</p></li><li><p>docker run</p><p>不仅创建的容器，而且启动了容器</p></li></ul><p>容器创建后，会返回容器的ID。</p><p>要想让创建的容器立马进入运行态，可以使用<code>docker run</code>命令，该命令相当于下面的两条命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker create</span><br><span class="line">docker start</span><br></pre></td></tr></table></figure><p>使用<code>docker run</code>命令可以创建两种类型的容器——后台型容器和交互型容器。</p><ul><li>交互型容器：运行在前台，通常会指定有交互的控制台，可以给容器输入，也可以得到容器的输出。创建该容器的终端被关闭，在容器内部使用<code>exit</code>命令或者调用了<code>docker stop</code>、<code>docker kill</code>命令后，容器会变成停止状态。</li><li>后台型容器：运行在后台，创建启动之后就与终端无关。即便终端关闭了，该后台容器也依然存在，只有调用<code>docker stop</code>或<code>docker kill</code>命令时才能够使容器变成停止状态。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -i -t --name=inspect_shell ubuntu /bin/bash</span><br></pre></td></tr></table></figure><p>其中，<code>-i</code>用于打开容器的标准输入(STDIN),<code>-t</code>告诉Docker为容器建立一个命令行终端。</p><p><code>--name</code>为容器指定一个名字，是一个可选项。如果没有这个选项，Docker会为容器创建一个随机名字</p><p><code>ubuntu</code>是镜像名，<code>/bin/bash</code>代表告诉Docker要在容器里面执行命令<code>/bin/bash</code>。</p><p>执行该命令之后，如果本地没有该镜像，Docker会从远程仓库中获取。然后，Docker使用这个镜像创建一个新的容器并将其启动；容器的文件系统是在只读的镜像文件上增加一层可读写的文件层，这样可以保证镜像不变而只记录改变的数据，这对容器的共享和传输都非常有利。接着会配置容器的网络，Docker会为容器分配一个虚拟网络接口，并通过网桥的方式将该网络接口桥接到宿主主机上，然后该虚拟网络接口分配一个IP地址。最后，Docker在新容器中运行指定的命令。</p></li><li><h3 id="查看容器"><a href="#查看容器" class="headerlink" title="查看容器"></a>查看容器</h3><p>查看正在运行的容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure><p>CONTAINER ID：唯一标识容器的ID</p><p>IMAGE：创建容器时使用的镜像</p><p>COMMAND：容器最后运行的命令</p><p>CREATED：创建容器的时间</p><p>STATUS：容器的状态</p><p>PORT：对外开放的接口</p><p>NAMES：容器名。和容器ID一样都可以唯一标识一个容器。</p><p>查看所有的容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps -a</span><br></pre></td></tr></table></figure><p>列出所有容器，包括运行的和停止的容器。</p></li><li><h3 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h3><p>通过<code>docker create</code>命令创建的容器会进入到停止状态，想要运行该容器，可以执行以下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker start 容器名/容器ID</span><br></pre></td></tr></table></figure></li><li><h3 id="终止容器"><a href="#终止容器" class="headerlink" title="终止容器"></a>终止容器</h3><p>执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop 容器名/容器ID</span><br></pre></td></tr></table></figure></li><li><h3 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h3><p>执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm 容器名</span><br></pre></td></tr></table></figure><p>注意：不可以删除一个运行中的容器，必须先用<code>docker stop</code>或<code>docker kill</code>命令停止它才能删除。当然，也可以使用<code>-f</code>选项强制删除。</p><p>删除所有容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm 'docker ps -a -q'</span><br></pre></td></tr></table></figure><p><code>-a</code>标志列出所有容器，<code>-q</code>标志只列出容器的ID，不包括容器的其他信息。然后将这个列表传给<code>docker rm</code>命令，依次删除容器。</p></li></ol><h2 id="四、容器内信息获取与命令执行"><a href="#四、容器内信息获取与命令执行" class="headerlink" title="四、容器内信息获取与命令执行"></a>四、容器内信息获取与命令执行</h2><ol><li><h3 id="依附容器"><a href="#依附容器" class="headerlink" title="依附容器"></a>依附容器</h3><p>依附操作<code>attach</code>通常用于由<code>docker start</code>或者<code>docker restart</code>启动的交互型容器中。由于<code>docker start</code>启动的交互型容器并没有具体终端可以依附，而容器本身是可以接收用户交互的，这时就需要通过<code>attach</code>命令来将终端依附到容器上。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker attach 容器ID</span><br></pre></td></tr></table></figure></li></ol><ol start="2"><li><h3 id="查看容器日志"><a href="#查看容器日志" class="headerlink" title="查看容器日志"></a>查看容器日志</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker logs -f 容器名 </span><br><span class="line">docker logs -f --tails=5 容器名   #控制logs输出的日志行数，只输出最后五行</span><br></pre></td></tr></table></figure></li></ol><ol start="3"><li><h3 id="查看容器进程"><a href="#查看容器进程" class="headerlink" title="查看容器进程"></a>查看容器进程</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker top 容器名</span><br></pre></td></tr></table></figure></li><li><h3 id="查看容器信息"><a href="#查看容器信息" class="headerlink" title="查看容器信息"></a>查看容器信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect 容器名</span><br></pre></td></tr></table></figure><p>用来查看容器的配置环境，包括容器名，环境变量，运行命令，主机配置，网络配置和数据卷配置等。使用<code>-f</code>或者<code>--format</code>命令格式化标志，可以查看指定部分的信息。</p></li><li><h3 id="容器的导入与导出"><a href="#容器的导入与导出" class="headerlink" title="容器的导入与导出"></a>容器的导入与导出</h3><p>Docker的导入和导出分别由<code>import</code>命令和<code>export</code>命令完成。</p><p>使用<code>docker export</code>命令导出容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker export 容器名 &gt; my_container.tar</span><br></pre></td></tr></table></figure><p><code>docker export</code>命令会把容器的文件系统以tar包的格式导出到标准输出。我们将其定位到目标文件<code>name.tar</code>。将容器保存到本地文件也算是持久化方式的一种。将容器保存到本次之后，我们就可以通过网络等方法将tar包分享给他人。</p><p>使用<code>docker import</code>命令导入一个本地的tar包作为镜像：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat my_container.tar | docker import - imported:container</span><br></pre></td></tr></table></figure><p><code>docker import</code>会把打包的容器导入为一个镜像。</p><p><code>import</code>表示从标准输入读取容器内容，我们把<code>name.tar</code>的内容传给标准输入，res和tag代表生成的镜像和标记。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、Docker是什么？&quot;&gt;&lt;a href=&quot;#一、Docker是什么？&quot; class=&quot;headerlink&quot; title=&quot;一、Docker是什么？&quot;&gt;&lt;/a&gt;一、Docker是什么？&lt;/h2&gt;&lt;p&gt;Docker是容器的一种，容器是一种轻量级的虚拟技术，和容器
      
    
    </summary>
    
      <category term="分布式与云计算" scheme="http://wanqbin.xyz/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
      <category term="Docker" scheme="http://wanqbin.xyz/tags/Docker/"/>
    
      <category term="容器" scheme="http://wanqbin.xyz/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes集群部署</title>
    <link href="http://wanqbin.xyz/2019/11/19/Kubernetes%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"/>
    <id>http://wanqbin.xyz/2019/11/19/Kubernetes集群部署/</id>
    <published>2019-11-19T14:05:00.000Z</published>
    <updated>2019-11-19T14:08:22.267Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、环境概述"><a href="#一、环境概述" class="headerlink" title="一、环境概述"></a>一、环境概述</h2><ul><li><h3 id="节点信息"><a href="#节点信息" class="headerlink" title="节点信息"></a>节点信息</h3></li></ul><table><thead><tr><th>IP</th><th>角色</th><th>服务器名</th></tr></thead><tbody><tr><td>192.168.43.60</td><td>Master</td><td>Matser</td></tr><tr><td>192.168.43.61</td><td>Node</td><td>Node1</td></tr><tr><td>192.168.43.62</td><td>Node</td><td>Node2</td></tr><tr><td>192.168.43.63</td><td>Node</td><td>Node3</td></tr></tbody></table><ul><li><h3 id="服务器配置信息"><a href="#服务器配置信息" class="headerlink" title="服务器配置信息"></a>服务器配置信息</h3><p>Master：虚拟机CentOS7</p><p>Node：虚拟机CentOS7</p></li></ul><ul><li><h3 id="节点分布："><a href="#节点分布：" class="headerlink" title="节点分布："></a>节点分布：</h3><p>利用局域网中的四台电脑中的虚拟机实现K8S集群的部署。</p></li></ul><h2 id="二、部署步骤"><a href="#二、部署步骤" class="headerlink" title="二、部署步骤"></a>二、部署步骤</h2><p>需要说明的是，kubernetes集群部署可以采用二进制文件进行安装，也可以采用kubeadm工具快速安装kubernetes，这里我使用了kubeadm工具。</p><ol><li><h3 id="设置服务器名"><a href="#设置服务器名" class="headerlink" title="设置服务器名"></a>设置服务器名</h3><p>分别设置各个服务器名：</p><p>执行命令：<code>vi /etc/hostname</code></p><p>Master：修改<code>localhost</code>为<code>Master</code></p><p>Node1：修改<code>localhost</code>为<code>Node1</code></p><p>Node2：修改<code>localhost</code>为<code>Node2</code></p><p>Node3：修改<code>localhost</code>为<code>Node3</code></p></li><li><h3 id="设置HOST"><a href="#设置HOST" class="headerlink" title="设置HOST"></a>设置HOST</h3><p>在每个节点中执行命令：<code>vi /etc/hosts</code></p><p>插入如下内容：</p></li></ol>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">192.168.43.60 Master</span><br><span class="line">192.168.43.61 Node1</span><br><span class="line">192.168.43.61 Node2</span><br><span class="line">192.168.43.61 Node3</span><br></pre></td></tr></table></figure><ol start="3"><li><h3 id="时间同步"><a href="#时间同步" class="headerlink" title="时间同步"></a>时间同步</h3><p>执行下列命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ntpdate cn.pool.ntp.org</span><br></pre></td></tr></table></figure><p>若提示ntpdate未安装，执行命令：<code>yum install ntpdate</code></p></li><li><h3 id="关闭防火墙-开启特定端口策略"><a href="#关闭防火墙-开启特定端口策略" class="headerlink" title="关闭防火墙/开启特定端口策略"></a>关闭防火墙/开启特定端口策略</h3><p>在各个节点上执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable firewalld</span><br><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure></li></ol><ol start="5"><li><h3 id="禁用SELinux，让容器可以读取主机文件系统"><a href="#禁用SELinux，让容器可以读取主机文件系统" class="headerlink" title="禁用SELinux，让容器可以读取主机文件系统"></a>禁用SELinux，让容器可以读取主机文件系统</h3><p>在各个节点上执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br></pre></td></tr></table></figure></li></ol><ol start="6"><li><h3 id="配置yum源"><a href="#配置yum源" class="headerlink" title="配置yum源"></a>配置yum源</h3><p>在各个服务器上执行命令： <code>*vi /etc/yum.repos.d/kubernetes.repo*</code></p><p>插入如下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes Repository</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br></pre></td></tr></table></figure></li><li><h3 id="安装kubeadm和相关工具"><a href="#安装kubeadm和相关工具" class="headerlink" title="安装kubeadm和相关工具"></a>安装kubeadm和相关工具</h3><p>执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br></pre></td></tr></table></figure></li><li><h3 id="安装docker-ce"><a href="#安装docker-ce" class="headerlink" title="安装docker-ce"></a>安装docker-ce</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install docker-ce</span><br></pre></td></tr></table></figure><p>若报类似于nothing的错误，执行命令：<code>yum update</code></p><p>然后执行<code>yum search docker-ce</code></p><p>之后根据查找结果安装docker-ce</p></li><li><h3 id="启动Docker服务和kubectl服务"><a href="#启动Docker服务和kubectl服务" class="headerlink" title="启动Docker服务和kubectl服务"></a>启动Docker服务和kubectl服务</h3><p>执行下列命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable docker &amp;&amp; systemctl start docker</span><br><span class="line">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure></li><li><h3 id="检测docker服务和kubelet服务"><a href="#检测docker服务和kubelet服务" class="headerlink" title="检测docker服务和kubelet服务"></a>检测docker服务和kubelet服务</h3><p>执行下列命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl status docker</span><br><span class="line">systemctl status kubelet</span><br></pre></td></tr></table></figure><p>执行结果显示绿色字样的<code>running</code>即为正常状态。</p></li><li><h3 id="通过kubeadm获取初始化配置文件"><a href="#通过kubeadm获取初始化配置文件" class="headerlink" title="通过kubeadm获取初始化配置文件"></a>通过kubeadm获取初始化配置文件</h3><p>执行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config print init-defaults &gt; init.default.yaml</span><br><span class="line">cp init.default.yaml init-config.yaml</span><br><span class="line">vi init-config.yaml</span><br></pre></td></tr></table></figure><p>修改内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta2</span></span><br><span class="line"><span class="attr">bootstrapTokens:</span></span><br><span class="line"><span class="attr">- groups:</span></span><br><span class="line"><span class="attr">  - system:</span><span class="attr">bootstrappers:kubeadm:default-node-token</span></span><br><span class="line"><span class="attr">  token:</span> <span class="string">lo7fj7.j16rob4ic6mbgs5q</span></span><br><span class="line"><span class="attr">  ttl:</span> <span class="number">24</span><span class="string">h0m0s</span></span><br><span class="line"><span class="attr">  usages:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">signing</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">authentication</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">InitConfiguration</span></span><br><span class="line"><span class="attr">localAPIEndpoint:</span></span><br><span class="line"><span class="attr">  advertiseAddress:</span> <span class="number">192.168</span><span class="number">.43</span><span class="number">.60</span>   <span class="comment">#master IP</span></span><br><span class="line"><span class="attr">  bindPort:</span> <span class="number">6443</span></span><br><span class="line"><span class="attr">nodeRegistration:</span></span><br><span class="line"><span class="attr">  criSocket:</span> <span class="string">/var/run/dockershim.sock</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">  taints:</span></span><br><span class="line"><span class="attr">  - effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="attr">    key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiServer:</span></span><br><span class="line"><span class="attr">  timeoutForControlPlane:</span> <span class="number">4</span><span class="string">m0s</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta2</span></span><br><span class="line"><span class="attr">certificatesDir:</span> <span class="string">/etc/kubernetes/pki</span></span><br><span class="line"><span class="attr">clusterName:</span> <span class="string">kubernetes</span></span><br><span class="line"><span class="attr">controllerManager:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">dns:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">CoreDNS</span></span><br><span class="line"><span class="attr">etcd:</span></span><br><span class="line"><span class="attr">  local:</span></span><br><span class="line"><span class="attr">    dataDir:</span> <span class="string">/var/lib/etcd</span></span><br><span class="line"><span class="attr">imageRepository:</span> <span class="string">registry.aliyuncs.com/google_containers</span>  <span class="comment">#镜像源，国内</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">v1.16.0</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line"><span class="attr">  dnsDomain:</span> <span class="string">cluster.local</span></span><br><span class="line"><span class="attr">  podSubnet:</span> <span class="string">"192.168.0.0/16"</span></span><br><span class="line"><span class="attr">  serviceSubnet:</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span><span class="string">/12</span></span><br><span class="line"><span class="attr">scheduler:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure></li><li><h3 id="修改docker镜像源"><a href="#修改docker镜像源" class="headerlink" title="修改docker镜像源"></a>修改docker镜像源</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> &quot;registry-mirrors&quot;:[&quot;https://e384u25y.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的镜像源是阿里云加速链接，可以注册阿里云账号，然后在镜像服务中找到专属的加速链接</p></li><li><h3 id="下载镜像文件"><a href="#下载镜像文件" class="headerlink" title="下载镜像文件"></a>下载镜像文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config images pull --config=init-config.yaml</span><br></pre></td></tr></table></figure></li></ol><ol start="14"><li><h3 id="使用kubeadm-init命令安装Master"><a href="#使用kubeadm-init命令安装Master" class="headerlink" title="使用kubeadm init命令安装Master"></a>使用<code>kubeadm init</code>命令安装Master</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config=init-config.yaml</span><br></pre></td></tr></table></figure><p>在安装的过程中可能会出现比较多的问题。</p><ul><li>如果是镜像源的问题，可以重新启动docker服务，加载修改的镜像源，命令如下：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><ul><li><p>如果是提示<code>hostname &quot;master&quot; could not be reached</code>之类的问题，可以修改<code>/etc/hosts</code>文件，见第2步。</p><p>若提示如下问题：</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">running with swap on is not supported. Please disable swap</span><br></pre></td></tr></table></figure><p>执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*swapoff -a*</span><br></pre></td></tr></table></figure><ul><li><p>若提示如下问题：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables contents are not set to 1</span><br></pre></td></tr></table></figure><p>执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure></li></ul><p>安装成功后会出现如下提示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br></pre></td></tr></table></figure><p>在最下面的提示信息中也会出现token，这用于节点加入集群，不过这个token只有24小时的有效期。我们也可以使用其他命令生成永久的token。</p></li><li><h3 id="准备配置文件，以便系统重启时，自动启动集群"><a href="#准备配置文件，以便系统重启时，自动启动集群" class="headerlink" title="准备配置文件，以便系统重启时，自动启动集群"></a>准备配置文件，以便系统重启时，自动启动集群</h3><p>执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure></li></ol><ol start="16"><li><h3 id="验证安装是否成功"><a href="#验证安装是否成功" class="headerlink" title="验证安装是否成功"></a>验证安装是否成功</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@Master ~]# kubectl get -n kube-system configmap</span><br><span class="line">NAME                                 DATA   AGE</span><br><span class="line">coredns                              1      10d</span><br><span class="line">extension-apiserver-authentication   6      10d</span><br><span class="line">kube-proxy                           2      10d</span><br><span class="line">kubeadm-config                       2      10d</span><br><span class="line">kubelet-config-1.16                  1      10d</span><br></pre></td></tr></table></figure><p>至此，master节点安装完毕。下面安装node节点。</p></li><li><h3 id="安装节点"><a href="#安装节点" class="headerlink" title="安装节点"></a>安装节点</h3><p>在各个节点上重复步骤1~10。</p></li><li><h3 id="通过kubeadm获取join配置文件"><a href="#通过kubeadm获取join配置文件" class="headerlink" title="通过kubeadm获取join配置文件"></a>通过kubeadm获取join配置文件</h3><p>执行命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config print join-defaults &gt; join-config.yaml</span><br><span class="line">vim join-config.yaml</span><br></pre></td></tr></table></figure><p>然后修改内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta2</span></span><br><span class="line"><span class="attr">caCertPath:</span> <span class="string">/etc/kubernetes/pki/ca.crt</span></span><br><span class="line"><span class="attr">discovery:</span></span><br><span class="line"><span class="attr">  bootstrapToken:</span></span><br><span class="line"><span class="attr">    apiServerEndpoint:</span> <span class="number">192.168</span><span class="number">.43</span><span class="number">.60</span><span class="string">:6443</span>  <span class="comment">#这地方是master节点的IP</span></span><br><span class="line"><span class="attr">    token:</span> <span class="string">lo7fj7.j16rob4ic6mbgs5q</span>   <span class="comment">#这地方是token，一般是初始化的toke，和master节点中的init文件中的token相同</span></span><br><span class="line"><span class="attr">    unsafeSkipCAVerification:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  timeout:</span> <span class="number">5</span><span class="string">m0s</span></span><br><span class="line"><span class="attr">  tlsBootstrapToken:</span> <span class="string">lo7fj7.j16rob4ic6mbgs5q</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">JoinConfiguration</span></span><br><span class="line"><span class="attr">nodeRegistration:</span></span><br><span class="line"><span class="attr">  criSocket:</span> <span class="string">/var/run/dockershim.sock</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">node1</span>   <span class="comment">#节点名，每个节点的名字必须不同</span></span><br><span class="line"><span class="attr">  taints:</span> <span class="literal">null</span></span><br></pre></td></tr></table></figure></li><li><h3 id="运行kubeadm-join命令加入集群"><a href="#运行kubeadm-join命令加入集群" class="headerlink" title="运行kubeadm join命令加入集群"></a>运行<code>kubeadm join</code>命令加入集群</h3><p>执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join --config=join-config.yaml</span><br></pre></td></tr></table></figure></li></ol><ol start="20"><li><h3 id="查看已加入节点"><a href="#查看已加入节点" class="headerlink" title="查看已加入节点"></a>查看已加入节点</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@Master ~]# kubectl get node</span><br><span class="line">NAME     STATUS     ROLES    AGE     VERSION</span><br><span class="line">master   NotReady   master   10d     v1.16.2   </span><br><span class="line">node1    NotReady   &lt;none&gt;   7d12h   v1.16.2</span><br><span class="line">node2    NotReady   &lt;none&gt;   7d12h   v1.16.2</span><br><span class="line">node3    NotReady   &lt;none&gt;   7d12h   v1.16.2</span><br></pre></td></tr></table></figure><p>在节点加入成功后，执行命令的结果如上。这里notready是因为没有安装网络插件。网络插件比较多，比如weave，Flannel等。这里安装weave。</p></li><li><h3 id="安装网络插件"><a href="#安装网络插件" class="headerlink" title="安装网络插件"></a>安装网络插件</h3><p>执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"</span><br></pre></td></tr></table></figure><p>这里可能会因为科学上网的问题而出现ErrImage或者ImagePullback等问题。我的也出现了这个问题，后来不知道什么原因，突然就安装上了。</p></li><li><h3 id="验证Kubernetes集群是否安装完成"><a href="#验证Kubernetes集群是否安装完成" class="headerlink" title="验证Kubernetes集群是否安装完成"></a>验证Kubernetes集群是否安装完成</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kube-system            coredns-58cc8c89f4-8rxzx                     1/1     Running            13         7d12h</span><br><span class="line">kube-system            coredns-58cc8c89f4-cdwm7                     1/1     Running            15         7d12h</span><br><span class="line">kube-system            etcd-master                                  1/1     Running            26         10d</span><br><span class="line">kube-system            kube-apiserver-master                        1/1     Running            265        10d</span><br><span class="line">kube-system            kube-controller-manager-master               1/1     Running            108        10d</span><br><span class="line">kube-system            kube-proxy-bhdzd                             1/1     Running            9          7d1h</span><br><span class="line">kube-system            kube-proxy-dj4qt                             1/1     Running            14         7d1h</span><br><span class="line">kube-system            kube-scheduler-master                        1/1     Running            96         10d</span><br><span class="line">kube-system            weave-net-6nd4h                              2/2     Running            44         7d12h</span><br><span class="line">kube-system            weave-net-9tzjk                              2/2     Running            41         7d19h</span><br></pre></td></tr></table></figure><p>这里，Kubernetes集群就可以搭建完毕了。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、环境概述&quot;&gt;&lt;a href=&quot;#一、环境概述&quot; class=&quot;headerlink&quot; title=&quot;一、环境概述&quot;&gt;&lt;/a&gt;一、环境概述&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;h3 id=&quot;节点信息&quot;&gt;&lt;a href=&quot;#节点信息&quot; class=&quot;headerlink&quot;
      
    
    </summary>
    
      <category term="分布式与云计算" scheme="http://wanqbin.xyz/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
      <category term="k8s" scheme="http://wanqbin.xyz/tags/k8s/"/>
    
      <category term="分布式集群" scheme="http://wanqbin.xyz/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>面向对象设计原则</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"/>
    <id>http://wanqbin.xyz/2019/11/19/面向对象设计原则/</id>
    <published>2019-11-18T17:06:00.000Z</published>
    <updated>2019-11-18T17:07:20.490Z</updated>
    
    <content type="html"><![CDATA[<p>面向对象设计，为什么？</p><p>变化是复用的天敌，面向对象设计最大的优势在于：抵御变化。</p><p>重新认识面向对象</p><ul><li>理解隔离变化<ul><li>从宏观层面来看，面向对象的构建方式更能适应软件的变化，能将变化所带来的影响减为最小</li></ul></li><li>各司其职<ul><li>从微观层面来看，面向对象的方式更强调各个类的“责任”</li><li>由于需求变化导致的新增类型不应该影响原来类型的实现——是所谓各司其职。</li></ul></li><li>对象是什么<ul><li>从语言实现层面来看，对象封装了代码和数据</li><li>从规格层面讲，对象是一系列可被使用的公共接口</li><li>从概念层面讲，对象时某种拥有责任的抽象。</li></ul></li></ul><p>面向对象设计原则</p><ul><li><p>依赖倒置原则（DIP)</p><ul><li>高层模块（稳定）不应该依赖于底层模块（变化），二者都应该依赖于抽象（稳定）</li><li>抽象（稳定）不应该依赖于实现细节（变化），实现细节应该依赖于抽象（稳定）。</li></ul></li><li><p>开放封闭原则（OCP)</p><ul><li>对扩展开放，对更改封闭</li><li>类模块应该是可扩展的，但是不可修改</li></ul></li><li><p>单一职责原则</p><ul><li>一个类应该仅有一个引起它变化的原因</li><li>变化的方向隐含着类的责任。</li></ul></li><li><p>Liskov替换原则（LSP）</p><ul><li>子类必须能够替换它们的基类</li><li>继承表达类型抽象</li></ul></li><li><p>接口隔离原则（ISP）</p><ul><li>不应该强迫客户程序依赖它们不用的方法</li><li>接口应该小而完备</li></ul></li><li><p>优先使用对象组合，而不是类继承</p><ul><li>类继承通常为“白箱复用”，对象组合通常为“黑箱复用”</li><li>继承在某种程度上破坏了封装性，子类父类耦合度高</li><li>而对象组合则只要求被组合的对象具有良好定义的接口，耦合度低</li></ul></li><li><p>封装变化点</p><ul><li>使用封装来创建对象之间的分界层，让设计者可以在分界层一侧进行修改，而不会对另一侧产生不良的影响，从而实现层次间的松耦合</li></ul></li><li><p>针对接口编程，而不是针对实现编程</p><ul><li>不将变量类型声明为某个特定的具体类，而是声明为某个接口。</li><li>客户程序无需获知对象的具体类型，只需要知道对象所具有的接口</li><li>减少系统中各部分的依赖关系，从而实现“高内聚，松耦合”的类型设计方案。</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;面向对象设计，为什么？&lt;/p&gt;
&lt;p&gt;变化是复用的天敌，面向对象设计最大的优势在于：抵御变化。&lt;/p&gt;
&lt;p&gt;重新认识面向对象&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解隔离变化&lt;ul&gt;
&lt;li&gt;从宏观层面来看，面向对象的构建方式更能适应软件的变化，能将变化所带来的影响减为最小&lt;/li
      
    
    </summary>
    
      <category term="设计模式" scheme="http://wanqbin.xyz/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://wanqbin.xyz/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="面向对象设计原则、" scheme="http://wanqbin.xyz/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%E3%80%81/"/>
    
  </entry>
  
  <entry>
    <title>什么是设计模式？</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E4%BB%80%E4%B9%88%E6%98%AF%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9F/"/>
    <id>http://wanqbin.xyz/2019/11/19/什么是设计模式？/</id>
    <published>2019-11-18T17:05:00.000Z</published>
    <updated>2019-11-18T17:06:06.114Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>每一个模式描述了一个在我们周围不断重复发生的问题，以及该问题的解决方案的核心。这样，你就能一次又一次地使用该方案而不必做重复劳动。</p><p>​                                                                           ——Christopher Alexander</p></blockquote><p>一般而言，一个模式有四个基本要素：</p><ol><li><p>模式名称。</p><p>一个助记名，它用一两个词来描述模式的问题，解决方案和效果。命名一个新的设计模式增加了我们的设计词汇。设计模式允许我们在较高的抽象层次进行设计。</p></li><li><p>问题。</p><p>描述了应该在何时使用模式。它解释了设计问题和问题存在的前提，它可能描述了特定的设计问题，如怎样用对象表示算法。也可能描述了导致不灵活设计的类或对象结构。</p></li><li><p>解决方案</p><p>描述了设计的组成成分，它们之间的相互关系以及各自的职责和协作方式。因为模式就像是一个模板，可应用于多种不同场合，所以解决方案并不描述一个特定而具体的设计或实现，而是提供设计问题的抽象和怎样用一个具有一般意义的元素组合来解决这个问题。</p></li><li><p>效果。</p><p>描述了模式应用的效果以及使用模式应权衡的问题。尽管我们描述设计决策时，并不总提到设计模式，但它们对于评价设计选择和理解使用模式的代价以及好处具有重要意义。软件效果大多关注对时间和空间的衡量，它们也表述了语言和实现问题。因为复用是面向对象设计的要素之一，所以模式效果包括它对系统灵活性、扩充性或可移动性的影响，显式地列出这些效果对理解和评价这些模式很有帮助。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;每一个模式描述了一个在我们周围不断重复发生的问题，以及该问题的解决方案的核心。这样，你就能一次又一次地使用该方案而不必做重复劳动。&lt;/p&gt;
&lt;p&gt;​                                                  
      
    
    </summary>
    
      <category term="设计模式" scheme="http://wanqbin.xyz/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://wanqbin.xyz/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>传输控制协议TCP</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AETCP/"/>
    <id>http://wanqbin.xyz/2019/11/19/传输控制协议TCP/</id>
    <published>2019-11-18T17:04:00.000Z</published>
    <updated>2019-11-18T17:04:33.756Z</updated>
    
    <content type="html"><![CDATA[<p>TCP是TCP/IP体系中面向连接的运输层协议，它提供了全双工的和可靠交付的服务。TCP与UDP最大的区别就是：TCP是面向连接的，而UDP是无连接的。TCP比UDP复杂的多，除了具有面向连接和可靠传输的特性外，TCP还在运输层使用流量控制和拥塞控制机制。</p><h2 id="一、TCP的主要特点"><a href="#一、TCP的主要特点" class="headerlink" title="一、TCP的主要特点"></a>一、TCP的主要特点</h2><ul><li>TCP是面向连接的运输层协议。这就是说，应用程序在使用TCP提供的服务传送数据之前，必须先建立TCP连接。建立TCP连接的目的是通信双方为接下来的数据传送做好准备，初始化各种状态变量，分配缓存等资源，在传送数据完毕后，必须释放已建立的TCP连接，即释放相应的资源和变量。</li><li>每一条TCP连接只能有两端点，即每一条TCP连接只能是点对点的（一对一）。TCP连接唯一地被通信两端的端点所确定，而两个端点分别由二元组（IP地址，端口号）唯一标识，即一条TCP连接由两个套接字地址标识。</li><li>TCP是提供可靠服务的。也就是说，通过TCP连接传送的数据无差错，不丢失，不重复，并且按序到达。</li><li>TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都没有发送缓存和接受缓存，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP的缓存后，就可以做自己的事，而TCP在合适的时候把数据发送出去。在接收时，TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。</li><li>面向字节流。TCP中的流指的是流入到进程或从进程流出的字节序列。面向字节流的含义是：虽然应用程序和TCP的交互时一次一个数据块，但TCP把应用程序交下来的数据看成是一连串的无结构的字节流。TCP不保证接收方应用程序收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系，从TCP接收方缓存中将数据读取完毕。但接受方应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。</li></ul><p>发送方的应用进程按照自己产生数据的规律，不断地把数据块陆续写入到TCP的发送缓存中。TCP再从发送缓存中取出一定数量的数据，将其组成TCP报文段逐个传递给IP层，然后发送出去。</p><p>接收方从IP层收到TCP报文段后，先把它暂存在接收缓存中，然后等待接收方对应的应用进程从接收缓存中按顺序读取。需要注意的是，接收方应用进程每次从接收缓存中读取数据时，是按应用进程指定的数量读取数据，而不是一次读取接收缓存中的一个完整的报文段或所有数据。只有当接收缓存中的数据量小于应用进程指定的读取量时，才返回给应用进程接收缓冲中所有的数据。当接收缓存中完全没有数据时，根据读取方式的不同，应用进程可能会一直等待，也可能直接返回。由此可见，TCP的接收方应用进程读取的数据块与发送方应用进程发送的数据块边界毫无关系，也就是说，TCP接收方在向上层交付数据时不保证能保持发送方应用进程发送数据块的边界。</p><p>TCP连接时一条虚连接，而不是一条物理连接。也就是说，TCP连接时一种抽象的逻辑连接。</p><p>TCP报文段首先要传送到IP层，加上IP首部后，再传送到数据链路层，再加上数据链路层的首部和尾部后，才离开主机发送到物理链路。另外，TCP连接仅存在于两个端系统同中，而网络核心的中间设备完全不知道该连接的存在。TCP连接的组成主要包括：通信两端主机上的缓存、状态变量，在这两台主机间的路由器和交换机没有为该连接分配任何缓存和变量。</p><p>与UDP的端口队列不同的是，TCP的发送缓存和接受缓存都是分配给一个连接的，而不是一个端口。TCP的一个连接由四元组（源IP地址，源端口号，目的IP地址，目的端口号）标识，即由源/目的套接字地址对标识。也就是说，来自不同源的TCP报文段，即使它们的目的IP地址和面对端口号相同，它们也不可能被交付到同一个TCP接收缓存中，因为它们在不同的TCP管道中传输，到达不同管道出口的缓存。通常一个TCP服务器进程用一个端口号与不同的客户机进程建立多个连接，然后创建多个子进程分别用这些连接与各自的客户机进程进行通信。</p><h2 id="二、TCP报文段的格式"><a href="#二、TCP报文段的格式" class="headerlink" title="二、TCP报文段的格式"></a>二、TCP报文段的格式</h2><p>TCP虽然是面向字节流的，但TCP传送的数据单元却是报文段。TCP报文段分为首部和数据两部分，而TCP的全部功能都体现在它首部各字段的作用。</p><p>TCP报文段首部的前20个字节是固定的，后面有4N个字节是根据需要而增加的选项。因此，TCP首部的最小长度是20字节。</p><p>首部固定部分各字段的意义如下所述：</p><ul><li>源端口和目的端口。各占两个字节。与UDP一样，该字段定义了主机中发送和接受该报文段的应用程序的端口号，用于运输层的复用和分用。</li><li>序号。占4个字节。序号从0开始，到$2^{32}-1$为止。TCP是面向数据流的.TCP传送的报文段可看成连续的数据流。在一个TCP连接中传送的数据流中的每一个字节都是按顺序编号。整个数据的起始序号在连接建立时设置。首部中的序号字段的值则指的是本报文段所含的数据的第一个字节的序号。</li><li>确认号。占4个字节，是期望收到对方的下一个报文段的第一个数据字节的序号。TCP提供的是双向通信，当一端发送数据时同时对接收到的对端数据进行确认。TCP采用的是累积确认。</li><li>数据偏移。占4位，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远。这实际上就是TCP报文段首部的长度。由于首部长度不固定，因此数据偏移字段是必要的。但应注意的是，“数据偏移”的单位不是字节而是32位字（即以4字节长的字为计算单位）。由于4位二进制数能够表示的最大十进制数字是15，因此数据偏移的最大值是60字节，这也是TCP首部的最大长度。</li><li>保留。占6位，保留为今后使用，但目前应置0.</li><li>紧急URG。当URG=1时，表明紧急指针字段有效。它告诉接收方TCP此报文段中有紧急数据，应尽快交付给应用程序，而不要按序从接收缓存中读取。</li><li>确认ACK。只有当ACK=1时确认号字段才有效。当ACK=0时，确认号无效。</li><li>推送PSH。处于效率的考虑，TCP可能会延迟发送数据或向应用程序延迟交付数据，这样可以一次处理更多的数据。但是当两个应用进程进行交互式通信时，有时在一段的应用进程希望在键入一个命令后立即就能得到对方的响应。在这种情况下，应用程序可以通知TCP使用推送操作。这时发送方TCP把PSH置1，并立即创建一个报文段发送出去，而不需要累积到足够多的数据再发送。。接收TCP收到PSH置1的报文段，就尽快地交付给接收应用进程，而不要等到收到足够多的的数据才向上交付。</li><li>复位RST。当RST=1时，表明TCP连接中出现严重差错，必须释放连接，然后再从新建立运输连接。RST置1还用来拒绝一个非法的报文段或拒绝打开一个连接。RST也可称为重建位或重置位。</li><li>同步SYN。用来建立一个连接。当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN=1和ACK=1。因此，SYN置1就表示这是一个连接请求或连接接收报文。</li><li>终止FIN。用来释放一个连接。当FIN=1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。</li><li>窗口。占两字节。窗口值指示发送该报文段的接受窗口大小，在0到$2^{16}-1$之间。窗口字段用来控制对方发送的数据量，单位为字节。窗口字段反映了接收方接收缓存的可用空间大小。</li><li>检验和。占两个字节。检验和字段检验的范围包括首部和数据两部分。</li><li>选项。长度可变。这里介绍一个，即最大报文段长度（MSS）。</li></ul><h2 id="三、TCP的可靠传输"><a href="#三、TCP的可靠传输" class="headerlink" title="三、TCP的可靠传输"></a>三、TCP的可靠传输</h2><ul><li><p>数据编号与确认</p><p>TCP是面向字节的。TCP把应用层交下来的长报文看成是一个个字节组成的数据流，并使每一个字节对应于一个序号。注意，GBN协议中是对每个分组进行编号在。在建立连接时，双方TCP要各自确定初始序号。TCP每次发送的报文段的首部中的序号字段数值表示该报文段中紧接着首部后面的第一个数据字节的序号。</p><p>TCP使用累积确认，即确认是对所有按序收到的数据的确认。但请注意，接收方返回的确认号时已按序收到的数据的最高序号加1.也就是说，确认号表示接收方期望下一次收到的数据中的第一个数据直接序号。</p><p>当TCP发送一报文段时，它同时也咋自己的重传队列中存放这个报文段的一个副本。若收到确认，则删除此副本。若在规定时间内没有收到确认，则重传此报文段的副本。TCP的确认并不保证数据已交付给了应用进程，而只是表明在接收方的TCP已按序正确收到了对方所发送的报文段。</p><p>由于TCP连接能提供全双工通信，因此通信中的每一方都不必专门发送确认报文段，而可以在传送数据时顺便把确认信息捎带传送。为此，TCP采用了一种延迟确的机制，即接收方在正确接收到数据时可能要等待一段时间再发送确认。若这段时间内有数据要发送给对方，则可以捎带确认。也有可能在这段时间内又有数据到达，则可以同时对这两次到达的数据进行累计确认。这样做可以减少发送完全不带数据的确认报文段，以提高TCP的传输效率。</p><p>接收方若收到有差错的报文段就丢弃。若收到重复的报文段，也要丢弃，但要立即发回确认信息。</p><p>若收到的报文段无差错，只是未按序号顺序到达，那么应如何处理？在GBN协议中会丢弃所有未按序到达的分组，但是TCP对此未做明确规定，而是让TCP的实现者自行确定。可以像GBN协议一样将不按序到达的报文段丢弃，但多数TCP实现是先将其暂存与接收缓存内，待所缺序号的报文段收齐后再一起上交应用层。在互联网环境中，封装TCP报文段和IP数据报不一定是按序到达的，将失序的报文段先缓存起来可以避免不必要的重传。注意，不论采用哪种方法，接收方都要立即对已按序接收到的数据进行确认。</p><p>TCP发送方每发送一个报文段，就会为这个报文段设置一个计时器。只要计时器设置的重传时间已经到了但还没有收到确认，就要重传这一报文段。我们知道，在GBN协议中，一旦发送方某个分组超时，则会重传窗口内所有已发送的分组。而在TCP中发送方只会重传超时的那一个报文段，如果后序报文段的确认能够在超时之前及时到达，则不会重传那些还没有超时的后续报文段。</p></li><li><p>以字节为单位的滑动窗口</p><p>为了提高报文段的传输效率，TCP采用滑动窗口协议。但与GBN协议不同的是，TCP发送窗口大小的单位是字节，而不是分组数。TCP发送方已发送的未被确认的字节数不能超过发送窗口的大小。</p><p>落入发送窗口内的是允许发送的字节，落在发送窗口外左侧的是已发送并被确认的字节，而落在发送窗口外右侧是是还不能发送的字节。收到确认后，发送窗口向右滑动，直到发送窗口的左沿正好包含确认序号的字节。</p><p>发送缓存用来暂时存放：</p><ul><li>发送应用程序传送给发送方TCP准备发送的数据</li><li>TCP已发送出去但尚未收到确认的数据</li></ul><p>发送窗口通常只是发送缓存的一半部分。已被确认的数据应当才能够发送缓存中删除，因此发送缓存和发送窗口的后沿是重合的。发送应用程序最后写入发送缓存的字节序号减去最后被确认的字节序号，就是还保留在发送缓存的被写入的字节数。如果发送应用程序传送给TCP发送方的速度太快，可能会最终导致发送缓存被填满，这时发送应用程序必须等待，直到有数据从发送缓存中删除。</p><p>接收缓存用来暂时存放：</p><ul><li>按序到达的，但尚未被接受应用程序读取的数据</li><li>未按序到达的，但还不能被接收应用程序读取的数据</li></ul><p>如果收到的分组被检测出有差错，则要丢弃。如果接受应用程序来不及读取收到的数据，接收缓存最终就会被填满，使接收窗口减小到0.反之，如果接受应用程序能够及时从接收缓存中读取收到的数据，接收窗口就会增大，但最大不能超过接收缓存的大小。</p></li><li><p>超时重传时间的选择</p><p>由于TCP的下层是互联网环境，发送的报文段可能只经过一个高速率的局域网，但也可能经过多个低速率的广域网，并且每个IP数据报所选择的路由还可能不同，不同时间网络拥塞情况也有不同。因此往返时间是不断变化的。</p><p>对于运输层来说，其往返时间的方差很大。如果把超时时间设置得太短，则很多报文段就会过早超时，引起很多报文段的不必要的重传，使网络负荷增大。但如果把超时时间设置得过长，则大量丢失的报文段不能被及时重传，降低了传输效率。因此，选择超时重传时间再数据链路层并不困难，但在运输层却不那么简单。</p><p>那么。运输层的超时计时器的超时重传时间究竟应设置为多大呢？<br>显然，超时重传时间应比当前报文段的往返时间要长一些。针对互联网环境中端到端的时延是动态变化的特点，TCP才用了一种自适应算法。该算法记录每个报文段发出的时间，以及收到相应的确认报文段的时间。这两个时间之差就是报文段得到往返时间RTT。在互联网中，实际的RTT测量值变化非常大，因此需要用多个RTT测量值的平均值来估计当前报文段的RTT。由于越近的测量值越能反映网络当前的情况,TCP采用指数加权移动平均的算法对RTT测量值进行加权平均，得出报文段的平均往返时间RTT。</p></li><li><p>快速重传</p><p>超时触发重传存在的一个问题就是超时时间可能相对较长。由于无法精确估计实际的往返时间，超时重传时间RTO往往比实际的往返时间大很多。当一个报文段丢失时，发送方需要等待很长时间才能重传丢失的报文段，因而增加了端到端时延。幸运的是，有时一个报文段的丢失会引起发送方连续收到多个重复的确认，通过收到多个重复的确认可以快速地判断报文段可能已经丢失而不必等待重传计时器超时。快速重传就是基于该方法对超时重传的补充和改进。</p></li><li><p>选择确认</p><p>TCP报文段的确认字段是一种累积确认，就是说，它只通告收到的最后一个按序到达的字节，而没有通告所有收到的失序到达的那些字节，虽然这些字节已经被接收方接收并暂存在接收缓存中。这些没有被确认的字节很可能因为超时而被发送方重传。为了避免这些无意义的重传，一个可选功能选择确认可以解决这个问题。选择确认允许接收方通知发送方所有正确接收了的但是失序的字节块，发送方可以根据这些信息只重传那些接收方还没有收到的字节块。</p></li></ul><h2 id="四、TCP的流量控制"><a href="#四、TCP的流量控制" class="headerlink" title="四、TCP的流量控制"></a>四、TCP的流量控制</h2><p>一条TCP连接的双方主机都为该连接设置了接收缓存。当该TCP连接接收得到按序的字节后，它就将数据放入接收缓存。相关联的应用程序会从该缓存中读取数据，但应用程序不一定能马上将数据取走。事实上，接收方应用也许正忙于其他任务，需要过很长的时间后才能去读取数据。如果应用程序读取数据比较慢，而发送方发送数据很快、很多，则很容易使该连接的接收缓存溢出。</p><p>TCP为应用程序提供了流量控制服务，以解决因发送方发送数据太快而导致接收方来不及接收，使接收方缓存溢出的问题。</p><p>流量控制的基本方法就是接收方根据自己的接收能力控制发送方的发送速率。因此，可以说流量控制是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读速率相匹配。利用滑动窗口机制可以很方便地控制发送方的平均发送速率。TCP采用接收方控制发送方发送窗口大小的方法来实现在TCP连接上的流量控制。在TCP报文段首部的窗口字段写入的数值就是当前给对方设置的发送窗口数值的上限。这种由接收方控制发送方的做法，在计算机网络中经常使用。</p><p>发送窗口在连接建立时由双方商定。但在通信的过程中，接收方根据接收缓存中可用缓存的大小，随时动态地调整对方的发送窗口的上限值。为此，TCP接收方要维持一个接受窗口的变量，其值不能大于可用缓存大小。</p><p>在TCP报文段首部的窗口字段写入的数值就是当前接收方的接收窗口的大小。TCP发送方的发送窗口的大小必须小于该值。</p><p>当接收方的可用接收缓存大小不再为0时，向发送方发送的窗口更新报文段丢失了会出现什么问题？如果接收方一直没有数据要发送给发送方，则发送方将会永远等下去。为防止因为因接收方发送给发送方的窗口变更变文段的丢失所导致的死锁状态，实际上，当窗口变为0时，如果发送方有数据要发送，则会周期性地发送只包含一个字节数据的窗口探测报文段，以便强制接收方发回确认并公告接收窗口大小。如果这时接收窗口大小非零，则会接收这个字节，并对这个字节进行确认，否则会丢弃该字节并对以前数据进行重复确认。</p><h2 id="五、TCP的连接管理"><a href="#五、TCP的连接管理" class="headerlink" title="五、TCP的连接管理"></a>五、TCP的连接管理</h2><p>TCP是面向连接的协议。连接的建立和释放是每一次面向连接的通信中必不可少的过程。因此TCP连接就有三个阶段，即连接建立、数据传送、连接释放。建立连接的目的就是为接下来要进行的通信做好充分的准备，其中最重要的就是分配相应的资源。在通信结束之后显然要释放所占用的资源，即释放连接。注意，TCP的连接时运输层连接，只存在于通信的两个端系统中，而网络核心的路由器完全不知道它的存在。</p><ul><li><p>TCP的连接建立</p><p>在连接建立时要解决以下三个问题：</p><ul><li>要使每一方能够确知对方的存在；</li><li>要允许双方协商一些参数</li><li>能够对运输实体资源进行分配和初始化</li></ul><p>TCP的连接建立采用客户——服务器方式。主动发起连接建立的应用进程叫做客户，而被动等待连接建立的应用进程叫做服务器。</p><p>设主机B运行TCP的服务器进程，它先发出一个被动打开命令，准备接受客户进程的连接请求。然后服务器进程就处于“听”状态，不断检测是否有客户进程要发起连接请求。如有，即做出响应。</p><p>设客户进程运行在主机A中。它先向其TCP发出主动打开命令，表明要向某个IP地址的某个端口建立运输层连接。</p><p>主机A的TCP向主机B的TCP发出连接请求报文段，其首部的同步位SYN应置1，同时选择一个序号<code>seq=x</code>，这表明下一个报文段的第一个数据字节的序号是<code>x+1</code>。</p><p>主机B的TCP收到连接请求报文段后，如同意，则发回连接请求确认。在确认报文段中应把SYN位和ACK位都置1，确认号<code>ack=x+1</code>，同时也为自己选择一个序号<code>seq=y</code>。</p><p>主机A的TCP收到B接受连接请求的确认后，还要向B给出确认，其ACK置1，确认号<code>ack=y+1</code>。而自己的序号<code>seq=x+1</code>。TCP标准规定，SYN=1的报文段不能携带数据，但要消耗一个序号。因此A发送的第二个报文段的序号应当是第一个报文段的序号加1.注意，A发送的第二个报文段中SYN是0而不是1，ACK位必须为1.该报文段是对B的同步报文段的确认，但是一个普通报文段，可携带数据。若该报文段不携带数据，则按照TCP的规定，确认报文段不消耗序号。</p><p>运行客户进程的主机A的TCP通知上层应用进程，连接已经建立。</p><p>当运行服务器进程的主机B的TCP收到主机A的确认后，会通知其上层应用进程，连接已经建立。</p><p>连接建立采用的这种过程叫做三次握手。</p><p>为什么要发送这三个报文段呢？这主要是为了防止已失效的连接请求报文段突然又传送到了主机B，因而导致错误产生。</p></li><li><p>TCP的连接释放</p><p>在数据传输结束后，通信的双方都可以发出释放连接的请求。在连接释放过程中要释放为该连接分配的所有资源。</p><p>设主机A的应用进程先向其TCP发出连接释放请求，并且不再发送数据。TCP通知对方要释放A到B这个方向的链接，把发往主机B的报文段首部的FIN置1，其序号<code>seq=u</code>。由于FIN报文段要消耗一个序号，因此序号u等于A前面已传送过的数据的之后一个字节的序号加1.</p><p>主机B的TCP收到释放连接的通知后即发出确认，确认号<code>ack=u+1</code>，而这个报文段自己的序号假定为v。主机B的TCP这时应通知高层应用进程。这样，从A到B的连接就释放了，连接处于半关闭状态。</p><p>此后，主机B不再接受主机A发来的数据。但若主机B还有一些数据要发往主机A，则可以继续发送。主机A只要正确收到数据，仍应向主机B发送确认。</p><p>若主机B不再向主机A发送数据，其应用进程就通知TCP释放连接。主机B发出的连接释放报文段必须使FIN=1，其序号为w。主机A必须对此发出确认，把ACK置1，确认号<code>ack=w+1</code>，而自己的序号为<code>seq=u+1</code>。这样才把从B到A的反方向连接释放掉。但此时，主机A的TCP并不能马上释放整个连接，还要再等待一个超时时间才能将整个连接释放。因为主机A的确认有可能丢失，这时B会重传FIN报文段。在这段超时时间内，若A又收到B重传的FIN报文段，A需要再次进行确认。收到A的最后确认，B才能将整个连接释放。若等待的这段超时时间内没有收到B的FIN报文段，主机A的TCP则应向其应用进程报告，整个连接已经全部释放。</p><p>上述的连接释放过程是四次握手。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;TCP是TCP/IP体系中面向连接的运输层协议，它提供了全双工的和可靠交付的服务。TCP与UDP最大的区别就是：TCP是面向连接的，而UDP是无连接的。TCP比UDP复杂的多，除了具有面向连接和可靠传输的特性外，TCP还在运输层使用流量控制和拥塞控制机制。&lt;/p&gt;
&lt;h2 
      
    
    </summary>
    
      <category term="计算机网络" scheme="http://wanqbin.xyz/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="TCP" scheme="http://wanqbin.xyz/tags/TCP/"/>
    
      <category term="传输控制协议" scheme="http://wanqbin.xyz/tags/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>拥塞控制</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/"/>
    <id>http://wanqbin.xyz/2019/11/19/拥塞控制/</id>
    <published>2019-11-18T17:04:00.000Z</published>
    <updated>2019-11-18T17:05:04.673Z</updated>
    
    <content type="html"><![CDATA[<p>当网络中出现太多的分组时，网络的性能开始下降。这种情况称为拥塞。拥塞是分组交换网中一个非常重要的问题。如果网络中的负载，即发送到网络中的数据量超过了网络的容量，即网络中能处理的数据量，那么在网络中就可能发生拥塞。所谓拥塞控制就是放置过多的数据注入到网络中，这样可以使网络中的路由器或链路不至过载。</p><h2 id="一、拥塞的原因及危害"><a href="#一、拥塞的原因及危害" class="headerlink" title="一、拥塞的原因及危害"></a>一、拥塞的原因及危害</h2><p>理想情况下，在吞吐量饱和之前，网络吞吐量应等于输入负载。但当输入负载超过网络容量时，在理想情况下，吞吐量不再增长而保持为水平线，即吞吐量达到饱和。这就表明输入负载中有一部分损失掉了。</p><p>但是，在实际的网络中，若不采取有效的拥塞控制手段，随着输入负载的增大，网络吞吐量的增长速率逐渐减小。特别是当输入负载达到某一数值时，网络的吞吐量反而随负载的增大而下降，这时网络就进入了拥塞状态。当输入负载继续增大时，网络的吞吐量甚至有可能下降到零，即网络已无法工作。这就是所谓的死锁。</p><p>当网络拥塞而丢弃分组时，该分组在其经过路径中所占用的全部资源都被白白浪费掉了。</p><p>既然网络拥塞是因为发送到网络中的数据量超过了网络的容量，要彻底解决分组交换网中的拥塞问题，就要想办法限制输入到网络中的负载，即控制源点的发送速率。</p><h2 id="二、拥塞控制的基本方法"><a href="#二、拥塞控制的基本方法" class="headerlink" title="二、拥塞控制的基本方法"></a>二、拥塞控制的基本方法</h2><p>拥塞控制和流量控制之间的区别是需要注意的，因为它们都需要控制源点的发送速率，因此容易混淆。拥塞控制的任务是防止过多的数据注入到网络中，使网络能够承受现有的网络负载。这是一个全局性的问题，涉及各方面的行为，包括所有的主机，所有的路由器，路由器内部的存储转发处理过程，以及与降低网络传输性能有关的所有因素。</p><p>与此相反，流量控制只与特定点对点通信的发送方和接收方之间的流量有关。它的任务是，确保一个快速的发送方不会持续地以超过接收方接收能力的速率发送数据，以防止接收方来不及处理数据。流量控制通常涉及的做法是，接收方向发送方提供某种直接的反馈，以抑制发送方的发送速率。</p><p>从控制论的角度出发，拥塞控制可以分为开环控制和闭环控制两大类。开环控制方法试图用良好的设计来解决问题，它的本质是从一开始就保证问题不会发生。一旦系统启动并运行起来了，就不需要中途做修正。</p><p>相反，闭环控制是一种基于反馈环路的方法，它包括三个部分：</p><ul><li>监测网络系统以便监测到拥塞在何时、何地发生</li><li>把拥塞发生的信息传送到可以采取行动的地方</li><li>调整网络系统的运行以解决出现的问题</li></ul><p>当网络系统的流量可以准确规定、性能要求可以事先获得时，适于使用开环控制；而当流量特征不能1准确描述或者当系统不提供资源预留时，适于使用闭环控制。由于因特网中不提供资源预留的机制，而且流量的特性不能准确地描述，所以在因特网中拥塞控制主要采用闭环控制方法。</p><p>根据拥塞反馈信息的形式，又可以将闭环拥塞控制算法分为显式反馈算法和隐式反馈算法。在显式反馈算法中，从拥塞点（即路由器）向源点提供关于网络中拥塞状态的显式反馈信息。当因特网中一个路由器被大量的IP是数据报淹没时，它可能会丢弃一些数据报，同时可使用ICMP源站抑制报文通告源主机。源站收到后应降低发送速率。不过当网络拥塞发生时，向网络中注入这些额外的分组可能会”火上浇油“，因此在实际中很少使用。现在，因特网中的拥塞控制任务主要是在运输层上完成的。更好的显式反馈信息的方法是，在路由器转发的分组中保留一个比特或字段，用该比特或字段的值表示网络的拥塞状态，而不是专门发送一个分组。</p><p>在隐式反馈算法中，源端通过对网络行为的观察来推断是否发生了拥塞，无需拥塞点提供显式反馈信息。TCP采用的就是隐式反馈算法。</p><p>需要说明的是，拥塞控制并不仅仅是运输层要考虑的问题。显式反馈算法就必须涉及网络层。虽然一些网络体系结构主要在网路层实现拥塞控制，但因特网主要利用隐式反馈在运输层实现拥塞控制。</p><p>不论采用哪种方法进行拥塞控制都是需要付出代价的。例如，在实施拥塞控制时，可能需要在结点之间交换信息和各种命令，以便选择控制的策略和实施控制。这样会产生额外的开销。有些拥塞控制机制会预留一些资源用于特殊用户或特殊情况，降低了网络资源的共享程度。因此，当网络输入负载1不大时，有拥塞控制的系统吞吐量要低于无拥塞控制的系统吞吐量。但付出一定的代价是值得的，它会保证网络性能的稳定，不会因为输入负载的增长而导致网络性能的恶化甚至出现崩溃。</p><h2 id="三、TCP的拥塞控制"><a href="#三、TCP的拥塞控制" class="headerlink" title="三、TCP的拥塞控制"></a>三、TCP的拥塞控制</h2><p>TCP采用的方法是让每一个发送方根据所感知到的网络拥塞的程度，来限制其向连接发送流量的速率。如果TCP发送方感知从它到目的地之间的路径上没有拥塞，则增加其发送速率；如果发送方感知在该路径上有拥塞，则降低其发送速率。该方法具体要解决以下三个问题：首先，TCP发送方如何限制它的发送速率；其次，TCP发送方如何感知从它到目的地之间的路径上存在拥塞；最后，当发送方感知到端到端的拥塞时，采用什么算法来改变其发送速率。</p><p>TCP的流量控制利用接收方通告给发送方的接收窗口<code>rwnd</code>大小来限制发送窗口的大小。这个窗口大小就是接收方给发送方的TCP报文段首部中的窗口字段的值。实际上TCP的发送方还维持着一个叫做拥塞窗口<code>cwnd</code>的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且是动态变化的。TCP发送方在确定发送报文段的速率时，既要根据接收方的接收能力，又要从全局考虑不要使网络发生拥塞。因此TCP发送方的发送窗口大小取接收方接收窗口和拥塞窗口的最小值，即应按如下公式确定：</p><p><code>发送窗口的上限值=Min(rwnd,cwnd)</code></p><p>当<code>rwnd&lt;cwnd</code>时，是接收方的接收能力限制发送窗口的最大值。但当<code>cwnd&lt;rwnd</code>时，则是网络的传输能力限制发送窗口的最大值。</p><p>TCP发送方又是如何知道网络发生了拥塞呢？我们知道，当网络发生拥塞时，路由器就要丢弃分组。现在通信线路的传输质量一般都很好，因传输出差错而丢弃分组的概率是很小的。因此检测到分组丢失就可以认为网络出现了故障。在快速重传中，发送方不一定要通过重传计时器超时才能发现分组的丢失，可以通过接收到三个重复确认就能判断有分组的丢失。因此，当重传计时器超时或接收到三个重复确认时，TCP的发送方就认为网络出现了拥塞。</p><p>当发送方感知到端到端的拥塞时，采用什么算法来改变其发送速率呢？慢启动、拥塞避免和快速恢复。</p><ul><li><p>慢启动和拥塞避免</p><p>当主机刚开始发送数据时完全不知道网络的拥塞情况，如果立即把较大的发送窗口中的全部数据字节都注入到网络，那么就有可能引发网络拥塞。经验证明，较好的方法是通过试探发现网络中的可用带宽，即由小到大逐渐增大发送方的拥塞窗口数值，直到发生拥塞。通常在刚刚开始发送报文段时可先将拥塞窗口<code>cwnd</code>设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，将拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口<code>cwnd</code>，可以使分组注入到网络的速率更加合理。这就是慢启动算法。</p><p>在慢启动阶段发送速率以指数方式迅速增长，若持续以该速度增长发送速率必然导致网络很快进入到拥塞状态。因此当网络要接近拥塞时应降低发送速率的增长率，以避免网络拥塞。这可以使TCP连接在一段相对长的时间内保持较高的发送速率但又不使网络拥塞。为此，TCP定义了一个状态变量，即慢启动门限<code>ssthresh</code>（即从慢启动阶段进入拥塞避免阶段的门限）。慢启动门限<code>ssthresh</code>的用法如下：</p><ul><li>当<code>cwnd&lt;ssthresh</code>时，使用上述的慢启动算法</li><li>当<code>cwnd&gt;ssthresh</code>时，停止使用慢启动算法而改用拥塞避免算法</li><li>当<code>cwnd=ssthresh</code>时，即可以使用慢启动算法，又可以使用拥塞避免算法</li></ul><p>具体的做法如下所述：</p><p>拥塞避免算法使发送方的拥塞窗口<code>cwnd</code>每经过大约一个往返时间RTT就增加一个MSS的大小。实际的做法是，每收到一个新的确认，将<code>cwnd</code>增加<code>MSS*(MSS/cwnd)</code>。这样，拥塞窗口<code>cwnd</code>按线性规律缓慢增长，比慢启动算法的拥塞窗口增长速率缓慢得多。</p><p>无论在慢启动阶段还是在拥塞避免阶段，只要发送方发现网络拥塞，就立即将拥塞窗口<code>cwnd</code>重新设置为1，并执行慢启动算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够的时间把队列中积压的分组处理完毕。在重新执行慢启动算法的同时，将慢启动门限<code>ssthresh</code>设置为出现拥塞时的发送窗口值的一半。这样设置的考虑是：这一次在该窗口值发生拥塞，则下次很有可能在该窗口值再出现拥塞，因此当下次拥塞窗口又接近该值时，就要降低窗口的增长速率，进入拥塞避免阶段。</p><p>拥塞避免的具体过程：</p><ul><li>当TCP连接进行初始化时，将拥塞窗口置为1.</li><li>执行慢启动算法时，拥塞窗口<code>cwnd</code>的初始值为1。以后发送方每收到一个对新报文段的确认ACK，就将发送方的拥塞窗口加1，然后开始下一次的传输。一个轮次就是把拥塞窗口<code>cwnd</code>所允许发送的报文段都发送出去，并且都收到了对方的确认。“轮次”之间的间隔时间可以近似为一个RTT。因此，拥塞窗口<code>cwnd</code>随着传输轮次按指数规律增长。当拥塞窗口<code>cwnd</code>增长到慢启动门限值<code>ssthresh</code>时，就改为执行拥塞避免算法，拥塞窗口按线性规律增长。</li><li>假定拥塞窗口的数值增长到24时，网络出现拥塞。更新后的<code>ssthresh</code>值变为12，拥塞窗口再重新设置为1，并执行慢启动算法。当<code>cwnd=12</code>时改为执行拥塞避免算法，拥塞窗口按线性规律增长，每经过一个往返时间就增加一个MSS的大小。</li></ul><p>可见，执行拥塞避免算法后，拥塞窗口呈线性增长，发送速率增长比较缓慢，以防止网络过早出现拥塞，并使发送方可以长时间保持一个合理的发送速率。这里要再强调一下，“拥塞避免”并不能避免拥塞，而是说把拥塞窗口控制为按线性规律增长，使网络不容易立即出现拥塞。</p></li><li><p>快速恢复</p><p>实际上TCP检测到分组丢失有两种情况：重传计时器超时和收到连续三个重复的ACK。上面的拥塞控制算法对这两种情况采取了同样的反应，即将拥塞窗口降低为1，然后执行慢启动算法。但实际上这两种情况下网络拥塞情况是不一样的。当发送方收到连续三个重复的ACK时，虽然有可能丢失了一些分组，但这连续的三个重复ACK同样又表明丢失分组以外的另外三个分组已经被接收方接收了。因此，与发生超时事件的情况不同，网络还有一定的分组交付能力，拥塞情况并不严重。既然网络拥塞情况并不严重，将拥塞窗口直接降低为1则反应太过剧烈了，这会导致发送方要经过很长时间才能恢复到正常的传输速率。</p><p>为此，定义了与快速重传配套使用的快速恢复算法，其具体步骤如下：</p><ul><li>当发送方收到连续三个重复的ACK时，就重新设置慢启动门限<code>ssthresh</code>，将其设置为当前发送窗口的一半。这一点和慢启动算法是一样的。</li><li>与慢启动不同之处是拥塞窗口<code>cwnd</code>不是设置为1，而是设置为新设置的慢启动门限<code>ssthresh</code>，然后开始执行拥塞避免算法，使拥塞窗口缓慢地线性增长。</li></ul><p>对于超时事件，由于后续的分组都被丢弃了，一直没有收到它们的确认而导致重传计时器超时，显然网络存在严重的阻塞。对于这种情况重新执行慢启动有助于迅速减少主机发送到网络中的分组数，使发生拥塞的路由器有足够的时间把队列中积压的分组处理完毕。</p><p>采用快速恢复算法的情况下，长时间的TCP连接在稳定的时候通常处于下面描述的不断重复状态。经过慢启动发送方迅速进入拥塞避免阶段，在该阶段，使拥塞窗口呈线性增长，即加性增，发送速率缓慢增长，以防止网络网络过早拥塞。当流量逐渐超过网络可用带宽时会出现拥塞，但由于发送速率增长缓慢，通常仅导致少量分组丢失。这种情况下发送方会超过三个重复ACK并将拥塞窗口减半，即“乘性减”，然后再继续执行“加性增”缓慢增长发送速率，如此重复下去。因此，对于长时间的TCP连接，在稳定时的拥塞窗口大小呈锯齿状变化。在这种“加性增，乘性减“的拥塞控制下，发送方的平均发送速率始终保持在较接近网络可用带宽的位置。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;当网络中出现太多的分组时，网络的性能开始下降。这种情况称为拥塞。拥塞是分组交换网中一个非常重要的问题。如果网络中的负载，即发送到网络中的数据量超过了网络的容量，即网络中能处理的数据量，那么在网络中就可能发生拥塞。所谓拥塞控制就是放置过多的数据注入到网络中，这样可以使网络中的
      
    
    </summary>
    
      <category term="计算机网络" scheme="http://wanqbin.xyz/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://wanqbin.xyz/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
      <category term="TCP" scheme="http://wanqbin.xyz/tags/TCP/"/>
    
      <category term="拥塞控制" scheme="http://wanqbin.xyz/tags/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>用户数据报协议UDP</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AEUDP/"/>
    <id>http://wanqbin.xyz/2019/11/19/用户数据报协议UDP/</id>
    <published>2019-11-18T17:03:00.000Z</published>
    <updated>2019-11-18T17:03:48.323Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、UDP概述"><a href="#一、UDP概述" class="headerlink" title="一、UDP概述"></a>一、UDP概述</h2><p>用户数据报协议UDP只在IP数据报服务之上增加了有限的功能，这就是端口的功能（有了端口，运输层就能进行复用和分用）和差错检测功能。虽然UDP用户数据报只能提供不可靠的交付，但UDP在某些方面有其特殊的优点，如下：</p><ul><li>UDP是无连接的，即发送数据之前不需要建立连接，因此减少了开销和发送数据之前的时延。</li><li>UDP使用尽最大努力交付，即不保证可靠交付，同时也不使用流量控制和拥塞控制，因此主机不需要维持具有很多参数的、复杂的连接状态表。</li><li>由于UDP没有拥塞控制，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用时很重要的。</li><li>UDP是面向报文的。这就是说，UDP对应用程序交下来的报文不再划分为若干个分组来发送，也并把收到的若干个报文合并后再交给应用程序。应用程序交给UDP一个报文，UDP就发送这个报文；而UDP收到一个报文，就把它交付给应用程序。因此，应用程序必须选择合适大小的报文。若报文太长，UDP把它交给IP层后，IP层在传送时可能要进行分片，这会降低IP层的效率。反之，若报文太短，UDP就把它交给IP层后，会使IP数据报的首部相对太大，降低了IP层的效率。</li><li>UDP支持一对一，一对多，多对一和多对多的交互通信。</li><li>用户数据报只有8个字节的首部开销，比TCP的20个字节的首部要短得多。</li></ul><h2 id="二、UDP报文的首部格式"><a href="#二、UDP报文的首部格式" class="headerlink" title="二、UDP报文的首部格式"></a>二、UDP报文的首部格式</h2><p>UDP报文有两个字段：数据字段和首部字段。首部字段很简单，只有8个字节，由四个字段组成，每个字段都是两个字节。各字段意义如下：</p><ul><li>源端口：源端口号</li><li>目的端口：目的端口号</li><li>长度：UDP用户数据报的长度</li><li>检验和：差错检验码，防止UDP用户数据报在传输中出错。</li></ul><p>UDP报文首部中最重要的字段就是源端口和目的端口，它们用来标识UDP发送方和接收方。实际上，UDP是通过二元组（目的IP地址，目的端口号）来定位一个接收方应用进程，而用二元组（源IP地址，源端口号）来标识一个发送方进程。二元组（IP地址，端口号）被称为套接字地址。</p><p>一个UDP端口与一个报文队列（缓存）关联，UDP根据目的端口号将到达的报文加到相应的队列。应用进程根据需要的队列中读取整个报文。由于UDP没有流量控制功能，如果报文到达的速度长期大于应用进程从队列中读取报文的速度，则会导致队列溢出和报文丢失。</p><p>如果接收方UDP发现收到的报文中的目的端口号不正确（即不存在对应于该端口号的应用进程），则丢弃该报文，并由网际控制报文协议ICMP发送一个端口不可达的差错报文给对方1.</p><p>UDP用户数据报首部中检验和的计算方法有些特殊。在1计算检验和时，要在UDP用户数据报之前增加12个字节的伪首部。所谓伪首部是因为这种伪首部并不是UDP用户数据报真正的首部。只是在计算检验和时，临时和UDP用户数据报连接在一起，得到一个临时的UDP用户数据报。检验和就是按照这个临时的UDP用户数据报来计算的。伪首部既不向下传送也不向上递交，而仅仅是为了计算检验和，防止报文被意外地交付到错误的目的地。</p><p>UDP计算检验和的方法和计算IP数据报首部检验和的方法相似。但不同的是：IP数据报的检验和只检验IP数据报的首部，但UDP的检验和是把首部和数据部分一起都检验。在发送方，首先是先把全零放入检验和字段。再把伪首部及UDP用户数据报看成是由许多16位的子串接起来。若UDP用户数据报的数据部分不是偶数个字节，则要填入一个全零字节（但此字节不发送）。然后按二进制反码计算出这些16位字的和。将此和的二进制反码写入检验和字段后，发送这样的UDP用户数据报。在接收方，把收到的UDP用户数据报连同伪首部一起，按为二进制反码求这些16位字的和，当无差错时其结果全为1，否则就表明有差错出现，接收方就丢弃这个UDP用户数据报，也可以上交给应用层，但附上出现差错的警告。这种简单的差错检验方法的检错能力并不强，但它的好处是简单，处理起来较快。</p><p>伪首部的第三字段是全零，第四个字段是IP首部中的协议字段的值。对于UDP，此协议字段值为17，第五字段是UDP用户数据报的长度。这样的检验和，既检查了UDP用户数据报的源端口号，目的端口号及UDP用户数据报的数据部分，又检查了IP数据报的源IP地址和目的地址。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、UDP概述&quot;&gt;&lt;a href=&quot;#一、UDP概述&quot; class=&quot;headerlink&quot; title=&quot;一、UDP概述&quot;&gt;&lt;/a&gt;一、UDP概述&lt;/h2&gt;&lt;p&gt;用户数据报协议UDP只在IP数据报服务之上增加了有限的功能，这就是端口的功能（有了端口，运输层就能进
      
    
    </summary>
    
      <category term="计算机网络" scheme="http://wanqbin.xyz/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://wanqbin.xyz/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
      <category term="用户数据报协议" scheme="http://wanqbin.xyz/tags/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE/"/>
    
      <category term="UDP" scheme="http://wanqbin.xyz/tags/UDP/"/>
    
  </entry>
  
  <entry>
    <title>运输层概述</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E8%BF%90%E8%BE%93%E5%B1%82%E6%A6%82%E8%BF%B0/"/>
    <id>http://wanqbin.xyz/2019/11/19/运输层概述/</id>
    <published>2019-11-18T17:02:00.000Z</published>
    <updated>2019-11-18T17:02:42.294Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、进程之间的通信"><a href="#一、进程之间的通信" class="headerlink" title="一、进程之间的通信"></a>一、进程之间的通信</h2><p>从通信和信息处理的角度看，运输层向它上面的应用层提供端到端通信服务。它属于面向通信部分的最高层，同时也是用户功能中的最底层。当位于网络边缘部分的两台主机使用网络核心部分的功能进行端到端的通信时，只有主机的协议栈才有运输层，网络核心部分中的路由器在转发分组时都只用到了下三层的功能。</p><p>从IP层看，通信的两端是两个主机。IP数据报的首部明确地标志了这两个主机的IP地址。然而严格地讲，两个主机进行通信实际上就是两个主机中的应用程序互相通信。IP协议虽然能把分组送到目的主机，但是这个分组还停留在主机的网络层而没有交付给主机中的应用程序。从运输层的角度看，通信的真正端点并不是主机而是主机中的进程。因此从运输层来看，端到端的通信是应用进程之间的通信。</p><p>在一个主机中经常有多个应用进程同时分别和另一个主机中的多个应用进程通信。因此，运输层的一个很重要的功能就是复用和分用。这里的复用是指在发送方不同的应用进程都可以使用同一个运输层协议传送数据，而分用是指接收方的运输层在剥去报文的首部后能够把这些数据正确地交付到目的应用进程。</p><p>运输层提供应用进程之间的逻辑通信指的是，运输层之间的通信好像是沿水平方向的传送数据，但事实上这两个传输层之间并没有与一条水平方向的物理连接。</p><p>网络层和运输层有很大的区别：网络层是为主机之间提供逻辑通信，而运输层是为应用进程之间提供端到端的逻辑通信。</p><p>运输层向高层用户屏蔽了下面网络核心的细节，它使应用进程看见的就是好像在两个运输层实体之间有一条端到端的逻辑通信信道，但这条逻辑通信信道对上层的表现却因运输层使用的不同协议而有很大的差别。</p><p>当运输层采用面向连接的TCP协议时，尽管下面的网络是不可靠的，但这种逻辑通信信道就相当于一条全双工的可靠信道。但当运输层采用无连接的UDP协议时，这种逻辑通信信道仍然是一条不可靠信道。</p><p>在网络中，两个进程要进行通信，必须有一个进程要主动发起通信，而另一个进程要事先准备好接受通信请求，这就是客户——服务器通信模式。在术语客户——服务器通信模式中，客户和服务器都是进行通信的应用进程，客户是主动发起通信的进程，而服务器是被动接受通信请求的进程。</p><h2 id="二、因特网的运输层协议"><a href="#二、因特网的运输层协议" class="headerlink" title="二、因特网的运输层协议"></a>二、因特网的运输层协议</h2><p>我们知道，因特网的网络层为主机之间提供的逻辑通信服务是一种尽最大努力交付的数据报服务。也就是说，IP报文在传送过程中有可能出错、丢失或失序。对于像电子邮件、文件传输、万维网以及电子银行等很多应用，数据丢失可能会造成灾难性的后果。因此，需要运输层为这类应用提供可靠的数据传输服务。但对于实时的多媒体应用，如实时音/视频，它们能够承受一定程度的数据丢失。在这些多媒体应用1中，丢失少量的数据会对播放的质量产生一些小的影响，但不会造成致命的损伤。为实现可靠数据传输，运输层协议必须增加很多复杂得多机制，而这些机制非但不能为这些多媒体应用带来明显的好处，而且会带来一些不利因素。总之，单一的运输层服务很难满足所有应用的需求。</p><p>因特网为上层应用提供了两个不同的运输层协议，即：</p><ul><li>用户数据报协议UDP</li><li>传输控制协议TCP</li></ul><p>按照OSI的术语，两个对等运输实体在通信时传送的数据单元叫做运输协议数据单元。但在因特网中，根据使用的协议是TCP还是UDP，分别称为TCP报文段或UDP报文或用户数据报。</p><p>UDP在传送数据之前不需要先建立连接。接收方运输层在收到UDP报文后，不需要给出任何确认。虽然UDP不提供可靠交付，但在某些情况下UDP却是一种最有效的工作方式。</p><p>TCP则提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP不提供广播或多播服务。由于TCP要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多开销，如确认、流量控制、计时器及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。</p><h2 id="三、运输层的复用与分用"><a href="#三、运输层的复用与分用" class="headerlink" title="三、运输层的复用与分用"></a>三、运输层的复用与分用</h2><p>应用层所有的应用进程都可以通过运输层再传送到IP层，这就是复用。运输层从IP层收到数据后必须交付给指明的应用进程，这就是分用。运输层要能正确地将数据交付给指定应用继承，就必须给每个应用继承赋予一个明确的标志。在TCP/IP网络中，使用一种与操作系统无关的协议端口号来实现对通信的应用进程的标志。</p><p>端口是应用层与运输层之间接口的抽象，端口号是应用进程的运输层地址。为此，在运输协议数据单元的首部中必须包含两个字段：源端口号和目的端口号。当运输层收到IP层交上来的数据，就要根据其目的端口号来决定应当通过哪一个端口上交给目的应用进程。</p><p>对于不同的计算机，端口的具体实现方法可能有很大的差别，因为这取决于计算机的操作系统。因此端口的基本概念就是：应用层的源进程将报文发送给运输层的某个端口，而应用层的目的进程从端口接收报文。端口用一个16位端口号进行标志，但端口号只有本地意义。在因特网不同计算机中，相同的端口号是没有联系的，并且TCP和UDP端口号之间也没有必然联系。IP协议根据IP数据报中的协议字段定位要交付的运输层协议，而相应的运输层协议需要根据运输层协议数据单元中的目的端口号来确定要交付的引用进程。16位的端口号可以允许有65535个端口号，这个数目对于一个计算机来说是足够用的。</p><p>由此可见，两个计算机中的进程要相互通信，不仅要知道对方的IP地址，而且还要知道对方的端口号。我们知道应用进程间的通信采用的是客户——服务器通信模式，在应用层中的各种不同的服务器进程不断监听它们的端口，以便发现是否有某个客户进程要和它通信。客户在发起通信请求时，必须先找到对方服务器的IP地址和端口号，而服务器总是可以从接收到的报文中获得客户的IP地址和端口号。为此运输层的端口号供分为下面的3类。</p><ul><li>熟知端口，0~1023.这类端口由因特网赋号管理局负责分配给一些常用的应用程序固定使用，因而所有用户进程都知道。当一种新的应用程序出现时要获得一个熟知的端口，必须向因特网赋号管理局申请。</li><li>登记端口：1024~49151.这类端口因特网赋号管理局不分配也不控制，但可以在因特网赋号管理局注册登记，以防止重复使用。</li><li>动态端口：49152~65535.这类端口是留給客户进程选择作为临时端口。当客户进程发起通信前要先为自己选择一个未用的临时端口，通信结束后要释放该端口以便其他客户进程使用。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、进程之间的通信&quot;&gt;&lt;a href=&quot;#一、进程之间的通信&quot; class=&quot;headerlink&quot; title=&quot;一、进程之间的通信&quot;&gt;&lt;/a&gt;一、进程之间的通信&lt;/h2&gt;&lt;p&gt;从通信和信息处理的角度看，运输层向它上面的应用层提供端到端通信服务。它属于面向通信部
      
    
    </summary>
    
      <category term="计算机网络" scheme="http://wanqbin.xyz/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="http://wanqbin.xyz/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
      <category term="运输层" scheme="http://wanqbin.xyz/tags/%E8%BF%90%E8%BE%93%E5%B1%82/"/>
    
  </entry>
  
  <entry>
    <title>虚拟存储器</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8/"/>
    <id>http://wanqbin.xyz/2019/11/19/虚拟存储器/</id>
    <published>2019-11-18T17:00:00.000Z</published>
    <updated>2019-11-18T17:00:52.441Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、虚拟存储器概述"><a href="#一、虚拟存储器概述" class="headerlink" title="一、虚拟存储器概述"></a>一、虚拟存储器概述</h2><p>之前的各种存储器管理方式有一个共同的特点，即它们都要求将一个作业全部装入内存后方能运行，于是出现了下面两种情况：</p><ul><li>有的作业很大，其所要求的内存空间超过了内存总容量，作业不能全部被装入内存，致使该作业无法运行</li><li>有大量作业要求运行，但由于内存容量不足以容纳所有这些作业，只能将少数作业装入内存让它们先运行，而将其他大量的作业留在外存上等待。</li></ul><p>解决方法：</p><ul><li>从物理上增加内存容量</li><li>从逻辑上扩充内存容量，即虚拟存储技术</li></ul><ol><li><h3 id="常规存储管理方式的特征和局部性原理"><a href="#常规存储管理方式的特征和局部性原理" class="headerlink" title="常规存储管理方式的特征和局部性原理"></a>常规存储管理方式的特征和局部性原理</h3><ul><li><p>常规存储器管理方式的特征：</p><ul><li>一次性</li><li>驻留性</li></ul></li><li><p>局部性原理</p><p>程序在执行时将呈现出局部性规律，即在一个较短的时间内，程序的执行仅局限于某个部分，相应地，它所访问的存储空间也局限于某个区域。</p><ul><li>程序执行时，除了少部分的转移和过程调用指令外，大多数情况下是顺序执行的</li><li>过程调用将会使程序的执行轨迹由一部分区域转至另一部分区域</li><li>程序中存在许多循环结构，这些结构虽然由少数指令构成，但是它们将被多次执行</li><li>程序中还包括许多对数据结构方面的处理，如对数组进行操作，这些处理往往都局限于很小的范围内。</li></ul><p>局限性又表现在下述两个方面：</p><ul><li>时间局限性。产生原因是，在程序中存在着大量的循环操作</li><li>空间局限性。典型情况是程序的顺序执行</li></ul></li><li><p>虚拟存储器的基本工作情况</p><p>&emsp;&emsp;基于局部性原理可知，应用程序在运行之前没有·必要将之全部装入内存，而仅须将那些当前要运行的少数页面或段先装入内存便可运行，其余部分暂留在盘上。</p><p>&emsp;&emsp;程序在运行时，如果它所要访问的页（段）已调入内存，便可继续执行下去；但如果程序所要访问的页（段）尚未调入内存（称为缺页或缺段），便发出缺页（段）中断请求，此时OS将利用请求调页（段）功能将它们调入内存，以使进程能继续执行下去</p><p>&emsp;&emsp;如果此时内存已满，无法再装入新的页（段），OS还须再利用页（段）的置换功能，将内存中暂时不用的页（段）调至盘上，腾出足够的内存空间后，再将要访问的页（段）调入内存，使程序继续执行下去。这样，便可使一个大的用户程序在较小的内存空间中运行，也可在内存中同时装入更多的进程，使它们并发执行。</p></li></ul></li><li><h3 id="虚拟存储器的定义和特征"><a href="#虚拟存储器的定义和特征" class="headerlink" title="虚拟存储器的定义和特征"></a>虚拟存储器的定义和特征</h3><ul><li><p>虚拟存储器的定义</p><p>&emsp;&emsp;所谓虚拟存储器是指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统其逻辑容量由内存容量和外存容量之和决定，其运行速度接近于内存速度，而每位的成本又接近与外存。可见，虚拟存储技术是一种性能非常优越的存储器管理技术，故被广泛地应用于大、中、小型机器和微型机中。</p></li><li><p>虚拟存储器的特征</p><ul><li>多次性</li><li>对换性</li><li>虚拟性</li></ul><p>虚拟性是以多次性和对换性为基础的；而多次新和对换性显然又必须建立在离散分配的基础上。</p></li></ul></li><li><h3 id="虚拟存储器的实现方法"><a href="#虚拟存储器的实现方法" class="headerlink" title="虚拟存储器的实现方法"></a>虚拟存储器的实现方法</h3><p>&emsp;&emsp;虚拟存储器的实现，建立在离散分配存储管理方式的基础上。</p><ul><li><p>分页请求系统</p><p>分页请求系统是在分页系统的基础上增加了请求调页功能和页面置换功能所形成的页式虚拟存储系统。置换时以页面为单位。</p><ul><li><p>硬件支持</p><ul><li>请求分页的页表机制，它是在纯分页的页表机制上增加了若干项而形成的，作为请求分页的数据结构</li><li>缺页中断机构，每当用户程序要访问的页面尚未调入内存时，便产生一缺页中断，以请求OS将所缺页面调入内存</li><li>地址变换机构，它同样是在存分页地址变换机构的基础上发展形成的</li></ul></li><li><p>实现请求分页的软件</p><p>这里包括有用于实现请求调页的软件和实现页面置换的软件。它们在硬件的支持下，将程序正在运行时所需的页面调入内存，再将内存中暂时不用的页面从内存置换到磁盘上。</p></li></ul></li><li><p>请求分段系统</p><p>请求分段系统是在分段系统的基础上，增加了请求调段及分段置换功能后所形成的段式虚拟存储系统。置换时以段为单位进行的。</p><ul><li><p>硬件支持</p><ul><li>请求分段的段表机制。它是在纯分段的段表机制上增加了若干项而形成的，作为请求分段的数据结构</li><li>缺段中断机构。每当用户程序要访问的段尚未调入内存时，便产生一缺段中断，以请求OS将所缺的段调入内存</li><li>地址变换机构，它同样是在纯分段地址变换机构的基础上发展形成的。</li></ul></li><li><p>软件支持</p><p>包括有用于实现请求调段的软件和实现段置换的软件。</p></li></ul><p>目前，有不少虚拟存储器是建立在段页式系统基础上的，通过增加请求调页和页面置换功能形成了段页式虚拟存储器系统，而且把实现虚拟存储器所需支持的硬件集成在处理器芯片上。</p></li></ul></li></ol><h2 id="二、请求分页储存管理方式"><a href="#二、请求分页储存管理方式" class="headerlink" title="二、请求分页储存管理方式"></a>二、请求分页储存管理方式</h2><ol><li><h3 id="请求分页中的硬件支持"><a href="#请求分页中的硬件支持" class="headerlink" title="请求分页中的硬件支持"></a>请求分页中的硬件支持</h3><ul><li><p>请求页表机制</p><p>需要的主要数据结构是请求页表，其基本作用仍是将用户地址空间中的逻辑地址映射为内存空间中的物理地址。为了满足页面换进换出的需要，在请求页表中又增加了四个字段。这样，在请求分页系统这两个的每个页表应含有：</p><ul><li>页号</li><li>物理块号</li><li>状态位P，用于指示该页是否已调入内存</li><li>访问字段A，用于记录本页被访问的词素，或记录本页最近已有多长时间未被访问</li><li>修改位M，标识该页在调入内存后是否被修改过</li><li>外存地址，用于指出该页在外存上的地址，通常是物理块号</li></ul></li><li><p>缺页中断机构</p><p>在请求分页系统中，每当所要访问的页面不在内存时，便产生一缺页中断，请求OS将所缺页面调入内存。缺页中断作为中断，与一般的中断有很明显的区别：</p><ul><li>在指令执行期间产生和处理中断信号</li><li>一条指令在执行期间可能产生多次缺页中断</li></ul></li><li><p>地址变换机构</p><p>&emsp;&emsp;请求分页系统中的地址变换机构是在分页系统地址变换机构的基础上，为实现虚拟存储器，再增加一些功能所形成的，如产生和处理缺页中断，以及从内存中换出一页的功能等等。</p><p>&emsp;&emsp;在进行地址变换时，首先检索快表，试图从中找出所要访问的页。若找到，便修改页表项中的访问位，供置换算法选换出页面时参考。对于写指令，还须将修改位置成“1”，表示该页在调入内存后已被修改。然后利用页表项给出的物理块号和页内地址形成物理地址。地址变换过程到此结束。</p><p>&emsp;&emsp;如果在快表中未找到该页的页表项，则应到内存中去查找页表，再从找到的页表项中的状态位P来了解该页是否已调入内存。若该页已调入内存，这时应将该页的页表项写入快表。当快表已满时，则应先调出按某种算法所确定的页表项，然后再写入该页表项；若该页尚未调入内存，这时应产生缺页中断，请求OS从外存把该页调入内存。</p></li></ul></li><li><h3 id="请求分页中的内存分配"><a href="#请求分页中的内存分配" class="headerlink" title="请求分页中的内存分配"></a>请求分页中的内存分配</h3><p>在为进程分配内存时，将涉及到三个问题：第一，为保证进程能正常运行，所需要的最小物理块数的确定；第二，在为每个进程分配物理块时，应采取什么样的分配策略，即所分配的物理块是固定的，还是可变的；第三，为不同进程所分配的物理块数，是采取平均分配算法，还是根据进程的大小按比例分配。</p><ul><li><p>最小物理块数的确定</p><p>&emsp;&emsp;随着为每个进程所分配的物理块的减少，将使进程在执行中的缺页率上升，从而降低进程的执行速度。</p><p>&emsp;&emsp;最小物理块数是指能保证进程正常运行所需的最小物理块数，当系统为进程分配的物理块数少于此值时，进程将无法运行。</p><p>&emsp;&emsp;进程应获得的最少物理块树，与计算机的硬件结构有关，取决于指令的格式、功能和寻址方式。对于某些简单的机器，若是单地址指令，且采用直接寻址方式，则所需的最少物理块数为。其中，一块是用于存放指令的页面，一块这是用于存放数据的页面。如果该机器运行间接寻址，则至少要求有三个物理块。</p><p>&emsp;&emsp;在缺页中断结构要发生6次中断，那么，至少要为每个进程分配6个物理块，以装入6个页面。</p></li><li><p>内存分配策略</p><p>在请求分页系统中，可采取两种内存分配策略，即固定和可变分配策略。</p><p>在进行置换时，也可采取两种策略，即全局置换和局部置换。</p><ul><li>固定分配局部置换<ul><li>所谓固定分配，是指为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。</li><li>局部置换，是指如果进程在运行中发现缺页，则只能从分配给该进程的n个页面中选出一页换出，然后再调入一页，以保证分配给该进程的内存空间不变。</li><li>采用该策略时，为每个进程分配多少物理块是根据进程类型或根据程序员，程序管理员的建议来确定的</li><li>该策略的困难之处是：应为每个进程分配多少个物理块难以确定。5</li></ul></li><li>可变分配全局置换<ul><li>可变分配，是指事先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。</li><li>全局置换，是指如果进程在运行中发现缺页，则将OS所保留的空闲物理块取出一块分配给该进程，或者以所有进程的全部物理块为标的，选择一块换出，然后将所缺页面调入。</li><li>采用这种策略时，凡产生缺页的进程，都将获得新的物理块，仅当空闲物理块队列中的物理块用完时，OS才能从内存中选择一页调出。被选择调出的页可能是系统中任何一个进程中的页，因此这个被选中的进程拥有的物理块会减少，这将导致其缺页率增加。</li></ul></li><li>可变分配局部置换<ul><li>该策略同样是基于进程的类型或程序员的要求，为每一个进程分配一定数目的物理块，但当某进程发现缺页时，只允许从该进程在内存中的页面选择一页调出，这样就不会影响其他进程的运行。如果进程在运行中频繁发生缺页中断，则系统须再为该进程分配若干附加物理块，直至该进程的缺页率减少到适当程度为止。反之，若其他进程缺页率高，该进程缺页率低，会适当减少分配给该进程的物理块函数。</li></ul></li></ul></li><li><p>物理块分配算法</p><ul><li>平均分配算法<ul><li>将系统中所有可供分配的物理块平均分配给各个进程。</li><li>但是这种方式不公平，因为未考虑每个进程的页面数。</li></ul></li><li>按比例分配算法<ul><li>根据进程的大小按比例分配物理块。</li></ul></li><li>考虑优先权的分配算法<ul><li>一部分按比例分配给各个进程</li><li>另一部分根据各进程的优先权进行分配。重要的实时系统中，可能是完全按优先权为各个进程分配其物理块的。</li></ul></li></ul></li></ul></li><li><h3 id="页面调入策略"><a href="#页面调入策略" class="headerlink" title="页面调入策略"></a>页面调入策略</h3><p>为使进程能够正常运行，必须事先将要执行的那部分程序和数据所在的页面调入内存，现在的问题是：</p><p>（1）系统应该何时调入所需页面</p><p>（2）系统应从何处调入这些页面</p><p>（3）是如何进行调入的</p><ul><li><p>何时调入页面</p><ul><li>预调页策略<ul><li>以预测为基础的预调页策略，将那些预计在不久以后便会被访问的页面预先调入内存。目前，预调页的成功率仅为50%</li><li>首先可用于在第一将进程调入内存时，此时可将程序员指出的那些页先调入内存。其次是，在采用工作集的系统中，每个进程都具有一张表，表中记录有运行时的工作集，每当程序被调度运行时，将工作集中的所有页调入内存</li></ul></li><li>请求调页策略<ul><li>当进程在运行中需要访问某部分程序和数据时，如偶发现其所在的页面不在内存中，便立即提出请求，由OS将其所需页面调入内存。</li><li>该策略每次仅调入一页，效率低，系统的开销大</li></ul></li></ul></li><li><p>从何处调入页面</p><ul><li>系统拥有足够的对换区空间，这时可以全部从对换区调入所需页面，以提高调页速度。</li><li>系统缺少足够的对换区空间，这是凡是不会被修改的文件，都直接从文件区调入；而当换出这些页面时，由于它们未被修改，则不必再将它们重写到磁盘以后再调入时，仍从文件区直接调入。对于那些可能被修改的部分，在将它们换出时便须调到对换区，以后需要再从对换区调入</li><li>UNIX方式。由于与进程有关的文件都放在文件区，故凡是未运行过的页面，都应从文件区调入。而对于曾经运行过但又被换出的页面，由于是被放在对换区，因此在下次调入时应从对换区调入。由于UNIX系统允许页面共享，因此，某进程所请求的页面有可能已被其他进程调入内存，此时也就无需再从对换区调入。</li></ul></li><li><p>页面调入过程</p><p>&emsp;&emsp;每当程序所要访问的页面未在内存时，便向CPU发出一缺页中断，中断处理程序首先保留CPU环境，分析中断原因后转入缺页中断处理程序。</p><p>&emsp;&emsp;该程序通过查找页表得到该页在外存的物理块后，如果此时内存能容纳新页，则启动磁盘I/O，将所缺页面调入内存，然后修改页表。</p><p>&emsp;&emsp;如果内存已满，则须先按某种置换算法，从内存中选出一页准备换出：如果该页未被修改过，可不必将该页写回磁盘，并修改页表中的相应表项，置其存在位为“1”，并将此页表项写入快表。在缺页调入内存后，利用修改后的页表形成所要访问数据的物理地址，再去访问内存数据，整个页面的调入过程对于用户来说是透明的。</p></li><li><p>缺页率</p><p>在进程运行的过程中，访问页面成功的次数为S，访问页面失败的次数为F，则该进程总的页面访问次数为A=S+F,那么该进程在其运行过程中的缺页率即为：</p><p>​                f=$\frac{F}{A}$</p><p>通常，缺页率受到以下几个因素的影响：</p><ul><li>页面大小，页面划分越大，缺页率越低</li><li>进程所分配物理块数。分配的物理块数越多，缺页率越低</li><li>页面置换算法</li><li>程序固有特性：程序本身的编制方法对缺页中断次数有影响。根据程序执行的局部性原理，程序编制的局部化程度越高，相应地执行时的缺页程度越低。</li></ul></li></ul></li></ol><h2 id="三、页面置换算法"><a href="#三、页面置换算法" class="headerlink" title="三、页面置换算法"></a>三、页面置换算法</h2><p>通常，把选择换出页面的算法称为页面置换算法。置换算法的好好直接影响到系统的性能。</p><p>不适当的算法可能会导致进程发生“抖动”，即刚被换出的页很快又要被访问，需要将它重新调入，此时又需要再选一页调出；而此刚被调出的页很快又被访问，又须将它调入，如此频繁的更换页面，以致一个进程在运行中把大部分时间都花费在了页面置换工作上，我们称该进程发生了“抖动”。好的置换算法应具有较低的页面更换频率。</p><ol><li><h3 id="最佳置换算法"><a href="#最佳置换算法" class="headerlink" title="最佳置换算法"></a>最佳置换算法</h3><p>其选择的被淘汰的页面将使以后永不再使用的，或许是在最长时间内不再被访问的页面。采用最佳置换算法可以获得较低的缺页率，但是无法预知哪个页面是未来最长时间内不再被访问的，因而该算法无法实现。</p></li><li><h3 id="先进先出置换算法（FIFO"><a href="#先进先出置换算法（FIFO" class="headerlink" title="先进先出置换算法（FIFO)"></a>先进先出置换算法（FIFO)</h3><ul><li>总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰。该算法实现简单。</li><li>一个替换指针，指向最老的页面。</li><li>换页频率是最佳置换算法的两倍</li></ul></li><li><h3 id="最近最久未使用置换算法（LRU）"><a href="#最近最久未使用置换算法（LRU）" class="headerlink" title="最近最久未使用置换算法（LRU）"></a>最近最久未使用置换算法（LRU）</h3><ul><li>根据页面调入内存后的使用情况作出决策。</li><li>LRU置换算法是选择最近最久未使用的页面予以淘汰。该算法赋予每个页面一个访问了字段，用来记录一个页面自上次被访问以来经历的时间t。淘汰时i，选择了t最大的淘汰。</li><li>LRU的硬件支持<ul><li>寄存器</li><li>栈</li></ul></li></ul></li><li><h3 id="最少使用置换算法（LFU）"><a href="#最少使用置换算法（LFU）" class="headerlink" title="最少使用置换算法（LFU）"></a>最少使用置换算法（LFU）</h3><ul><li>在内存中为每个页面设置一个移位寄存器，用来记录该页面被访问的频率。选择在最近时期使用最少的页面作为淘汰值。</li><li>采用的是在较大时间间隔来记录对该页的访问</li><li>利用LRU中的硬件，可以实现LFU</li></ul></li><li><h3 id="Clock置换算法"><a href="#Clock置换算法" class="headerlink" title="Clock置换算法"></a>Clock置换算法</h3><ul><li><p>Clock算法是一种LRU近似算法</p></li><li><p>简单的Clock置换算法</p><ul><li>为每页设置一未访问位，再将内存中的所有页面都通过链接指针链接成一个循环队列。</li><li>当某页被访问时，其访问位置1。选择页面淘汰时，只需检查页的访问位，如果是0，换出，若为1，重新将其置0，暂不换出，给予该页面第二次驻留内存的机会。</li><li>再按照FIFO算法检查下一个页面。当检查到队列中最后一个页面时，若其访问位仍是1，则再返回到队首去检查第一个页面。</li><li>又称为最近未用算法（NRU）</li></ul></li><li><p>改进型Clock置换算法</p><ul><li><p>在这个算法中，除了要考虑页面的使用情况外，还须再增加一个因素——置换代价。这样，选择页面换出时，既要是未使用过的页面，又要是未秀爱过的页面。把同时满足这两个条件的页面作为首选淘汰的页面。</p></li><li><p>由访问位A和修改位M可以组合成下面四种类型的页面：</p><ul><li>A=0，M=0：表示该页最最近既没有被访问，也没有被修改，是最佳淘汰页</li><li>A=0，M=1：该页未被访问，已被修改，不是很好的淘汰页</li><li>A=1，M=0，该页已被访问，未被修改，很有可能再次被访问</li><li>A=1，M=1，被访问且被修改，该页可能再次被访问</li></ul><p>执行过程分为三步：</p><ul><li>从指针所指示的当前位置开始，扫描循环队列，寻找A=0且M=0的第一类页面，将所遇到的第一个页面作为选中的淘汰页。在第一次扫描期间不改变访问位A</li><li>第一步失败，开始第二轮扫描，寻找第二类页面，将所遇到的第一个该类页面作为淘汰页。在第二轮扫描期间，将所有扫描过的页面的访问位置0</li><li>第二步失败，将指针返回到最开始的位置，将所有的访问位置0，重复第一步。</li></ul><p>该算法比简单的Clock算法减少了I/O操作次数。但本身开销有所增加。</p></li></ul></li></ul></li><li><h3 id="页面缓冲算法"><a href="#页面缓冲算法" class="headerlink" title="页面缓冲算法"></a>页面缓冲算法</h3><ul><li>影响页面换进换出效率的若干因素<ul><li>页面置换算法</li><li>写回磁盘的速率</li><li>读入内存的频率</li></ul></li><li>页面缓冲算法PBA<ul><li>主要特点：<ul><li>显著降低了页面换进、换出的频率，使磁盘I/O数大为减少</li><li>由于换进换出的开销大幅度减小，才能使其采用一种较简单的置换策略，如FIFO算法，不需要特殊的硬件支持</li></ul></li><li>空闲页面链表<ul><li>实际上该链表是一个空闲物理块链表，是系统掌握的空闲物理块，用于分配给频繁发生缺页的进程，以降低缺页率</li><li>当这样的进程需要读入一个页面时，便可利用空闲物理块链表中的第一个物理块来装入该页</li><li>当有一个未被修改的页要换出时，实际上并不把它换出到外存，而是把它们所在的物理块挂在空闲链表的末尾。</li></ul></li><li>修改页面链表<ul><li>它是由已修改的页面所形成的链表</li><li>设置该链表的目的是为了减少已修改页面换出的次数</li><li>当该进程需要将一个已修改的页面换出时，系统并不立即将它换出到外存上，而是将它所在的物理块挂在修改页面链表的末尾。这样做的目的是：降低将已修改页面写回磁盘的频率，降低将磁盘内容读入内存的频率</li></ul></li></ul></li></ul></li><li><h3 id="访问内存的有效时间"><a href="#访问内存的有效时间" class="headerlink" title="访问内存的有效时间"></a>访问内存的有效时间</h3><ul><li>被访问页在内存中，且其对应的页表项在快表中<ul><li>查找快表时间λ，访问实际物理内存所需的时间t</li><li>EAT=λ+t</li></ul></li><li>被访问页在内存中，且其对应的页表项不在快表中<ul><li>查找快表的时间，修改快表的时间和访问实际物理地址的时间</li><li>EAT=λ+t+λ+t</li></ul></li><li>被访问页不在内存中<ul><li>查找快表的时间、查找页表的时间、处理缺页中断的时间（ε）、更新快表的时间、实际访问物理地址的时间</li><li>EAT=λ+t+ε+λ+t</li></ul></li></ul></li></ol><h2 id="四、“抖动”与工作集"><a href="#四、“抖动”与工作集" class="headerlink" title="四、“抖动”与工作集"></a>四、“抖动”与工作集</h2><ol><li><h3 id="多道程序度与“抖动”"><a href="#多道程序度与“抖动”" class="headerlink" title="多道程序度与“抖动”"></a>多道程序度与“抖动”</h3><ul><li>多道程序度与处理机的利用率<ul><li>由于虚拟存储器系统能从逻辑上扩大内存，这时，只需装入一个进程的部分程序和数据便可开始运行，故人们希望在系统中能运行更多的进程，即增加多道程序度，以提高处理机的利用率</li><li>进程数目增加，处理机利用率剧烈增加；进程再增加，处理机利用率加速下降趋于0，即发生抖动。</li></ul></li><li>产生“抖动”的原因<ul><li>根本原因是，同时在系统中运行的进程太多，由此分配给每一个进程的物理块太少，不能满足进程正常运行的基本要求，致使每个进程在运行时，频繁地出现缺页，必须请求系统将所缺的页面调入内存。</li><li>这会使得系统中排队等待页面调入/调出的进程数目增加，对磁盘的访问时间也随之急剧增加。</li><li>由于“抖动”的发生与系统为进程分配的物理块的多少有关，于是出现了“工作集”</li></ul></li></ul></li><li><h3 id="工作集"><a href="#工作集" class="headerlink" title="工作集"></a>工作集</h3><ul><li>工作集的基本概念<ul><li>基于程序运行时的局部性原理可知，程序在运行期间，对页面的访问时不均匀的，在一段时间内仅局限于较少的页面，在另一段时间内，可能仅局限于另一些较少的页面进行访问。这些页面被称为活跃页面。如果能够预知程序在某段时间间隔要访问哪些页面，并将它们调入内存，将会大大降低缺页率，从而显著地提高处理机的利用率</li></ul></li><li>工作集的定义<ul><li>所谓工作集，是指某段时间间隔A里，进程实际所要访问页面的集合。</li></ul></li></ul></li><li><h3 id="“抖动”的预防方法"><a href="#“抖动”的预防方法" class="headerlink" title="“抖动”的预防方法"></a>“抖动”的预防方法</h3><ul><li>采取局部置换策略<ul><li>在页面分配和置换中，如果采取的是可变分配方式，则为了预防发生“抖动”，可采取局部置换策略。根据这种策略，当某进程发生缺页时，只能在分配給自己的内存空间内进行置换，不允许从其他进程去获得新的物理块。</li><li>该策略将该进程“抖动”所造成的影响限制在较小的范围内。</li><li>该方法虽然简易可行，但效果不是很好，因为在某进程发生“抖动”后，它还会长期处在磁盘I/O的等待队列中，使队列的长度增加，这会延长其他进程缺页中断的处理时间。</li></ul></li><li>把工作集算法融入到处理机调度中<ul><li>在调度算法中融入了工作集算法，则在调度程序从外存调入作业之前，必须先检查每个进程在内存的主流页面是否足够多。如果都已足够多，此时便可以从外存调入新的作业，不会因新作业的调入而导致缺页率的增加，反之，如果有些进程的内存页面不足，则应首先为那些缺页率高的作业增加新的物理块，此时不再调入新的作业。</li></ul></li><li>利用“L=S”准则调节缺页率<ul><li>“L=S”的准则来调节多道程序度，L是缺页之间的平均时间，S是平均缺页服务时间，即用于置换一个页面所需的时间。</li><li>如果是L远大于S，说明很少发生缺页，磁盘的能力尚未得到充分的证明</li><li>如果L比S小，说明频繁发生缺页，缺页的速度已超过磁盘的处理能力</li><li>只有当L与S接近时，磁盘和处理机都可达到它们的最大利用率</li></ul></li><li>选择暂停的进程<ul><li>发生“抖动”，系统必须减少多道程序的数目</li><li>此时，应基于某种原则选择暂停某些当前活动的进程，将它们调出到磁盘上，以便腾出的内存空间分配给缺页率发生偏高的进程</li><li>通常采用与调度程序一致的策略，即首先选择暂停优先级最低的进程</li></ul></li></ul></li></ol><h2 id="五、请求分段存储管理方式"><a href="#五、请求分段存储管理方式" class="headerlink" title="五、请求分段存储管理方式"></a>五、请求分段存储管理方式</h2><p>分段基础上建立的请求分段式虚拟存储器系统，则是以分段为单位进行换入换出的。</p><ol><li><h3 id="请求分段中的硬件支持"><a href="#请求分段中的硬件支持" class="headerlink" title="请求分段中的硬件支持"></a>请求分段中的硬件支持</h3><p>所需的硬件支持有段表机制、缺段中断机构以及地址变换机构</p><ul><li>请求段表机制<ul><li>段名</li><li>段长</li><li>段基址</li><li>存取方式。由于应用程序中的段是信息的逻辑单位，可根据该信息的属性对它实施保护，故在段表中增加存取方式字段，如果该字段为两位，则存取属性是只执行、只读和允许读/写</li><li>访问字段A，记录该段是否被访问</li><li>修改位M，记录该页在进入内存后是否被修改</li><li>存在位P，指示该段是否已调入内存</li><li>增补位，请求分段式管理中所特有的字段，用于表示本段在运行过程中是否做过动态增长</li><li>外存始址，指示本段在外存中的起始地址，即起始盘号</li></ul></li><li>缺段中断机构<ul><li>在请求分段系统中采用的是请求段策略</li><li>所要访问的段未被调入内存时，由中断机构产生一缺段中断信号</li><li>缺段中断机构需要一条指令的执行期间产生执行和处理中断，以及在一条指令执行期间，可能产生多次缺段中断</li><li>由于分段是信息的逻辑单位，因而不可能出现一条指令被分割在两个分段中</li><li>由于段不是定长的，这使对缺段中断的处理比对缺页中断的处理复杂</li></ul></li><li>地址变换机构<ul><li>请求分段系统中的地址变换机构是在分段系统地址变换机构的基础上形成的。因为被访问的段并非全在内存，所以在地址变换后，若发现所要访问的段不在内存分钟，必须先将所缺的段调入内存，并修改段表，然后再利用段表进行地址变换。</li></ul></li></ul></li><li><h3 id="分段的共享与保护"><a href="#分段的共享与保护" class="headerlink" title="分段的共享与保护"></a>分段的共享与保护</h3><ul><li><p>共享段表</p><p>为了实现分段共享，可在系统中配置一张共享段表，所有歌共享段都在共享段表中占有一表项。在表项上记录了共享段的段号、段长、内存始址、状态存在位、外存始址以及共享计数信息。</p><ul><li>共享进程计数count。记录多少进程正在共享该段。系统示范该段时，首先检查count是否为0，为0才可以回收</li><li>存取控制字段。对于一个共享段，应为不同的进程矛不同的存取权限</li><li>段号，对于一个共享段，在不同的进程中可以具有不同的段号，每个进程可用自己进程的段号去访问该共享段。</li></ul></li><li><p>共享段的分配与回收</p><ul><li><p>共享段的分配</p><ul><li>在为共享段分配分配内存时，对第一个请求使用该共享段的进程，由内存分配方法有所不同。在为共享段分配内存时，对第一个请求使用该共享段的进程，由系统为该共享段分配一物理区，再把共享段调入该区，同时将该区的始址填入请求进程的段表的相应项中，还须再共享段表中增加以表项，填写请求使用该共享段的进程名、段号和存取控制等有关数据，把count置为1.</li><li>当又有其他进程需要调用该共享段时，由于该共享段已被调入内存，股此时无须再为该段分配内存，而只需在进程的段表中增加一表项，填写该共享段的物理地址。在共享段的段表中增加一个表项，填上调用进程的进程名、该共享段在本进程中的段号、存取控制等，再自行count=count+1操作，以表明有两个进程共享该段。</li></ul></li><li><p>共享段的回收</p><p>当共享此段的某进程不再需要该段时，应将该段释放，包括撤销在该进程段表中共享段对应的表项，以及执行count=count-1操作。若结果为0，该段由系统管理回收，以及取消在共享段表中该段所对应的表项，表明此时已没有进程使用该段；否则，只是取消调用者进程在共享段表中的有关记录。</p></li></ul></li><li><p>分段保护</p><ul><li><p>越界检查</p></li><li><p>存取控制检查</p><ul><li>只读</li><li>只执行</li><li>读/写</li></ul></li><li><p>环保护机构</p><p>低编号的环具有高优先级</p><ul><li>一个程序可以访问驻留在相同环或较低特权环（外环）的数据</li><li>一个程序可以调用驻留在相同环或高特权环（内环）中的服务</li></ul></li></ul></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、虚拟存储器概述&quot;&gt;&lt;a href=&quot;#一、虚拟存储器概述&quot; class=&quot;headerlink&quot; title=&quot;一、虚拟存储器概述&quot;&gt;&lt;/a&gt;一、虚拟存储器概述&lt;/h2&gt;&lt;p&gt;之前的各种存储器管理方式有一个共同的特点，即它们都要求将一个作业全部装入内存后方能运
      
    
    </summary>
    
      <category term="操作系统" scheme="http://wanqbin.xyz/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="操作系统" scheme="http://wanqbin.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="虚拟存储器" scheme="http://wanqbin.xyz/tags/%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>存储器管理</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E5%AD%98%E5%82%A8%E5%99%A8%E7%AE%A1%E7%90%86/"/>
    <id>http://wanqbin.xyz/2019/11/19/存储器管理/</id>
    <published>2019-11-18T16:58:00.000Z</published>
    <updated>2019-11-18T16:58:49.897Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、存储器的层次结构"><a href="#一、存储器的层次结构" class="headerlink" title="一、存储器的层次结构"></a>一、存储器的层次结构</h2><ul><li>存储器的多层结构<ul><li>最高层：CPU寄存器</li><li>中间：主存<ul><li>高速缓存</li><li>主存储器</li><li>磁盘缓存</li></ul></li><li>底层：辅存<ul><li>固定磁盘</li><li>可移动存储介质</li></ul></li></ul></li></ul><h2 id="二、连续分配存储管理方式"><a href="#二、连续分配存储管理方式" class="headerlink" title="二、连续分配存储管理方式"></a>二、连续分配存储管理方式</h2><ol><li><p>单一连续分配</p><p>&emsp;&emsp;在单道程序环境下，当时的存储器管理方式是把内存分为系统区和用户区两部分，系统区仅提供给OS使用，它通常是放在内存的低址部分。而在用户区内存中，仅装有一道用户程序，即整个内存的用户空间由该程序独占。这样的存储器分配方式被称为单一连续分配方式。</p></li><li><p>固定分区分配</p><p>&emsp;&emsp;为了能在内存中装入多道程序，且使这些程序之间又不会发生相互干扰，于是将整个用户空间划分为若干个固定大小的区域，使每个分区中只装入一道作业，这样就形成了最早的、也是最简单的一种可运行多道程序的分区式存储管理方式。如果在内存中有四个用户分区，便允许四个程序并发执行。当有一个空闲分区时，便可以再从外存的后备作业队列中选择一个适当大小的作业，装入该分区。当作业结束时，又可再从后备队列中找出另一作业调入该分区。</p></li><li><p>动态分区分配</p><ul><li><p>动态分区分配又称为可变分区分配，它是根据进程的实际需要，动态地为之分配内存空间。</p></li><li><p>动态分区分配中的数据结构</p><ul><li>空闲分区表</li><li>空闲分区链</li></ul></li><li><p>动态分区分配算法</p><p>为把一个新作业装入内存，须按照一定的分配算法，从空闲分区表或空闲分区链中选出一分区分配给该作业。</p></li><li><p>分区分配操作</p><ul><li>分配内存<ul><li>系统应利用某种分配算法，从空闲分区链（表）中找到所需大小的分区。</li></ul></li><li>回收内存<ul><li>当进程运行完毕释放内存时，系统根据回收区的首址，从空闲区链（表）中找到相应的插入点，此时可能出现以下四种情况之一：<ul><li>回收区与插入点的前一个空闲分区$F_1$相邻接。此时应将回收区与插入带来的前一分区合并，不必为回收分区分配新表项，而只修改其前一分区$F_1$的大小</li><li>回收分区与插入点的后一空闲分区$F_2$相邻接。此时也可将两分区合并，形成新的空闲分区，但用回收区的首址作为新空闲区的首址，大小为两者之和。</li><li>回收区同时与插入点的前、后两个分区邻接。此时将三个分区合并，使用$F_1$的表项和$F_1$的首址，取消$F_2$的表项，大小为三者之和。</li><li>回收区既不与$F_1$邻接，又不与$F_2$邻接。这时应为回收区单独建立一个新表项，填写回收区的首址和大小，并根据其首址插入到空闲链中的适当位置。</li></ul></li></ul></li></ul></li></ul></li><li><p>基于顺序搜索的动态分区分配算法</p><ul><li><p>首次适应算法（FF)</p><p>&emsp;&emsp;FF算法要求空闲分区链以地址递增的次序链接。在分配内存时，从链首开始顺序查找，直至找到一个大小能满足要求的空闲分区为止。然后再按照作业的大小，从该分区中划出一块内存空间，分配给请求者，余下的空闲分区仍留在空闲链中。若从链表直至链尾都不能找到一个能满足要求的分区，则表明系统中没有足够大的内存分配给该进程，内存分配失败，返回。</p></li><li><p>循环首次适应算法(NF)</p><p>&emsp;&emsp;为避免低址部分留下许多很小的空闲分区，以减少查找可用空闲分区的开销，循环首次适应算法在为进程分配内存空闲时，不再是每次都从链首开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找，直至找到一个能满足要求的空闲分区，从中划出一块与请求大小相等的内存空闲分配给作业。</p></li><li><p>最佳适应算法(BF)</p><p>&emsp;&emsp;所谓“最佳”是指，每次为作业分配内存时，总能把满足要求，又是最小的空闲分区分配给作业，避免“大材小用”。为了加速寻找，该算法要求将所有的空闲分区按其容量从小到大的顺序形成一空闲分区链。</p></li><li><p>最坏适应算法(WF)</p><p>&emsp;&emsp;由于最坏适应分配算法选择空闲分区的策略正好与最佳适应算法相反：它在扫描整个空闲分区表或链表时，总是他挑选一个最大的空闲区，从中分割一部分存储空间给作业使用，以至于存储器中缺乏大的空闲分区，故把它称为是最坏适应算法。</p></li></ul></li><li><p>基于索引搜索的动态分区分配算法</p><p>&emsp;&emsp;基于顺序搜索的动态分区分配算法，比较适用于不太大的系统。当系统很大时，系统中的内存分区可能会很多，相应的空闲分区链就可能很长，这时采用顺序搜索分区方法可能会很慢。为了提高搜索空闲分区的速度，在大、中型系统中往往会采用基于索引搜索的动态分区算法。</p><ul><li><p>快速适应算法</p><p>&emsp;&emsp;该算法又称为分类搜索法，是将空闲分区根据其容量大小进行分类，对于每一类具有相同容量的所有空闲分区，单独设立一个空闲分区链表，这样系统中存在多个空闲分区链表。同时，在内存中设立一张管理索引表，其中的每一个索引表项对应了一种空闲分区类型，并记录了该类型空闲分区链表表头的指针。空闲分区的分类是根据进程常用的空间大小进行划分的。</p></li><li><p>伙伴系统</p><p>&emsp;&emsp;该算法规定，无论已分配分区或空闲分区，其大小均为2的k次幂。通常$2^m$是整个可分配内存的大小。假设系统的可利用空间容量为$2^m$个字，则系统开始运行时，整个内存区是一个大小为$2^m$的空闲分区。在系统运行过程中，由于不断地划分，将会形成若干个不连续的空闲分区，将这些空闲分区按分区的大小进行分类。对于具有相同大小的所有空闲分区，单独设立一个空闲分区双向链表，这样，不同大小的空闲分区形成了k个空闲分区链表。</p><p>&emsp;&emsp;当需要为进程分配一个长度为n的存储空间时，首先计算一个i值，使$2^{i-1}$&lt;n&lt;=$2^i$,然后再空闲分区大小为$2^i$的空闲分区链表中查找。若找到，即把该空闲分区分配给进程。否则，表明长度为$2^i$的空闲分区已经耗尽，则在分区大小为$2^{i+1}$的空闲分区链表中寻找。若存在$2^{i+1}$的空闲分区，则把该空闲分区分为相等的两个分区，这两个分区称为一对伙伴，其中的一个分区用于分配，而把另一个加入分区大小为$2^i$的空闲分区链表中。</p><p>&emsp;&emsp;若大小为$2^{i+1}$的空闲分区也不存在，则需要查找大小为$2^{i+2}$的空闲分区，若找到则也对其进行两次分割：第一次，将其分割为大小为$2^{i+1}$的两个分区，一个用于分配，一个加入到大小为$2^{i+1}$的空闲分区链表中；第二次，将第一次用于分配的空闲区分割为$2^i$的两个分区，一个用于分配，另一个加入到大小为$2^i$的空闲链表中。若找不到，则继续查找大小为$2^{i+3}$的空闲分区，依次类推。由此可见，在最坏情况下，可能需要对$2^k$的空闲分区进行k次分割才能得到所需分区。</p><p>&emsp;&emsp;与一次分配可能要进行多次分割一样，一次回收也可能要进行多次合并，如回收大小为$2^i$的空闲分区时，若事先已存在$2^i$的空闲分区，则应将其伙伴分区合并为大小为$2^{i+1}$的空闲分区，若事先已存在$2^{i+1}$的空闲分区，又应继续与其伙伴分区合并为大小为$2^{i+1}$的空闲分区，依次类推。</p></li><li><p>哈希算法</p><p>&emsp;&emsp;哈希算法就是利用哈希快速查找的优点，以及空闲分区在可利用空闲区表中的分布规律，建立哈希函数，构造一张以空闲分区大小为关键字的哈希表，该表的每一表项记录了一个对应的空闲分区链表表头指针。</p><p>&emsp;&emsp;当进行空闲分区分配时，根据所需空闲分区大小，通过哈希函数计算，即得到在哈希表中的位置，从中得到相应的空闲分区链表，实现最佳分配策略。</p></li></ul></li></ol><h2 id="三、对换"><a href="#三、对换" class="headerlink" title="三、对换"></a>三、对换</h2><ol><li><p>对换的类型</p><p>&emsp;&emsp;在每次对换时，都是将一定数量的程序或数据换入或换出内存。根据每次对换时所对换的数量，可以将对换分为如下两类：</p><ul><li>整体对换</li><li>页面（分段）对换</li></ul></li><li><p>对换空间管理的主要目标</p><ul><li><p>对文件区管理的主要目标</p><p>&emsp;&emsp;文件区占用磁盘空间的大部分，用于存放各类文件。由于通常的文件都是较长时间地驻留在外存上，对它访问的频率是较低的，故对文件区管理的主要目标是提高文件存储空间的利用率，然后才是提高对文件的访问速度。因此，对文件区空间的管理采取离散分配方式。</p></li><li><p>对对换空间管理的主要目标</p><p>&emsp;&emsp;对换空间只占用磁盘空间的小部分，用于存放从内存换出的进程。由于这些进程在对换区中驻留的时间是短暂的，而对换操作的频率却较高，故对对换空间管理的主要目标，是提高进程换入和换出的速度，然后才是提高文件存储空间管理的利用率。为此，对对换空间的管理采取连续分配方式，较少考虑外存中的碎片问题。</p></li></ul></li><li><p>对换区空闲盘块管理中的数据结构</p><p>&emsp;&emsp;为了实现对对换区中的空闲盘块的管理，在系统中配置相应的数据结构，用于记录外存对换区中的空闲盘块的使用情况。其数据结构的形式与内存在动态分区分配方式中所用数据结构相似，即同样可以用空闲分区表或空闲分区链。在空闲分区表的每个表目中，应包含两项：对换区的首址及其大小，分别用盘块号和盘快速表示。</p></li><li><p>对换空间的分配与回收</p><ul><li>分配算法可以是首次适应算法、循环首次适应算法、最佳适应算法等</li><li>回收操作分为四种情况：<ul><li>回收分区与插入点的前一空闲分区$F_1$相邻接</li><li>回收分区与插入点的后一个空闲分区$F_2$相邻接</li><li>回收分区同时与插入点的前、后两个分区邻接</li><li>回收分区既不与$F_1$邻接，又不与$F_2$邻接</li></ul></li></ul></li><li><p>进程的换出</p><p>&emsp;&emsp;对换进程在实现进程换出时，是将内存中的某些进程调出至对换区，以便腾出内存空间。换出过程可分为以下两步：</p><ul><li>选择被换出的进程</li><li>进程换出过程<ul><li>申请对换空间，若申请成功，就启动磁盘，将该进程的程序和数据传送到磁盘的对换区上。</li><li>若传送过程未出现错误，便可回收该进程所占用的内存空间，并对该进程的进程控制块和内存分配表等数据结构做相应的修改。</li><li>若此时内存中海油可换出的进程，则继续执行换出过程，直到内存中再无阻塞进程为止。</li></ul></li></ul></li><li><p>进程的换入</p><p>&emsp;&emsp;对换进程将定时执行换入操作，它首先查看PCB集合中所有进程的状态，从中找出“就绪”状态但已换出的进程。当有许多这样的进程时，它将选择其中已换出到磁盘上时间最久的进程作为换入进程，为它申请内存。如果申请成功，可直接将进程从外存调入内存；如果失败，则需先将内存中的某些进程换出，腾出足够的内存空间后，再将进程调入。</p><p>&emsp;&emsp;在对换进程成功地换入一个进程后，若还有可换入的进程，则再继续执行换入换出过程，将其余处于“就绪且换出”状态的进程陆续换入，直到外存中再无“就绪且换出”状态的进程为止，或者已无足够的内存来换入进程，此时对换进程才停止换入。</p></li></ol><h2 id="四、分页存储管理方式"><a href="#四、分页存储管理方式" class="headerlink" title="四、分页存储管理方式"></a>四、分页存储管理方式</h2><ol><li><p>分页存储管理的基本方法</p><ul><li><p>页面和物理块</p><ul><li>页面。分页存储管理将进程的逻辑地址空间分成若干页，并为各页加以编号。相应地，也把内存的物理地址空间分成若干个块，同样也为它们加以编号。在为进程分配内存时，以块为单位，将进程中的若干个页分别装入到多个可以不相邻接的物理块中。由于进程的最后一页经常装不满一块，而形成了不可利用的碎片，称之为“页内碎片”。</li><li>页面大小。页面的大小应选择适中，且页面大小应是2的幂，通常为1KB~8KB。</li></ul></li><li><p>地址结构</p><p>分页地址中的地址结构如下:</p><p>它包含两部分内容：前一部分为页号P，后一部分为位偏移量W，即页内地址。</p></li><li><p>页表</p><ul><li>在分页系统中，允许将进程的各个页离散地存储在内存的任一物理块中，为保证进程仍然能够正确地运行，即能在内存中找到每个页面所对应的物理块，系统又为每个进程建立了一张页面映像表，简称页表。</li></ul></li></ul></li><li><p>地址变换机构</p><p>&emsp;&emsp;为了能将用户空间中的逻辑地址转换为内存空间中的物理地址，在系统中必须设置地址变换机构。该机构的基本任务是实现从逻辑地址到物理地址的转换。由于页内地址和物理地址是一一对应的，因此，地址变换结构的任务实际上只是将逻辑地址中的页号转换为内存中的物理块号。又因为页面映射表的作用就是用于实现从页号到物理块号的变换，因此，地址变换任务是借助页表来完成的。</p></li><li><p>两级页表</p><ul><li>针对难于找到大的连续的内存空间来存放页表的问题，可利用将页表进行分页的方法，使每个页面的大小与内存物理块的大小相同，并为它们进行编号，然后离散地将各个页面分别存放在不同的物理块中。</li><li>同样，也要为离散分配的页表再建立一张页表，称为外层页表，在每个页表项中记录了页表页面的物理块号。</li></ul></li><li><p>反置页表</p><p>&emsp;&emsp;为了减少页表占用的内存空间，引入了反置页表。一般页表的页表项是按页号进行排序的，页表项中的内容是物理块号。而反置页表则是为每个物理块设置一个页表项，并将它们按物理块的编号排序，其中的内容则是页号和其所隶属进程的标识符。</p></li></ol><h2 id="五、分段存储管理方式"><a href="#五、分段存储管理方式" class="headerlink" title="五、分段存储管理方式"></a>五、分段存储管理方式</h2><ol><li><p>分段系统的基本原理</p><p>&emsp;&emsp;在分段存储管理方式中，作业的地址空间被划分为若干个段，每个段定义了一组逻辑信息。为了简单起见，通常可用一个段号来代替段名，每个段都从0开始编址，并采用一段连续的地址空间。段的长度由相应的逻辑信息组的长度决定，因此各段的长度并不相等。整个作业的地址空间由于被分成多个段，所以呈现出二维特性，即每个段既包含了一部分地址空间，又表示了逻辑关系。其逻辑地址由段号和段内地址组成。</p></li></ol><h2 id="六、段页式存储管理方式"><a href="#六、段页式存储管理方式" class="headerlink" title="六、段页式存储管理方式"></a>六、段页式存储管理方式</h2><ol><li><p>基本原理</p><p>&emsp;&emsp;段页式系统的基本原理是分段和分页原理的结合，即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。在段页式系统中，其地址结构由段号、段内页号及页内地址三部分组成。</p></li><li><p>地址变换过程</p><p>&emsp;&emsp;在段页式系统中，为了便于实现地址变换，需配置一个段表寄存器，其中存放段表始址和段长TL。进行地址变换时，首先利用段号S，将它与段长TL进行比较。若S&lt;TL,表示未越界，于是利用段表始址和段号来求出该段所对应的段表项在段表中的位置，从中得到该段的页表始址，并利用逻辑地址中的段内页号P来获得对应页的页表项位置，从中读出该页所在的物理块号b，再利用块号b和页内地址来构成物理地址。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、存储器的层次结构&quot;&gt;&lt;a href=&quot;#一、存储器的层次结构&quot; class=&quot;headerlink&quot; title=&quot;一、存储器的层次结构&quot;&gt;&lt;/a&gt;一、存储器的层次结构&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;存储器的多层结构&lt;ul&gt;
&lt;li&gt;最高层：CPU寄存器&lt;/li&gt;
      
    
    </summary>
    
      <category term="操作系统" scheme="http://wanqbin.xyz/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="存储器管理" scheme="http://wanqbin.xyz/tags/%E5%AD%98%E5%82%A8%E5%99%A8%E7%AE%A1%E7%90%86/"/>
    
      <category term="分段存储" scheme="http://wanqbin.xyz/tags/%E5%88%86%E6%AE%B5%E5%AD%98%E5%82%A8/"/>
    
      <category term="分页存储" scheme="http://wanqbin.xyz/tags/%E5%88%86%E9%A1%B5%E5%AD%98%E5%82%A8/"/>
    
      <category term="段页式存储" scheme="http://wanqbin.xyz/tags/%E6%AE%B5%E9%A1%B5%E5%BC%8F%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>死锁</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E6%AD%BB%E9%94%81/"/>
    <id>http://wanqbin.xyz/2019/11/19/死锁/</id>
    <published>2019-11-18T16:57:00.000Z</published>
    <updated>2019-11-18T16:58:00.437Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、资源问题"><a href="#一、资源问题" class="headerlink" title="一、资源问题"></a>一、资源问题</h2><ul><li><p>可重用性资源和消耗性资源</p><ul><li><p>可重用性资源</p><p>一种可供用户重复使用多次的资源</p></li><li><p>消耗性资源</p><p>又称为临时性资源，它是在进程运行期间，由进程动态地创建和消耗的。</p></li></ul></li><li><p>可抢占性资源和不可抢占资源</p><ul><li><p>可抢占性资源</p><p>是指某进程在获得这类资源后，该资源可以再被其他进程或系统抢占。</p></li><li><p>不可抢占性资源</p><p>一旦系统把某资源分配给进程后，就不能将它强行收回，只能在进程用完后自行释放。</p></li></ul></li></ul><h2 id="二、计算机系统中的死锁"><a href="#二、计算机系统中的死锁" class="headerlink" title="二、计算机系统中的死锁"></a>二、计算机系统中的死锁</h2><ul><li>竞争不可抢占性资源引起死锁</li><li>竞争可消耗性资源引起死锁</li><li>进程推进顺序不当引起死锁</li></ul><h2 id="三、死锁的定义、必要条件和处理方法"><a href="#三、死锁的定义、必要条件和处理方法" class="headerlink" title="三、死锁的定义、必要条件和处理方法"></a>三、死锁的定义、必要条件和处理方法</h2><ul><li><p>死锁的定义</p><p>如果一组进程中的每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么这组进程是死锁的。</p></li><li><p>产生死锁的必要条件</p><ul><li>互斥条件</li><li>请求和保持条件</li><li>不可抢占条件</li><li>循环等待条件</li></ul></li><li><p>处理死锁的方法</p><ul><li>预防死锁</li><li>避免死锁</li><li>检测死锁</li><li>解除死锁</li></ul></li></ul><h2 id="四、预防死锁"><a href="#四、预防死锁" class="headerlink" title="四、预防死锁"></a>四、预防死锁</h2><ul><li>破坏“请求和保持条件”<ul><li>所有进程在开始运行之前，必须一次性地申请其在整个运行过程中所需的全部资源</li><li>允许一个进程只获得运行初期所需的全部资源后，便开始运行</li></ul></li><li>破坏“不可抢占条件”<ul><li>当一个已经保持了某些不可被抢占资源的进程，提出新的资源请求而不能得到满足时，它必须释放已经保持的所有资源，待以后需要时再从新申请。</li></ul></li><li>破坏“循环等待条件”<ul><li>对系统所有资源类型进行线性排序，并赋予不同的序号。规定每个进程必须按序号递增的顺序请求资源。</li></ul></li></ul><h2 id="五、避免死锁"><a href="#五、避免死锁" class="headerlink" title="五、避免死锁"></a>五、避免死锁</h2><ul><li><p>系统安全状态</p><p>&emsp;&emsp;在死锁避免方法中，把系统的状态分为安全状态和不安全状态。当系统处于安全状态时，可避免发生死锁。反之，当系统处于不安全状态时，则可能进入到死锁状态。</p><ul><li><p>安全状态</p><p>&emsp;&emsp;在该方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次资源分配的安全性。若此次分配不会导致系统进入不安全状态，才可将资源分配给进程，否则，令进程等待。</p><p>&emsp;&emsp;所谓安全状态，是指系统能按某种进程推进顺序为每个进程$P_i$分配其所需资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利地完成，此时称($P_1$、$P_2$、……、$P_n$)为安全序列。</p><p>&emsp;&emsp;如果系统无法找到这样一个安全序列，则称系统处于不安全状态。虽然并非所有不安全状态都必然会转为死锁状态，但当系统进入不安全状态后，就有可能进入死锁状态。反之，只要系统处于安全状态，系统便不会进入死锁状态。因此，避免死锁的实质在于，系统在进行资源分配时，应使系统不进入不安全状态。</p></li></ul></li><li><p>利用银行家算法避免死锁</p><ul><li>为实现银行家算法，每一个新进程在进入系统同时，它必须申明在运行过程中，可能需要每种资源类型的最大单元数目，其数目不应超过系统所拥有的资源总量。</li><li>当进程请求一组资源时，系统必须首先确定是否有足够的资源分配给该进程。若有，再进一步计算在将这些资源分配给进程后，是否会使系统处于不安全状态。如果不返回，才将资源分配给它，否则让进程等待。</li></ul></li></ul><h2 id="六、死锁的检测"><a href="#六、死锁的检测" class="headerlink" title="六、死锁的检测"></a>六、死锁的检测</h2><p>&emsp;&emsp;为了能对系统中是否已经发生了死锁进行检测，在系统中必须：①保存有关资源的请求和分配信息；②提供一种算法，它利用这些信息来检测系统是否已进入死锁状态。</p><ul><li>资源分配图</li><li>死锁定理<ul><li>S为死锁状态的充分条件为：当且仅当S状态的资源分配图是不可完全简化的。该充分条件被称为死锁定理。</li></ul></li></ul><h2 id="七、死锁的解除"><a href="#七、死锁的解除" class="headerlink" title="七、死锁的解除"></a>七、死锁的解除</h2><p>常采用解决死锁的两种方法是：</p><ul><li>抢占资源。从一个或多个进程中抢占足够数量的资源，分配给死锁进程，以解除死锁状态。</li><li>终止（或撤销）进程。终止（或撤销）系统中的一个或多个死锁进程，直至打破循环环路，使系统从死锁状态解脱出来。</li></ul><ol><li><p>终止进程的方法</p><ul><li><p>终止所有死锁进程</p><p>终止所有的死锁进程，死锁自然也就解除了，但所付出的代价可能会很大。</p></li><li><p>逐个终止进程</p><p>按某种顺序，逐个地终止进程，直至有足够的资源，以打破循环等待，把系统同从死锁状态解脱出来为止。</p><p>选择被终止进程时应考虑的若干因素：</p><ul><li>进程的优先级</li><li>进程已执行了多少时间，还需要多少时间方能完成？</li><li>进程在运行中已经使用资源的多少，以后还需要多少资源？</li><li>进程的性质是交互式的还是批处理式的？</li></ul></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、资源问题&quot;&gt;&lt;a href=&quot;#一、资源问题&quot; class=&quot;headerlink&quot; title=&quot;一、资源问题&quot;&gt;&lt;/a&gt;一、资源问题&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;可重用性资源和消耗性资源&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;可重用性资源&lt;/p&gt;
&lt;p&gt;一种
      
    
    </summary>
    
      <category term="操作系统" scheme="http://wanqbin.xyz/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="操作系统" scheme="http://wanqbin.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="死锁" scheme="http://wanqbin.xyz/tags/%E6%AD%BB%E9%94%81/"/>
    
  </entry>
  
  <entry>
    <title>处理机调度</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6/"/>
    <id>http://wanqbin.xyz/2019/11/19/处理机调度/</id>
    <published>2019-11-18T16:56:00.000Z</published>
    <updated>2019-11-18T16:57:19.022Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、处理机调度的层次和调度算法的目标"><a href="#一、处理机调度的层次和调度算法的目标" class="headerlink" title="一、处理机调度的层次和调度算法的目标"></a>一、处理机调度的层次和调度算法的目标</h2><p>&emsp;在多道程序系统中，调度的实质是一种资源分配，处理机调度是对处理机资源进行分配。处理机调度算法实质根据处理机分配策略所规定的处理机分配算法。在多道批处理系统中，一个作业从提交到获得处理机执行，直至作业运行完毕，可能需要经历多级处理机调度。</p><ol><li>处理机调度的层次<ul><li>高级调度：又称长程调度或作业调度，调度对象是作业</li><li>低级调度：又称进程调度或短程调度，调度对象是进程（或内核级线程）</li><li>中级调度：又称内存调度</li></ul></li><li>处理机调度算法的目标<ul><li>资源利用率</li><li>公平性</li><li>平衡性</li><li>策略强制执行</li></ul></li></ol><h2 id="二、作业与作业调度"><a href="#二、作业与作业调度" class="headerlink" title="二、作业与作业调度"></a>二、作业与作业调度</h2><p>&emsp;&emsp;在多道批处理系统中，作业是用户提交给系统的一项相对独立的工作。操作员把用户提交的作业通过相应的输入设备到磁盘存储器，并保存在一个后备作业队列中。再由作业调度程序将其从外存调入内存。</p><ol><li><p>批处理系统中的作业</p><ul><li><p>在批处理系统中，是以作业为基本单位从外存调入内存的</p></li><li><p>作业控制块JCB：包含的内容有，作业标识、用户名称、用户账号、作业类型、作业状态、调度信息、资源需求、资源使用情况等。</p></li><li><p>作业运行的三个阶段和三种状态</p><ul><li>收容阶段，对应后备状态</li><li>运行阶段，对应运行状态</li><li>完成阶段，对应完成状态</li></ul></li></ul></li><li><p>先来先服务调度算法（FCFS)</p><ul><li>系统按照作业到达的先后次序来进行调度，或者说它是优先考虑在系统中等待时间最长的作业，而不管作业所需执行时间的长短，从后备作业队列中选择几个最先进入该队列的作业，将它们调入内存，为它们分配资源和创建进程。然后把它放入就绪队列。</li></ul></li><li><p>短作业优先调度算法（SJF）</p><ul><li>由于在实际情况下，短作业占有很大比例，为了能使它们能比长作业优先执行，而产生了短作业优先调度算法。</li><li>SJF算法是以作业的长短来计算优先级，作业越短，其优先级越高。</li></ul></li><li><p>优先级调度算法（PSA）</p><ul><li>基于作业的紧迫程度，由外部赋予作业相应的优先级。调度算法是根据该优先级进行调度的。</li></ul></li><li><p>高响应比优先调度算法（HRRN）</p><ul><li><p>为每个作业引入一个动态优先级，即优先级是可以改变的，令它随等待时间延长而增加，这将使长作业的优先级在等待期间不断地增加，等到足够的时候后，必然有机会获得处理机。该优先级的变化规律可描述为：</p><p>优先权=$\frac{等待时间+要求服务时间}{要求服务时间}$</p></li><li><p>由于等待时间与服务时间之和就是系统对该作业的响应时间，故该优先级又相当于响应比$R_p$。据此，优先又可表示为：<br>$R_P$=$\frac{等待时间+要求服务时间}{要求服务时间}$=$\frac{响应时间}{要求服务时间}$</p></li></ul></li></ol><h2 id="三、进程调度"><a href="#三、进程调度" class="headerlink" title="三、进程调度"></a>三、进程调度</h2><ol><li><p>进程调度的任务</p><ul><li>保存处理机的现场信息</li><li>按某种算法选取进程</li><li>把处理机分配给进程</li></ul></li><li><p>进程调度的机制</p><ul><li>排队器</li><li>分派器</li><li>上下文切换器</li></ul></li><li><p>进程调度的方式</p><ul><li>非抢占方式</li><li>抢占方式<ul><li>优先权原则</li><li>短进程优先原则</li><li>时间片原则</li></ul></li></ul></li><li><p>轮转调度算法（RR）</p><p>&emsp;&emsp;在分时系统中，最简单的也是较常用的是基于时间片的轮转调度算法。该算法采取了非常公平的处理机分配方式，即让就绪队列上的每个进程每次仅运行一个时间片。如果就绪队列上有n个进程，则每个进程每次大约都可以获得$\frac{1}{n}$的处理机时间。</p><ul><li>轮转法的基本原理<ul><li>系统根据FCFS策略，将所有的就绪进程排成一个就绪队列，并可设置每个一定时间间隔即产生一次中断，激活系统中的进程调度程序，完成一次调度，将CPU分配给队首进程，令其自信。当该进程的时间片耗尽或运行完毕时，系统再次将CPU分配给新的队首进程。由此，可保证就绪队列中的所有进程在一个确定的时间段内，都能获得一次CPU执行。</li></ul></li><li>切换时机<ul><li>若一个时间片尚未用完，正在运行的进程便已完成，就立即激活调度程序，将它从就绪队列中删除，再调度就绪队列中队首的进程运行，并启动一个新的时间片。</li><li>在一个时间片用完时，计时器中断处理程序被激活。如果进程尚未运行完毕，调度程序将把它送往就绪队列的末尾。</li></ul></li><li>时间片大小的确定<ul><li>时间片的大小略大于一次典型的交互所需要的时间，使大多数交互式进程能在一个时间片内完成，从而获得很小的响应时间。</li></ul></li></ul></li><li><p>优先级调度算法</p><ul><li>优先级调度算法的类型<ul><li>非抢占式优先级调度算法</li><li>抢占式优先级调度算法</li></ul></li><li>优先级的类型<ul><li>静态优先级<ul><li>进程类型</li><li>进程对资源的需求</li><li>用户要求</li></ul></li><li>动态优先级</li></ul></li></ul></li><li><p>多队列调度算法</p><ul><li>将系统中的进程就绪队列从一个拆分为若干个，将不同类型或性质的进程固定分配在不同的就绪队列，不同的就绪队列采用不同的调度算法，一个就绪队列中的进程可以设置不同的优先级，不同的就绪队列本身也可以设置不同的优先级。</li></ul></li><li><p>多级反馈队列调度算法</p><ul><li>设置多个就绪队列。为每个队列赋予不同的优先级，第一个队列的优先级最高，依次递减。优先级越高，时间片越小。</li><li>每个队列采用FCFS算法</li><li>按队列优先级调度</li></ul></li><li><p>基于公平原则的调度算法</p><ul><li><p>保证调度算法</p><p>如果系统中有n个相同类型的进程同时运行，为公平起见，须保证每个进程都获得相同的处理机时间1/n。</p></li><li><p>公平分享调度算法</p><p>在该算法中，调度的公平性针对用户而言，使所有用户能获得相同的处理机时间，或所要求的时间比例。</p></li></ul></li></ol><h2 id="四、实时调度"><a href="#四、实时调度" class="headerlink" title="四、实时调度"></a>四、实时调度</h2><ol><li><p>实现实时调度的基本条件</p><ul><li>提供必要的信息<ul><li>就绪时间</li><li>开始截止时间和完成截止时间</li><li>处理时间</li><li>资源要求</li><li>优先级</li></ul></li><li>系统处理能力强</li><li>采用抢占式调度机制</li><li>具有快速切换机制<ul><li>对中断的快速响应能力</li><li>快速的任务分派能力</li></ul></li></ul></li><li><p>实时调度算法的分类</p><ul><li>非抢占式调度算法<ul><li>非抢占式轮转调度算法</li><li>非抢占式优先调度算法</li></ul></li><li>抢占式调度算法<ul><li>基于时钟中断的抢占式优先级调度算法</li><li>立即抢占的优先级调度算法</li></ul></li></ul></li><li><p>最早截止时间优先EDF算法</p><ul><li>该算法根据任务的截止时间确定任务的优先级，任务的截止时间越早，其优先级越高，具有最早截止时间的任务排在队列的队首。</li></ul></li><li><p>最低松弛度优先LLF算法</p><ul><li>该算法在确定任务的优先级时，根据的是任务的紧急（或松弛）程度。任务紧急程度越高，赋予该任务的优先级就越高，以使之优先执行。</li></ul></li><li><p>优先级倒置</p><ul><li><p>优先级倒置的形成</p><p>&emsp;&emsp;当前OS广泛采用优先级调度算法和抢占方式，然而在系统中存在着影响进程运行的资源而产生“优先级倒置”现象，即高优先级进程（或线程）被低优先级进程（或线程）延迟或阻塞。</p><p>&emsp;&emsp;例如，假如有三个完全独立的进程$P_1$、$P_2$和$P_3$，$P_1$的优先级最高，$P_2$次之，$P_3$最低。$P_1$和$P_3$通过共享一个临界资源进行交互。假如$P_3$最先执行，进入到临界区，在时刻a，当$P_2$就绪时，因为它比$P_3$的优先级高，$P_2$抢占了$P_3$的处理机而运行，在时刻b，$P_1$就绪，因为它比$P_2$的优先级高，$P_1$抢占了$P_2$的处理机而运行。在时刻c，$P_1$试图进入临界区，但因为相关的临界资源已被$P_3$占用，故$P_1$将被阻塞。由$P_2$继续运行，直到时刻d运行结束。然后由$P_3$接着运行，到时刻e时$P_3$退出临界区，并唤醒$P_1$。因为它比$P_3$的优先级高，故它抢占了$P_3$的处理机而运行。</p></li><li><p>优先级倒置的解决方法</p><ul><li>一种简单的解决办法是规定：加入进程$P_3$在进入临界区后$P_3$所占用的处理机就不允许被抢占。</li><li>一种比较实用的方法是在建立动态优先级继承基础上的。该方法规定，当高优先级进程$P_1$要进入临界区，去使用临界资源R，如果已有一个低优先级进程$P_3$正在使用该资源，此时一方面$P_1$被阻塞，另一方面由$P_3$继承$P_1$的优先级，并一直保持到$P_3$退出临界区。</li></ul></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、处理机调度的层次和调度算法的目标&quot;&gt;&lt;a href=&quot;#一、处理机调度的层次和调度算法的目标&quot; class=&quot;headerlink&quot; title=&quot;一、处理机调度的层次和调度算法的目标&quot;&gt;&lt;/a&gt;一、处理机调度的层次和调度算法的目标&lt;/h2&gt;&lt;p&gt;&amp;emsp;
      
    
    </summary>
    
      <category term="操作系统" scheme="http://wanqbin.xyz/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="进程调度" scheme="http://wanqbin.xyz/tags/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/"/>
    
      <category term="处理机调度" scheme="http://wanqbin.xyz/tags/%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>进程相关总结</title>
    <link href="http://wanqbin.xyz/2019/11/19/%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/"/>
    <id>http://wanqbin.xyz/2019/11/19/进程相关总结/</id>
    <published>2019-11-18T16:55:00.000Z</published>
    <updated>2019-11-18T16:55:57.877Z</updated>
    
    <content type="html"><![CDATA[<p>程序顺序执行的特征：</p><ul><li>顺序性</li><li>封闭性</li><li>可再现性</li></ul><p>程序并发执行的特征：</p><ul><li>间断性</li><li>失去封闭性</li><li>不可再现性</li></ul><h2 id="一、进程的描述"><a href="#一、进程的描述" class="headerlink" title="一、进程的描述"></a>一、进程的描述</h2><ol><li><p>进程的定义：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。</p></li><li><p>进程的特征：</p><ul><li>动态性</li><li>并发性</li><li>独立性</li><li>异步性</li></ul></li><li><p>进程的三种基本状态：</p><ul><li>就绪状态</li><li>执行状态</li><li>阻塞状态</li></ul></li><li><p>进程控制块PCB：PCB作为进程实体的一部分，记录了操作系统所需的，用于描述进程的当前情况以及管理进程运行的全部信息，是操作系统中最重要的记录型数据结构。</p></li><li><p>PCB的作用是使一个在多道程序环境下不能独立运行的程序（含数据）成为一个能独立运行的基本单位，一个能与其他进程并发执行的过程。</p><ul><li>作为独立运行基本单位的标志</li><li>能实现间断性运行方式</li><li>提供进程管理所需要的信息</li><li>提供进程调度所需要的信息</li><li>实现与其他进程的同步与通信</li></ul></li><li><p>PCB中的信息：</p><ul><li>进程描述符</li><li>处理机状态</li><li>进程调度信息</li><li>进程控制信息</li></ul></li></ol><h2 id="一、进程控制"><a href="#一、进程控制" class="headerlink" title="一、进程控制"></a>一、进程控制</h2><p>&emsp;&emsp;进程控制是进程管理中最基本的功能，主要包括创建新进程、终止已完成的进程、将因发生异常情况而无法继续运行的进程置于阻塞状态、负责进程运行中的状态转换等功能。</p><ol><li>操作系统内核的功能：<ul><li>支撑功能<ul><li>中断处理</li><li>时钟管理</li><li>原语操作</li></ul></li><li>资源管理功能<ul><li>进程管理</li><li>存储器管理</li><li>设备管理</li></ul></li></ul></li><li>引起创建进程的事件<ul><li>用户登录</li><li>作业调度</li><li>提供服务</li><li>应用请求</li></ul></li><li>进程的创建<ul><li>申请空白PCB</li><li>为新进程分配其运行所需的资源</li><li>初始化进程控制块PCB</li><li>如果进程就绪队列能够接纳新进程，便将新进程插入就绪队列</li></ul></li><li>引起进程终止的事件<ul><li>正常结束</li><li>异常结束<ul><li>越界错</li><li>保护错</li><li>非法指令</li><li>特权指令错</li><li>运行超时</li><li>等待超时</li><li>算术运算错</li></ul></li><li>外界干预<ul><li>操作员或操作系统干预</li><li>父进程请求</li><li>父进程终止</li></ul></li></ul></li><li>进程的终止过程<ul><li>根据被终止进程的标识符，从PCB集合中检索出该进程的PCB，从中读出该进程的状态</li><li>若被终止进程正处于执行状态，应立即终止该进程的执行，并置调度标志为真，用于指示该进程被终止后应重新进行调度</li><li>若该进程还有子孙进程，还应将其所有子孙进程也都予以终止，以防它们成为不可控进程</li><li>将被终止进程所拥有的全部资源或者归还给其父进程，或者归还给系统</li><li>将被终止进程从所在队列中移出，等待其他程序来搜集信息</li></ul></li><li>引起进程阻塞和唤醒的事件<ul><li>向系统请求共享资源失败</li><li>等待某种操作的完成</li><li>新数据尚未到达</li><li>等待新任务的到达</li></ul></li></ol><h2 id="二、进程同步"><a href="#二、进程同步" class="headerlink" title="二、进程同步"></a>二、进程同步</h2><ul><li><p>临界区</p><p>&emsp;&emsp;通过对多线程的插混行化来访问公共资源或1一段代码，速度快，适合控制数据访问。</p><ul><li>优点：保证在某一时刻只有一个线程能访问数据的简便方法</li><li>缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程</li></ul></li><li><p>互斥量</p><p>&emsp;&emsp;为协调共同对一个共享资源的单独访问而设计的。互斥量和临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限</p><ul><li>优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享</li><li>缺点：<ul><li>互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部使用的话，使用临界区会带来速度上的优势并能够减少资源占用量，因为互斥量是跨继承的互斥量一旦被创建，就可以通过名字打开它</li><li>通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理。比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买1的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时如果利用互斥量就没办法完成这个要求，信号量对象可以说是一种资源计数器</li></ul></li></ul></li><li><p>信号量</p><p>&emsp;&emsp;为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。</p><ul><li>优点：适用于对Socket程序中线程的同步。</li><li>缺点：<ul><li>信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点</li><li>信号量机制功能强大，但使用时对信号量的操作分散，而且难以控制，读写和维护都很困难，加重了程序员的编码负担</li><li>核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。</li></ul></li></ul></li><li><p>事件</p><p>&emsp;&emsp;用来通知线程有一些事件已发生，从而启动后继任务的开始。</p><ul><li><p>优点：</p><p>事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。</p></li></ul></li></ul><h2 id="三、进程通信"><a href="#三、进程通信" class="headerlink" title="三、进程通信"></a>三、进程通信</h2><p>&emsp;&emsp;进程通信是指进程之间的信息交换。由于进程的互斥与同步，需要在进程交换一定的信息，故不少学者将它们也归为进程通信，但只能把它们称为低级进程通信。以信号量机制为例，它们低级的原因是：</p><ul><li>效率低</li><li>通信对用户不透明</li></ul><p>&emsp;&emsp;在进程之间要传送大量数据时，应当利用OS提供的高级通信工具，该工具最主要的特点是：</p><ul><li>使用方便</li><li>高效地传送大量数据</li></ul><p>进程通信的类型：</p><ul><li>共享存储器系统：相互通信的进程共享某些数据结构或共享存储区，进程之间能够通过这些空间进行通信。<ul><li>基于共享数据结构的通信方式</li><li>基于共享存储区的通信方式</li></ul></li><li>管道通信系统：所谓“管道”是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又名<code>pipe</code>文件。<ul><li>管道机制必须提供一下三方面的协调能力：<ul><li>互斥</li><li>同步</li><li>确定对方是否存在，只有确定了对方已存在时才能进行通信</li></ul></li></ul></li><li>消息传递系统：在该机制中，进程不必借助任何共享存储区或数据结构，而是以格式化的消息为单位，将通信的数据封装在消息中，并利用操作系统提供的一组通信命令，在进程间进行消息传递，完成进程间的数据交换。<ul><li>直接通信方式：是指发送进程利用OS所提供的原语，直接把消息发送给目标进程</li><li>间接通信方式：是指发送和接收进程，都通过共享中间实体的方式进行消息的发送和接收，完成进程间的通信</li></ul></li><li>客户机—服务器系统<ul><li>套接字</li><li>远程过程调用</li><li>远程方法调用</li></ul></li></ul><h2 id="四、线程"><a href="#四、线程" class="headerlink" title="四、线程"></a>四、线程</h2><p>&emsp;&emsp;如果说，在OS中引入进程的目的是为了使多个程序能并发执行，以提高资源利用率和系统吞吐量，那么，在操作系统中再引入线程，则是为了减少程序在并发执行时所付出的时空开销，使OS具有更好的并发性。</p><ol><li><p>线程运行的三种基本状态</p><ul><li>执行状态</li><li>就绪状态</li><li>阻塞状态</li></ul></li><li><p>线程控制块TCB：如同每个进程有一个进程控制块一样，系统也为每个线程配置了一个线程控制块TCB，将用于控制和管理线程的信息记录在线程控制块中。</p><ul><li>线程标识符</li><li>一组寄存器</li><li>线程运行状态</li><li>优先级</li><li>线程专有存储区</li><li>信号屏蔽</li><li>堆栈指针</li></ul></li><li><p>多线程OS中的进程属性</p><p>&emsp;&emsp;通常在多线程OS中的进程都包含了多个线程，并为它们提供资源。OS支持在一个进程中的多个线程能并发执行，但此时的进程就不再作为一个执行的实体。多线程OS中的进程有以下属性：</p><ul><li>进程是一个可拥有资源的基本单位</li><li>多个线程可并发执行</li><li>进程已不是可执行的实体</li></ul></li><li><p>线程的实现方式</p><ul><li><p>内核支持线程KST(Kernel Support Threads)</p><ul><li><p>优点：</p><ul><li>在多处理器系统中，内核能够同时调度同一进程中的多个线程并发执行</li><li>如果进程中的一个线程被阻塞了，内核可以调度该进程中的其他线程占有处理器运行，也可以运行其他进程中的线程</li><li>内核支持线程具有很小的数据结构和堆栈，线程的切换比较快，切换开销小</li><li>内核本身也可以采用多线程技术，可以提高系统的执行速度和效率</li></ul></li><li><p>缺点：</p><p>对于用户的线程切换而言，其模式切换的开销较大，在同一个进程中，从一个线程切换到另一个线程时，需要从用户态转到核心态进行，这是因为用户进程的线程在用户态运行，而线程调度和管理是在内核实现的，系统开销比较大。</p></li></ul></li><li><p>用户级线程ULT(User Level Threads)</p><ul><li>优点：<ul><li>线程切换不需要转换到内核空间</li><li>调度算法可以是进程专用的</li><li>用户级线程的实现与OS平台无关</li></ul></li><li>缺点：<ul><li>系统调用的阻塞问题</li><li>在单纯的用户级线程实现方式中，多线程应用不能利用多处理机进行多重处理的优点，内核每次分配给一个进程的仅有一个CPU，因此，进程中仅有一个线程能执行，在该线程放弃CPU之前，其他线程只能等待</li></ul></li></ul></li></ul></li><li><p>线程的创建和终止</p><ul><li><p>线程的创建</p><p>&emsp;&emsp;应用程序在启动时，通常仅有一个线程在执行，人们把线程称为“初始化线程”，它的主要功能是用于创建新进程。在创建新进程时，需要利用一个线程创建函数，并提供相应的参数，如指向线程主程序的入口指针、堆栈的大小，以及用于调度的优先级等。在线程的创建函数执行完后，将返回一个线程标识符供以后使用。</p></li><li><p>线程的终止</p><p>&emsp;&emsp;当一个线程完成了自己的任务后，或是线程在运行中出现异常情况而须被强行终止时，由终止线程通过调用相应的函数来对它执行终止操作。但有些线程，它们一旦被建立起来之后，便一直运行下去而不被终止。在大多数的OS中，线程被中止后并不立即释放它所占有的资源，只有当进程中的其他线程执行了分离函数后，被终止的线程才与资源分离，此时的资源才能被其他线程利用。</p><p>&emsp;&emsp;虽已被终止但尚未释放资源的线程仍可以被需要它的线程所调用，以使被终止线程重新恢复运行。为此，调用线程须调用一条被称为“等待线程终止”的连接命令来与该线程进行连接。如果在一个调用者线程调用“等待线程终止”的连接命令，试图与指定线程相连接时，若指定线程尚未被终止，则调用连接命令的线程将会阻塞，直至指定线程被终止后，才能实现它与调用者线程的连接并继续执行；若指定线程已被终止，则调用者线程不会被阻塞而是继续执行。</p></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;程序顺序执行的特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;顺序性&lt;/li&gt;
&lt;li&gt;封闭性&lt;/li&gt;
&lt;li&gt;可再现性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;程序并发执行的特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;间断性&lt;/li&gt;
&lt;li&gt;失去封闭性&lt;/li&gt;
&lt;li&gt;不可再现性&lt;/li&gt;
&lt;/ul&gt;
      
    
    </summary>
    
      <category term="操作系统" scheme="http://wanqbin.xyz/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="操作系统" scheme="http://wanqbin.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="进程" scheme="http://wanqbin.xyz/tags/%E8%BF%9B%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Git的基本操作</title>
    <link href="http://wanqbin.xyz/2019/11/19/Git%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
    <id>http://wanqbin.xyz/2019/11/19/Git的基本操作/</id>
    <published>2019-11-18T16:48:00.000Z</published>
    <updated>2019-11-18T16:53:22.208Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第一阶段-初始化"><a href="#第一阶段-初始化" class="headerlink" title="第一阶段:初始化"></a>第一阶段:初始化</h2><p>想要让git对一个目录进行版本控制需要以下步骤：</p><ul><li><p>进入要管理的文件夹</p></li><li><p>执行初始化命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure></li><li><p>管理目录下的文件状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br><span class="line"><span class="meta">#</span> 注：新增的文件和修改过后的文件都是红色</span><br></pre></td></tr></table></figure></li><li><p>管理指定文件（红变绿）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git add 文件名</span><br><span class="line">git add . #添加当前文件夹下的全部文件</span><br></pre></td></tr></table></figure></li><li><p>个人信息配置：用户名，邮箱【一次即可】</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.email "Your Email"</span><br><span class="line">git config --global user.name "Your Name"</span><br></pre></td></tr></table></figure></li><li><p>生成版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m '描述信息'</span><br></pre></td></tr></table></figure></li><li><p>查看版本记录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log</span><br></pre></td></tr></table></figure></li></ul><h2 id="第二阶段：扩展新功能"><a href="#第二阶段：扩展新功能" class="headerlink" title="第二阶段：扩展新功能"></a>第二阶段：扩展新功能</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commmit -m 'message'</span><br></pre></td></tr></table></figure><h2 id="第三阶段：回滚"><a href="#第三阶段：回滚" class="headerlink" title="第三阶段：回滚"></a>第三阶段：回滚</h2><ul><li><p>回滚至之前的版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git log</span><br><span class="line">git reset --hard 版本号</span><br></pre></td></tr></table></figure></li><li><p>回滚至之后的版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git reflog</span><br><span class="line">git reset --hard 版本号</span><br></pre></td></tr></table></figure></li></ul><h2 id="第四阶段：分支-amp-修改"><a href="#第四阶段：分支-amp-修改" class="headerlink" title="第四阶段：分支&amp;修改"></a>第四阶段：分支&amp;修改</h2><ul><li><p>分支</p><p>分支可以给使用者提供多个环境，意味着你可以把你的工作从开发主线上分离开来，以免影响开发主线</p></li><li><p>修改方案</p><p><img src="/2019/11/19/Git的基本操作/git分支.PNG" alt="git分支"></p></li><li><p>查看分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure></li><li><p>创建分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch 分支名</span><br></pre></td></tr></table></figure></li><li><p>切换分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout 分支名</span><br></pre></td></tr></table></figure></li><li><p>分支合并（可能产生冲突）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git merge 要合并的分支</span><br><span class="line"><span class="meta">#</span>注：切换分支再合并，</span><br></pre></td></tr></table></figure></li><li><p>删除分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -d 分支名称</span><br></pre></td></tr></table></figure></li></ul><h2 id="第五阶段：GitHub"><a href="#第五阶段：GitHub" class="headerlink" title="第五阶段：GitHub"></a>第五阶段：GitHub</h2><ul><li><p>在家里上传代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin 远程仓库地址   #给远程仓库起名字</span><br><span class="line">git push -u origin 分支  #推送代码</span><br></pre></td></tr></table></figure></li><li><p>到公司新电脑上第一次获取代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone #远程仓库地址</span><br><span class="line">git checkout 分支 #切换分支</span><br></pre></td></tr></table></figure></li><li><p>在公司进行开发</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git checkout dev  #切换到dev分支进行开发</span><br><span class="line">git merge master #把master分支合并到dev（仅一次）</span><br><span class="line"><span class="meta">#</span>修改代码</span><br><span class="line"><span class="meta">#</span>提交代码</span><br><span class="line">git add .</span><br><span class="line">git commit -m 'xxx'</span><br><span class="line">git push origin dev</span><br></pre></td></tr></table></figure></li><li><p>回家继续写代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>切换到dev分支进行开发</span><br><span class="line">git checkout dev</span><br><span class="line"><span class="meta">#</span>拉代码</span><br><span class="line">git pull origin dev</span><br><span class="line"><span class="meta">#</span>继续开发</span><br><span class="line"><span class="meta">#</span>提交代码</span><br><span class="line"></span><br><span class="line">git add .</span><br><span class="line">git commit -m 'xx'</span><br><span class="line">git push origin dev</span><br></pre></td></tr></table></figure></li><li><p>开发完毕，要上线</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>将dev分支合并到master，进行上线</span><br><span class="line">git checkout master</span><br><span class="line">git merge dev</span><br><span class="line">git push origin master</span><br><span class="line"><span class="meta">#</span>把dev分支也推送到远程</span><br><span class="line">git checkout dev</span><br><span class="line">git merge master</span><br><span class="line">git push origin dev</span><br></pre></td></tr></table></figure></li></ul>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git pull origin dev</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>等同于下面的两行代码</span><br><span class="line">git fetch origin dev</span><br><span class="line">git merget origin/dev</span><br></pre></td></tr></table></figure><ul><li><p>保持代码提交整洁(变基）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git rebase 分支</span><br></pre></td></tr></table></figure></li><li><p>记录图形展示</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log --graph --preey=format:"%h %s"</span><br></pre></td></tr></table></figure><h3 id="快速解决冲突"><a href="#快速解决冲突" class="headerlink" title="快速解决冲突"></a>快速解决冲突</h3></li></ul><ol><li><p>安装beyond compare</p></li><li><p>在git中配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --locla merge.tool bc3  #--local说明只在当前项目中有效</span><br><span class="line">git config --local mergetool.path '/usr/local/bin/bcomp'</span><br><span class="line">git config --local mergetool.keepBackup false</span><br></pre></td></tr></table></figure></li><li><p>应用beyond compare解决冲突</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git mergetool  #启动beyond compare</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;第一阶段-初始化&quot;&gt;&lt;a href=&quot;#第一阶段-初始化&quot; class=&quot;headerlink&quot; title=&quot;第一阶段:初始化&quot;&gt;&lt;/a&gt;第一阶段:初始化&lt;/h2&gt;&lt;p&gt;想要让git对一个目录进行版本控制需要以下步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;进入要管理
      
    
    </summary>
    
      <category term="Git" scheme="http://wanqbin.xyz/categories/Git/"/>
    
    
      <category term="Git" scheme="http://wanqbin.xyz/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>Linux内存管理机制——基本机制</title>
    <link href="http://wanqbin.xyz/2019/08/12/Linux%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6%E2%80%94%E2%80%94%E5%9F%BA%E6%9C%AC%E6%9C%BA%E5%88%B6/"/>
    <id>http://wanqbin.xyz/2019/08/12/Linux内存管理机制——基本机制/</id>
    <published>2019-08-12T13:54:00.000Z</published>
    <updated>2019-08-12T13:54:49.678Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;内存管理是指应用程序通过软硬件协作来访问内存的内存子系统。它的主要职责为：在进程请求内存时，为其分配可用物理内存页面；在进程释放内存时，回收内存页面；负责跟踪系统中内存的使用状态。</p><p>&emsp;&emsp;最简单的内存管理方式是使运行的进程拥有对所有物理内存1的访问权。如果这样做，进程就必须包含对硬件进行操作的全部代码，必须能找到自己的物理内存地址，而且还必须负责将自身的数据载入内存。这种方式不但给程序开发人员造成了很重的负担，而且还要保证进程可以被加载到可用内存中去。这些苛刻的要求显然对日益复杂化的程序需求来说很不现实，所以要将内存管理这个棘手的任务交给操作系统完成。</p><p>&emsp;&emsp;现在操作系统要求能够使多个程序共享操作系统的资源，同时还要求内存对程序开发者是透明的。在此需求下虚拟内存便应运而生，它支持程序访问比系统物理可用内存大得多的内存空间，而其也使多个程序共享内存变得更容易、更方便。物理内存是在系统中由RAM芯片控制的可用内存，虚拟内存依靠透明地使用磁盘空间以允许程序使用比物理内存更多的内存空间，磁盘空间可作为物理内存的扩充。我们之所以称其为虚拟内存就是因为磁盘空间被当作内存一样使用。</p><p>&emsp;&emsp;使用虚拟内存时，程序数据被分割成可以在磁盘与内存空间来回移动的基本单元。这样程序被使用的部分就可以被置于内存中，以便获得更快的访问速度；而未被使用的部分则被临时存放在磁盘上，从而减轻了物理内存的压力。这些数据单元，或者说虚拟内存块被称为<code>页</code>。同样，物理内存也需要被划分成可容纳页的区，这些区被称为页面。当一个进程请求一个地址时，包含该地址的页将被调入内存中，所有对该页中数据的请求都会产生对页的访问。如果页中没有任何地址被事先访问过，那么该页就尚未被载入内存。当某个地址第一次访问该页时便会产生一个缺页，因为这时内存中并没有该页，因此必须从磁盘请求。当物理页面已全部被占用时，内核必须选择一个页面，然后将其内容写回到磁盘，从而用程序刚刚请求到的页内容来填充它。</p><p>&emsp;&emsp;当一个程序从内存页面中存取数据时，会使用地址来指出需要访问的内存位置。该地址被称作<code>虚拟地址</code>,它们组成了进程的虚拟地址空间。每个进程都有自己独立的虚拟地址空间，这样做的好处是可防止非法读取或写覆盖1其他进程的数据。虚拟内存允许进程“使用”超过可用物理内存的内存空间，于是操作可以给予每个进程自己独立的虚拟线性地址空间。</p><p>&emsp;&emsp;虚拟地址空间的大小取决于体系结构的字长，如果一个处理器的寄存器可容纳32位数据，那么该处理器支持的进程虚拟地址空间大小就是$2^{32}$字节。虚拟内存不仅扩大了可寻址的内存范围，而且也使得物理内存的大小限制对用户空间的开发者透明，比如开发者不需要管理内存中的任何空格键。以32位的系统为例，其虚拟空间的范围为0~4GB，如果系统有2GB的物理内存，那么它的物理内存地址范围为0-2GB。而程序可以有4GB之大，但是只有被装入可用内存中的程序才能运行，因此整个程序将被存放在磁盘上，系统只把所需要运行的程序页载入到内存。</p><p>&emsp;&emsp;这种页从内存到磁盘之间调入调出的机制称为分页机制，分页机制包括程序虚拟地址到物理内存地址的转换。</p><p>&emsp;&emsp;内存管理在操作系统中负责维护虚拟地址和物理地址之间的关系，并且实现分页机制。对内存管理子系统来说，页时内存的基本单元，内存单元MMU是完成实际地址转换工作的硬件部件，内核提供了页表以及相关的地址，MMU在执行地址转换时访问这些地址。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;emsp;&amp;emsp;内存管理是指应用程序通过软硬件协作来访问内存的内存子系统。它的主要职责为：在进程请求内存时，为其分配可用物理内存页面；在进程释放内存时，回收内存页面；负责跟踪系统中内存的使用状态。&lt;/p&gt;
&lt;p&gt;&amp;emsp;&amp;emsp;最简单的内存管理方式是使运行的
      
    
    </summary>
    
      <category term="Linux内核" scheme="http://wanqbin.xyz/categories/Linux%E5%86%85%E6%A0%B8/"/>
    
    
      <category term="内存管理机制" scheme="http://wanqbin.xyz/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6/"/>
    
      <category term="虚拟地址" scheme="http://wanqbin.xyz/tags/%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80/"/>
    
      <category term="虚拟内存" scheme="http://wanqbin.xyz/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"/>
    
      <category term="操作系统" scheme="http://wanqbin.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Linux模块机制——模块的使用</title>
    <link href="http://wanqbin.xyz/2019/08/12/Linux%E6%A8%A1%E5%9D%97%E6%9C%BA%E5%88%B6%E2%80%94%E2%80%94%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>http://wanqbin.xyz/2019/08/12/Linux模块机制——模块的使用/</id>
    <published>2019-08-12T03:22:00.000Z</published>
    <updated>2019-08-12T03:23:40.909Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;由于模块和内核是在同样的地址空间运行的，因此模块编程在一定意义上说也就是内核编程。但是并不不是内核中所有的地方都可以使用模块，一般是在设备驱动程序、文件系统等地方使用模块，而对Linux内核来说极为重要的地方如进程管理和内存管理等是无法通过模块来实现的，必须通过直接对内核进行修改来完成的。</p><h2 id="一、一个简单的内核模块程序"><a href="#一、一个简单的内核模块程序" class="headerlink" title="一、一个简单的内核模块程序"></a>一、一个简单的内核模块程序</h2><p>我们编写一个Hello World的内核模块。内核模块代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;linux/module.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;linux/kernel.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;linux/init.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> _<span class="function">init <span class="title">hello_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    printk(KERN_ALERT <span class="string">"Hello World2\n"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> _<span class="function"><span class="built_in">exit</span> <span class="title">hello_exit</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    printk(KERN_ALERT <span class="string">"Goodbye,world2\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">module_init(hello_init);</span><br><span class="line">module_exit(hello_init);</span><br><span class="line">MODULE_LICENSE(<span class="string">"GPL"</span>);</span><br><span class="line">MODULE_AUTHOR(<span class="string">"Author"</span>);</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;这是一个简单的内核模块，我们对其进行简单的介绍。<code>hello_init()</code>函数是模块的入口点，它通过<code>module_init()</code>函数例程注册到系统中，在模块装载时被调用。模块的初始化函数形式如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> _<span class="function">init <span class="title">my_init</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;由于初始化函数通常并不会被外部函数直接调用，所以不必导出该函数，故它可以被标记为<code>static</code>又由于<code>init</code>函数在模块加载以后，就不会再使用了，因此，我们使用<code>_init</code>宏，这个宏表示在模块初始化完成后，丢弃函数，并释放其所占内存。</p><p>&emsp;&emsp;<code>hello_exit()</code>函数是模块的出口函数，它由<code>module_exit()</code>函数例程注册到系统。在模块从内核卸载时，内核便会调用<code>hello_exit()</code>函数。退出函数可能会在返回前负责清理资源，以保证硬件处于一致状态。模块的退出函数形式如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> _<span class="function"><span class="built_in">exit</span> <span class="title">my_exit</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br></pre></td></tr></table></figure><p>&emsp;&emsp;与初始化函数的原因一样，也可以标记该函数为<code>static</code>。使用<code>_exit</code>宏，如果上述文件被静态地编译到内核映像中，那么退出函数将不被包含，而且永远都不会被调用。</p><p>&emsp;&emsp;<code>MODULE_LICENSE()</code>宏定义用于指定模块的版权。如果载入非GPL模块到系统内核，则会在内核中设置被污染标识，这个标识只起到记录信息的作用。不过如果开发者提交的bug报告中含有被污染的代码，那么报告的信用无疑会下降。另外非GPL模块不能使用标记为GPL-only的函数和变量。</p><p>&emsp;&emsp;MODULE_AUTHOR()宏指定了代码作者，用于做信息记录。</p><h2 id="二、构建模块"><a href="#二、构建模块" class="headerlink" title="二、构建模块"></a>二、构建模块</h2><p>&emsp;&emsp;在2.6内核中采用了新的<code>kbuild</code>机制来构建内核模块，使得模块的构建更加简单、灵活。在Linux内核中由用户建立的模块可以放在两个位置，一种是将自己构建的模块直接添加到内核源代码中，另外一种就是将该模块放在内核代码外。</p><ol><li><h3 id="在内核源代码中构建内核模块"><a href="#在内核源代码中构建内核模块" class="headerlink" title="在内核源代码中构建内核模块"></a>在内核源代码中构建内核模块</h3><p>&emsp;&emsp;如果想把自己编写的模块添加到内核源代码树中，首先，必须先明确该模块需要放在源代码树的什么位置，在Linux中，所有设备的驱动程序都存放在内核目录<code>drivers</code>下，打开该目录会发现在该目录下存在许多子目录。在这个目录下，系统将不同的驱动程序进行分类存放，如char、block、usb等。当然Linux并没有硬性规定哪些硬件必须放在哪个目录下。</p><p>&emsp;&emsp;下面用一个简单的例子来说明如何将自己编写的模块直接添加到内核源代码树中，现在假设已经编写好了一个字符类型的驱动程序，命名为mymodule，要把该模块添加到内核中，需要完成以下4步工作。</p><p>（1）确定内核模块代码的存放位置。由于模块是一个字符类型的驱动程序，那么需要把该模块放到目录<code>drivers/char</code>下，这里有两种选择，一种是直接将模块放到<code>char</code>目录下，另外一种是在<code>char</code>目录下先建立一个文件夹并命名为<code>mumodule</code>，然后将模块放到这个子目录下。这两种作法对最后所要完成的工作并没有任何影响，只是考虑到当驱动程序是由多个源代码文件组成的时候，如果直接将这些原文件都放在<code>char</code>目录下，会给维护工作带来一定的麻烦。</p><p>（2）修改和创建makefile文件。这里先假设在第一步中<code>char</code>目录下建立一个文件夹<code>mymodule</code>，那么下面需要做的工作就是修改以及创建makefile文件，在<code>char</code>目录下的makefile文件中添加如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obj-m +=mymodule/</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;在makefile中添加上述代码的主要作用就是告诉模块构件系统在编译模块的时候需要进入<code>mymodule</code>子目录中。</p><p>&emsp;&emsp;接下来，需要在<code>mymodule</code>子目录下创建一个makefile文件，这个文件用来告诉模块构件系统如何编译该子目录下的模块，makefile文件的内容如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obj-m += mymodule.o</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;如果要构件的模块是由多个原文件构成，如file1.c和file2.c，那么可以在<code>mymodule</code>目录下的makefile文件编写如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">obj-m :=mymodule.o</span><br><span class="line">mymodule-objs:=file1.o  file2.o</span><br></pre></td></tr></table></figure><p>（3）重新编译修改后的内核代码。在Linux内核编译时，就会在<code>lib/modules/2.6.10/kernel/drivers/char</code>目录下,生成一个名称为<code>mymodule.ko</code>的文件。注意，在2.6内核中，生成的模块拓展名为<code>.ko</code>，而不是以前的<code>.o</code></p><p>（4）安装内核模块。可以使用如下的命令将内核中所有编译好的模块安装到Linux系统内核中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make modules_install</span><br></pre></td></tr></table></figure><p>至此，内核模块的创建就完成了，用户可以在新的内核中使用自己定义的内核模块了。</p></li><li><h3 id="在内核源码外构建内核模块"><a href="#在内核源码外构建内核模块" class="headerlink" title="在内核源码外构建内核模块"></a>在内核源码外构建内核模块</h3><p>&emsp;&emsp;其实将模块放在内核源码外与放在内核源码树内的最大的区别在于构建过程，当用户把自己编写的模块放在内核源码树的外部时，在内核模块编译之前必须构建内核代码树。将内核模块放在内核源代码外的构建过程了如下所示。</p><p>（1）还是假设已经编写好了一个模块文件<code>mymodule.c</code>，现在将该文件放在一个用户自己创建的文件夹中，在这里冷仍然需要创建自己的makefile文件，其形式如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obj-m += mymodule.o</span><br></pre></td></tr></table></figure><p>（2）执行make命令编译<code>.c</code>文件，其形式如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -C /lib/modules/kernel-version/uild M=$ PWD</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;这个命令是改变文件的目录到用<code>-C</code>选项提供的目录下（就是内核源码目录）。它在那里会发现内核顶层makefile文件。<code>M=</code>选项使makefile在试图创建内核模块前，回到模块源代码所在目录。</p><p>&emsp;&emsp;重复的输入前面的make命令是很麻烦的一件事，为此，我们可以编写内容如下的makefile文件，在每次编译内核模块时，只要输入make命令就可以了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>如果已经定义了KERNELRELEASE，则说明是从内核构造系统调用的，因此</span><br><span class="line"><span class="meta">#</span>可以使用其内建语句</span><br><span class="line"><span class="meta">ifneq($</span>(KERNELRELEASE),)</span><br><span class="line">obj-m := hello.o</span><br><span class="line">else</span><br><span class="line">KERNELDIR ?= /lib/modules/$(shell uname -r)/build</span><br><span class="line">PWD := $(shell pwd)</span><br><span class="line">default:</span><br><span class="line"><span class="meta">$</span>(MAKE) -C $(kERNELDIR) M=$(PWD) modules</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><p>（3）最后一步就是把刚才编译好的内核模块<code>mymodule.ko</code>装载到系统中。在Linux中可以有两种方法来载入一个已经编译好的模块，一个是利用<code>insmod</code>，另外一个就是利用命令<code>modprobe</code>。</p><p>&emsp;&emsp;使用<code>insmod</code>命令安装内核模板的命令格式如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insmod mymodule.ko;</span><br></pre></td></tr></table></figure><p><code>insmod</code>命令将模块的代码和数据装入内核，然后使用内核符号表解析模块中任何未解析的符号，将内核模块映像复制到内存区域，并通过内核符号表解析模块中的内核引用，最后调用模块的初始化函数。</p><p>&emsp;&emsp;这里需要说明的是，<code>insmod</code>命令虽然很简单，但是其功能也同样有限，该命令的作用就是请求内核载入指定的模块，它不会进行任何依赖性分析和错误性检查。</p><p>&emsp;&emsp;<code>modprobe</code>命令与<code>insmod</code>的功能很相似，也是用于将指定的模块装载到内核中，但是它比<code>insmod</code>命令要实用得多，这是因为该命令提供了模块依赖性分析，错误智能检查，错误报告以及许多其他功能和选项。</p><p>&emsp;&emsp;这里以提供的模块依赖性为例来详细分析其优越性，当用<code>modprobe</code>命令来装载某个指定的模块的时候，它会考虑要装载的模块是否引用了一些当前内核中不存在的符号，也就是说该模块所引用的符号没有存放在当前的全局内核符号表中，在这种情况下，该命令会在当前模块搜索路径中查找定义了这些符号的模块，如果找到了这些模块，该命令会自动地将这些模块装载到内核中，而在这种情况下如果使用<code>insmod</code>命令来装载该模块，则会产生错误信息，即模块装载不成功，也就是说<code>modprobe</code>命令不但会加载指定的模块，而且还会自动加载任何它所依赖的有关模块。该命令的使用格式如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modprobe -i mymodule</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;最后来看如何从内核中卸载已经装载的模块，同样有两个命令来完成该任务，一个就是<code>rmmod</code>命令，另一个就是<code>modprobe</code>命令，它们的使用格式如下：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rmmod mymodule</span><br><span class="line">modprobe -r mymodule</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;这里需要说明的一点就是,<code>modprobe</code>与<code>rmmod</code>命令不同1，它不仅会卸载指定的模块，而且如果它发现需要卸载的这个模块所依赖的那些模块没有其他模块依赖于它们，那么该命令也会将这些模块一起从内核中卸载掉。</p></li></ol><h2 id="三、模块参数"><a href="#三、模块参数" class="headerlink" title="三、模块参数"></a>三、模块参数</h2><p>&emsp;&emsp;在装载内核模块时，用户可以向模块传递一些参数，如<code>modprobe modname var=value</code>,否则，<code>var</code>将使用模块内定义的缺省值。</p><p>&emsp;&emsp;2.4内核下,<code>linux/module.h</code>中定义有宏<code>MODULE_PARM(var,type)</code>，用于向模块传递命令行参数。<code>var</code>为接收参数值的变量名，<code>type</code>为采取如下格式的字符串<code>[min[-max]]{b,h,i,l,s}</code>。其中<code>min</code>及<code>max</code>用于表示当参数为数组类型时，允许输入的数组元素的个数范围，<code>b</code>表示<code>byte</code>，<code>h</code>表示<code>short</code>，<code>i</code>表示<code>int</code>，<code>l</code>表示<code>long</code>，<code>s</code>表示<code>string</code>。</p><p>&emsp;&emsp;2.6内核下，宏<code>MODULE_PARM(var,type)</code>不再被支持。在头文件<code>Linux/moduleparam.h</code>定义如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">module_param(name,type,perm)</span><br><span class="line">module_param_array(name,type,nump,perm)</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;<code>type</code>类型可以是<code>byte,short,ushort,int,uint,long,ulong,charp,bool</code>或<code>invbool</code>，不再采用2.4内核中的字符串形式，而且在模块编译时会将此处声明的<code>type</code>与变量定义的类型进行比较，判断是否一致。</p><p>&emsp;&emsp;<code>perm</code>表示此参数在<code>sysfs</code>文件系统中对应的文件节点的属性。2.6内核使用<code>sysfs</code>文件系统，这是一个奖励在内存中比<code>proc</code>更强大的文件系统。<code>sysfs</code>文件系统可以动态、实时、有组织层次地反应当前系统中的硬件，驱动等状态。当<code>perm</code>为0时，表示此参数在<code>sysfs</code>文件系统下对应的文件节点不存在。模块被加载后，在<code>sys/module</code>目录下1将出现以此模块名命名的目录。如果此模块存在<code>perm</code>不为0的命令行参数，在此模块的目录下将出现<code>paramters</code>目录，包含一系列以参数名命名的文件节点，这些文件的权限值等于<code>perm</code>，文件的内容为参数的值。</p><p>&emsp;&emsp;<code>nump</code>为保存输入的数组元素个数的变量指针。当不需保存实际输入的数组元素个数时，可以设为NULL。</p><h2 id="四、内核导出模块符号表"><a href="#四、内核导出模块符号表" class="headerlink" title="四、内核导出模块符号表"></a>四、内核导出模块符号表</h2><p>&emsp;&emsp;在内核模块被载入后，就会动态连接到内核中。注意，它与用户空间中的动态链接库类似，只有被明确导出的内核函数和变量，才可以被动态库使用。在内核中，导出内核函数需要使用特殊的指令：<code>EXPORT_SYMBOL</code>和<code>EXPORT_SYSBOL_GPL</code>。</p><p>&emsp;&emsp;导出的内核函数可以被其他模块调用，而未导出的诶恶化函数模块则无法被调用。模块代码的链接和调用规则相比核心内核映像中的代码而言，要更为严格。核心代码在内核中可以调用任意非静态接口，因为所有的核心源代码文件被链接成了同一个映像。当然，被导出的符号表所含的函数必然也是非静态的。</p><p>&emsp;&emsp;导出的内核符号表被看做是导出的内核接口，甚至是内核API。导出符号相当简单，如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">EXPORT_SYMBOL(var);<span class="comment">/*导出变量var*/</span></span><br><span class="line">EXPORT_SYMBLO(func);<span class="comment">/*导出函数func*/</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;emsp;&amp;emsp;由于模块和内核是在同样的地址空间运行的，因此模块编程在一定意义上说也就是内核编程。但是并不不是内核中所有的地方都可以使用模块，一般是在设备驱动程序、文件系统等地方使用模块，而对Linux内核来说极为重要的地方如进程管理和内存管理等是无法通过模块来实现
      
    
    </summary>
    
      <category term="Linux内核" scheme="http://wanqbin.xyz/categories/Linux%E5%86%85%E6%A0%B8/"/>
    
    
      <category term="Linux模块" scheme="http://wanqbin.xyz/tags/Linux%E6%A8%A1%E5%9D%97/"/>
    
      <category term="模块的使用" scheme="http://wanqbin.xyz/tags/%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    
      <category term="构建内核模块" scheme="http://wanqbin.xyz/tags/%E6%9E%84%E5%BB%BA%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97/"/>
    
      <category term="模块参数" scheme="http://wanqbin.xyz/tags/%E6%A8%A1%E5%9D%97%E5%8F%82%E6%95%B0/"/>
    
      <category term="导出模块符号表" scheme="http://wanqbin.xyz/tags/%E5%AF%BC%E5%87%BA%E6%A8%A1%E5%9D%97%E7%AC%A6%E5%8F%B7%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>Linux模块机制</title>
    <link href="http://wanqbin.xyz/2019/08/12/Linux%E6%A8%A1%E5%9D%97%E6%9C%BA%E5%88%B6/"/>
    <id>http://wanqbin.xyz/2019/08/12/Linux模块机制/</id>
    <published>2019-08-12T03:21:00.000Z</published>
    <updated>2019-08-12T03:22:04.259Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;Linux是单内核的操作系统，也就是整个系统内核都运行于一个单独的保护域中。相比于微内核的操作系统，单内核由于把所有的系统功能模块都集中到一起，系统的性能和速度都非常好，但是可扩展性和维护性就相对较差。为了弥补单内核的这个缺点，Linux操作系统使用了一种全新的机制——可装载内核模块机制(Load Kernel Module,LKM),用户可以根据需要，在不需要对内核重新编译的情况下，将模块动态地载入到内核或从内核中移出。</p><p>&emsp;&emsp;可装载内核模块，简称为模块，它是在内核空间运行的程序，实际上是一种目标对象文件，没有链接，不能独立运行，但是其代码可以在运行时链接到系统中作为内核的一部分运行或从内核中卸载，从而可以动态地扩展内核的功能。这种目标代码他通常由一部分函数和数据结构组成，用来实现一个文件系统、驱动程序或其他内核上层的功能。</p><p>&emsp;&emsp;内核模块与通常所说的运行在用户空间的应用程序有以下区别：</p><p>（1）当用户想从系统中删除某个指定的模块的时候，必须考虑到一些例如资源的释放或者其他的清除工作，Linux中每一个模块都必须包含的两个组成部分，一个用于在初始化该模块时调用，另外一个用于删除该模块的时候调用，这里之所以在模块被删除的时候还要调用一个指定的函数，就是需要这个函数来完成撤销由该模块的初始化函数所做的一切。而一般应用程序在大多数情况下是不用考虑这一点的。</p><p>（2）在Linux的内核模块中，只能调用那些由内核提供的函数，而不可以像其他应用程序那样调用应用程序库函数，这主要是因为模块仅仅被链接到内核，因此它能调用的函数仅仅是那些由内核导出的函数。</p><p>（3）在模块中发生错误的处理方式与在应用程序中发生错误的处理方式是不同的，用户在编写模块的时候必须非常小心，因为模块时链接到内核中的，一个内核模块错误在严重的情况下会导致整个系统崩溃。</p><p>&emsp;&emsp;其实对于Linux而言，几乎系统中的每一个高层组件都可以被作为模块来进行编译，例如文件系统、设备驱动程序等。当然也有些组件是不可以作为模块进行编译的，这些组件要么静态地包含在内核中，要么不编译。</p><p>&emsp;&emsp;Linux引入可加载模块机制有以下优点：</p><p>（1）使得内核更加紧凑和灵活</p><p>（2）修改内核时，不必全部重新编译整个内核，可节省时间。系统中如果需要使用新的功能，只要编译相应的模块，然后使用特定用户空间的程序将模块插入即可。</p><p>（3）模块的目标代码一旦被链接到内核，它的作用和静态链接的内核目标代码完全等价。所以，当调用模块的函数时，无需显式的消息传递。</p><p>但是内核模块的引入也带来了一定的问题。</p><p>（1）由于内核所占用的内存是不会被换出的，所以链接进内核的模块会给整个系统带来一定的性能和内存利用方面的损失。</p><p>（2）装入内核模块就成了内核的一部分，可以修改内核中的其他部分，因此模块的使用可能会导致系统崩溃。</p><p>（3）为了让内核模块能访问所有内核资源，内核必须维护一个符号表，并在装入和卸载模块时修改符号表。</p><p>（4）模块可以利用其他模块的功能，因此内核要维护模块之间的依赖关系。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;emsp;&amp;emsp;Linux是单内核的操作系统，也就是整个系统内核都运行于一个单独的保护域中。相比于微内核的操作系统，单内核由于把所有的系统功能模块都集中到一起，系统的性能和速度都非常好，但是可扩展性和维护性就相对较差。为了弥补单内核的这个缺点，Linux操作系统使用
      
    
    </summary>
    
      <category term="Linux内核" scheme="http://wanqbin.xyz/categories/Linux%E5%86%85%E6%A0%B8/"/>
    
    
      <category term="操作系统" scheme="http://wanqbin.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Linux模块机制" scheme="http://wanqbin.xyz/tags/Linux%E6%A8%A1%E5%9D%97%E6%9C%BA%E5%88%B6/"/>
    
      <category term="可装载内核模块机制" scheme="http://wanqbin.xyz/tags/%E5%8F%AF%E8%A3%85%E8%BD%BD%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E6%9C%BA%E5%88%B6/"/>
    
      <category term="LKM" scheme="http://wanqbin.xyz/tags/LKM/"/>
    
  </entry>
  
  <entry>
    <title>Linux内核同步机制分析——其他同步机制</title>
    <link href="http://wanqbin.xyz/2019/08/12/Linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%E5%85%B6%E4%BB%96%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/"/>
    <id>http://wanqbin.xyz/2019/08/12/Linux内核同步机制分析——其他同步机制/</id>
    <published>2019-08-12T03:19:00.000Z</published>
    <updated>2019-08-12T03:20:52.538Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、每个处理器变量"><a href="#一、每个处理器变量" class="headerlink" title="一、每个处理器变量"></a>一、每个处理器变量</h2><p>&emsp;&emsp;最后的同步机制就是不需要同步，因为所有的同步机制不仅需要浪费大量的处理器周期以探测临界区的状态，而且通常导致进程阻塞、系统并发能力下降、系统吞吐量减小。更糟糕的是，在同步机制使用不当的情况下，常常导致系统死锁。</p><p>&emsp;&emsp;在Linux内核中引入的每个处理器变量，是一种特殊的同步机制，用于多处理器系统中，通过为每个CPU创建一个变量副本，使每个CPU都只能使用自己本地的复制件，来避免处理器间的同步。使用每个处理器变量会减少数据加锁操作，它唯一的安全要求就是要禁止内核抢占。总的来说，使用每个处理器变量有以下两个显著的好处。</p><p>（1）按照每个CPU访问每个处理器变量的逻辑——每个CPU只能访问该处理器本身的数据变量，这样在CPU访问每个处理器变量时就不再需要任何锁。这样就避免了因处理器间的同步影响系统的并发能力，即消除了因同步而导致的系统性能损失。</p><p>（2）使用每个处理器变量可以较少缓存失效，进一步提高系统性能。缓存失效发生在处理器试图使它们的缓存保持同步时。如果一个处理器操作某个数据，而该数据又存放在其他处理器缓存中，那么存放该树的那个处理器必须清理或刷新它自己的缓存。持续不断的缓存失效称为缓存抖动，缓存抖动对系统性能影响颇大。使用每个处理器变量将使得缓存失效降至最低，因为理想情况下每个处理器只会访问它们自己的数据。</p><p>&emsp;&emsp;在Linux2.4内核中，系统把每个处理器变量存放到一个数组中，数组中的每一项对应着系统上一个存在的处理器，并使用每个CPU的处理器号作为每个CPU所对应元素的下标。我们可以按照下面的方式来使用每个处理器变量。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> my_percpu[NR_CPUS];<span class="comment">//每个处理器变量的声明</span></span><br><span class="line"><span class="keyword">int</span> cpu;</span><br><span class="line">cpu=get_cpu();<span class="comment">//获得当前处理器，并禁止内核抢占</span></span><br><span class="line">my_percpu[cpu]++;</span><br><span class="line">put_cpu();<span class="comment">//使能内核抢占</span></span><br></pre></td></tr></table></figure><p>&emsp;&emsp;注意，上面的代码中并没有出现锁。正如上面所言，所操作的变量对当前处理器来说是唯一的，除了当前处理器，没有其他处理器可以接触到这个变量，不存在并发访问问题，所以当前处理器在不用锁的情况下也可以安全地访问它。</p><p>&emsp;&emsp;Linux2.6内核为了方便创建和操作每个处理器变量，引入了新的操作接口，该操作接口归纳了前面的操作行为，并使得每个处理器变量的创建和操作得以简化。操作函数的功能及描述如下：</p><table><thead><tr><th>函数原型</th><th>描述</th></tr></thead><tbody><tr><td>DEFINE_PER_CPU(tyep,name)</td><td>在内核编译时，创建一个类型为type，名字为name的每个处理器变量</td></tr><tr><td>DECLARE_PER_CPU(type,name)</td><td>在内核编译时，声明一个类型为type，名字为name的每个处理器变量</td></tr><tr><td>get_cpu_var(var)</td><td>返回指定变量var在当前处理器上的复制件，并禁止内核抢占</td></tr><tr><td>put_cpu_var(var)</td><td>使能内核抢占</td></tr><tr><td>void* alloc_percpu(type)</td><td>在内核运行过程中，动态地创建一个类型为type的每个处理器变量，并返回指向这个变量的void类型指针</td></tr><tr><td>void *_alloc_percpu(size)</td><td>在系统运行过程中，动态地创建一个大小为size的每个处理器变量，并返回指向这个变量的void类型指针</td></tr><tr><td>free_percpu(ptr)</td><td>释放指针ptr所指向的每个处理器变量</td></tr><tr><td>void *per_cpu_ptr(ptr,cpu)</td><td>返回指针变量在处理器号cpu上的复制件</td></tr></tbody></table><p>&emsp;&emsp;为了保持Linux内核的兼容性，Linux2.4内核中每个处理器变量的使用方式，在Linux2.6内核中也可以使用。但是，由于新的操作接口使用方便，而且在性能上也得到了优化，因此，在内核编程中建议使用新操作接口。</p><h2 id="二、禁止内核抢占"><a href="#二、禁止内核抢占" class="headerlink" title="二、禁止内核抢占"></a>二、禁止内核抢占</h2><p>&emsp;&emsp;在Linux2.6内核中引入了内核抢占机制，这就使得内核中的进程在任何时刻都可能被抢占，让出CPU，以便另一个具有更高优先级的进程运行。这就意味着一个任务与被抢占的任务可能会在同一个临界区运行。为了避免这种情况的发生，临界区代码可以使用自旋锁作为非抢占区域的标记，因为如果临界区持有自旋锁，内核便不能进行抢占。在实际中，某些情况并不需要自旋锁，但是仍然需要禁止内核抢占。出现得最频繁的情况就是对每个处理器变量访问。为此，Linux提供了禁止内核抢占的操作函数<code>preempt_disable()</code>。这里我们对Linux禁止内核抢占机制进行讨论。</p><p>&emsp;&emsp;为了禁止内核抢占以避免因内核抢占导致的内核数据的不一致性，在每个进程的<code>thread_info</code>结构中引入了内核抢占计数器<code>preempt_count</code>。变量<code>preempt_count</code>被划分为3个字段，每个字段的名称及翻译如下：</p><table><thead><tr><th>字段</th><th>位</th><th>描述</th></tr></thead><tbody><tr><td>PREEMPT</td><td>0~7</td><td>系统设置禁止内核抢占的计数</td></tr><tr><td>SOFTIRQ</td><td>8~15</td><td>系统设置禁止执行软中断的计数</td></tr><tr><td>HARDIRQ</td><td>16~27</td><td>系统设置进入中断的计数，即中断嵌套的深度</td></tr></tbody></table><p>&emsp;&emsp;内核中提供了宏定义<code>add_preempt_count()</code>、<code>sub_preempt_count()</code>来方便对每个字段进行加1、减1操作。这两个宏定义具体操作哪个字段，依赖于传递给这两个宏定义的参数。候选参数有<code>PREEMPT_OFFSET</code>（也可以直接使用1代替）、<code>SOFTIRQ_OFFSET</code>、<code>HARDIRQ_OFFSET</code>，这些参数定义在<code>include/linux/hardirq.h</code>中，在默认情况下，<code>PREEMPT_OFFSET</code>的值为0x1，<code>SOFTIRQ_OFFSET</code>的值为0x100、<code>HARDIRQ_OFFSET</code>的值为0x10000。下面我们对这三个字段的用途分别进行介绍。</p><ol><li><h3 id="禁止内核抢占"><a href="#禁止内核抢占" class="headerlink" title="禁止内核抢占"></a>禁止内核抢占</h3><p>&emsp;&emsp;禁止内核抢占由宏定义<code>preempt_disable()</code>完成，该宏定义<code>include/linux/preempt.h</code>中，代码如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> preempt_disable()\</span></span><br><span class="line"><span class="keyword">do</span>&#123;\</span><br><span class="line">inc_preempt_count();\</span><br><span class="line">barrier();\</span><br><span class="line">&#125;<span class="keyword">while</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>第3行代码调用<code>inc_preempt_count()</code>函数将变量<code>preempt_count</code>对应<code>PREEMPT</code>字段的部分进行加1操作。</p><p>第4行代码中<code>barrier()</code>函数是一个内存屏障，保障在屏障之前缓存在寄存器中的变量写回到内存中去。</p><p>使能内核抢占函数由宏定义<code>preempt_enable()</code>完成，该宏定义在<code>include/linux/preempt.h</code>中，代码如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> preempt_enable()\</span></span><br><span class="line"><span class="keyword">do</span>&#123;\</span><br><span class="line">preempt_enable_no_resched();\</span><br><span class="line">barrier();\</span><br><span class="line">preempt_check_resched();\</span><br><span class="line">&#125;<span class="keyword">while</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>第3行代码调用<code>preempt_enable_no_resched()</code>函数将变量<code>preempt_count</code>对应<code>PREEMPT</code>字段部分进行减1操作，但是并不检查是否有需要被调度的任务。</p><p>第5行代码调用<code>preempt_check_resched()</code>函数检查是否需要被调度的任务，即当前进程是否设置了请求调度标志<code>TIF_NEED_RESCHED</code>,如果设置了该标志，则调用调度器进行内核抢占。</p></li><li><h3 id="禁止执行软中断的计数"><a href="#禁止执行软中断的计数" class="headerlink" title="禁止执行软中断的计数"></a>禁止执行软中断的计数</h3><p>&emsp;&emsp;Linux内核提供了<code>local_bh_disable()</code>用于禁止执行软中断，该函数定义在<code>kernel/softira.c</code>中，代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">local_bh_disable</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    _local_bh_disable((<span class="keyword">unsigned</span> <span class="keyword">long</span>) _builtin_return_address(<span class="number">0</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;该函数实际上是<code>_local_bh_disable()</code>函数的封装。<code>_local_bh_disable()</code>定义在一个文件中，代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">void</span> _local_bh_disable(<span class="keyword">unsigned</span> <span class="keyword">long</span> ip)</span><br><span class="line">&#123;</span><br><span class="line">    add_preempt_count(SOFTIRQ_OFFSET);</span><br><span class="line">    barrier();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第3行代码以<code>SOFTIRQ_OFFSET</code>为参数调用<code>add_preempt_count()</code>函数将变量<code>preempt_count</code>对应<code>SOFTIRQ</code>字段部分进行加1操作。</p><p>Linux内核提供了<code>local_bh_enable()</code>用于使能执行软中断，代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">local_bh_enable</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_TRACE_IRQFLAGS</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line">    WARN_ON_ONCE(in_irq());</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    </span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_TRACE_IRQFLAGS</span></span><br><span class="line">    local_irq_save(flags);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(softirq_count()==SOFTIRQ_OFFSET)</span><br><span class="line">        trace_softirqs_on(<span class="keyword">unsigned</span> <span class="keyword">long</span>) _builtin_return_address(<span class="number">0</span>));</span><br><span class="line">    </span><br><span class="line">    sub_preempt_count(SOFTIRQ_OFFSET<span class="number">-1</span>);</span><br><span class="line">    <span class="keyword">if</span>(unlikely(!in_interrupt()&amp;&amp;local_softirq_pending()))</span><br><span class="line">        do_softirq();</span><br><span class="line">    </span><br><span class="line">    dec_preempt_count();</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_TRACE_IRQFLAGS</span></span><br><span class="line">    local_irq_restore(flags);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    preempt_check_resched();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第12~13行代码判断是否可以允许执行软中断（即变量preempt_count中对应SOFTIRQ字段是否加1），如果是，调用<code>trace_softirq_on()</code>记录软中断使能的统计信息。</p><p>第15行代码以<code>SOFTIRQ_OFFSET-1</code>参数调用<code>sub_preempt_count()</code>函数将变量<code>preempt_count</code>对应<code>SOFTIRQ</code>字段部分进行减1操作，并禁止内核抢占（在PREEMPT对应字段减1）。</p><p>第16~17行代码中<code>in_interrupt()</code>函数用于查看当前是否处于中断上下文或者中断下半部中，<code>local_softirq_pending()</code>函数用于查看当前是否存在被挂起的软中断，<code>do_softirq()</code>函数用于执行当前被挂起的软中断。</p><p>第19行代码调用<code>dec_preempt_count()</code>函数使能内核抢占。</p><p>Linux内核提供了<code>in_softirq()</code>函数查看当前是否禁止了执行软中断，该函数定义在<code>include/linux/hardirq.h</code>中，代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> in_softirq()(softirq_count())</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> softirq_count()(preempt_count()&amp;SOFTIRQ_MASK)</span></span><br></pre></td></tr></table></figure><p>其中，<code>preempt_count()</code>用于获取<code>thread_info</code>结构中成员变量<code>preempt_count</code>,在默认情况下，<code>SOFTIRQ_MASK</code>的值为0xff00。</p></li><li><h3 id="中断计数"><a href="#中断计数" class="headerlink" title="中断计数"></a>中断计数</h3><p>&emsp;&emsp;当内核进入中断时，会调用<code>irq_enter()</code>函数来增加中断的嵌套次数，该函数实际上是<code>_irq_enter()</code>函数的封装。<code>_irq_enter()</code>是一个宏定义，定义在<code>include/linux/hardirq.h</code>中，代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _irq_enter()\</span></span><br><span class="line"><span class="keyword">do</span>&#123;\</span><br><span class="line">account_system_vtime(current);\</span><br><span class="line">add_preempt_count(HARDIRQ_OFFSET);\</span><br><span class="line">trace_harding_enter();\</span><br><span class="line">      &#125;<span class="keyword">while</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>第3行代码调用<code>account_system_vtime()</code>函数更新当前进程的虚拟运行时间<code>vtime</code>。</p><p>第4行代码以<code>HARDIRQ_OFFSET</code>参数调用<code>add_preempt_count()</code>函数将变量<code>preempt_count</code>对应的<code>HARDIRQ</code>字段进行加操作。</p><p>第5行代码调用<code>trace_hardirq_enter()</code>函数对当前进程的进入中断上下文的计数器（存放在进程描述符struct中的成员变量hardirq_context)加1操作。</p><p>当内核从一个中断中退出时，会调用<code>irq_exit()</code>函数，减少中断的嵌套次数，该函数实际上是<code>_irq_exit()</code>函数的封装。<code>_irq_exit()</code>是一个宏定义，定义在<code>include/linux/harrdirq.h</code>中，代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _irq_exit()\</span></span><br><span class="line"><span class="keyword">do</span>&#123;\</span><br><span class="line">trace_hardirq_exitt();\</span><br><span class="line">account_system_vtime(current);\</span><br><span class="line">sub_preempt_countt(HARDIRQ_OFFSET);\</span><br><span class="line">      &#125;<span class="keyword">while</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>第3行代码调用<code>trace_hardirq_exit()</code>函数对当前进程的退出中断上下文的计数器（存放在进程描述符struct中的成员变量hardirq_context)进行加1操作。</p><p>第5行代码以<code>HARRDIRQ_OFFSET</code>为参数调用<code>sub_preempt_count()</code>函数将变量<code>preempt_count</code>对应的<code>HARDIRQ</code>字段部分进行减1操作。</p><p>Linux内核提供了<code>in_irq()</code>函数用于查看当前是否处于中断上下文中，该函数实际上是对<code>hardirq_count()</code>函数的封装，在<code>include/linux/hardirq.h</code>中，代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> in_irq()(hardirq_count())</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> hardirq_count()(preempt_count()&amp;&amp;HARDIRQ_MASK)</span></span><br></pre></td></tr></table></figure><p>其中，默认情况下，<code>HARDIRQ_MASK</code>的值为0xfff0000。</p><p>内核提供了<code>in_interrupt()</code>函数用于查看当前是否处于中断上下文中或者禁止执行软中断，该函数定义在<code>include/linux/hardirq.h</code>中，代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> in_interrupt()(irq_count())</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> irq_count()(preempt_count()&amp;(HARDIRQ_MASK|SOFTIRQ_MASK))</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="三、BKL"><a href="#三、BKL" class="headerlink" title="三、BKL"></a>三、BKL</h2><p>&emsp;&emsp;BKL(大内核锁)是一个全局自旋锁，在早期的Linux版本中该锁被广泛使用，在Linux2.0版本中，这个锁是一个相对粗粒度的自旋锁，当时该锁是为了确保内核中一个时刻上只存在一个进程运行在内核态。而到了Linux2.2版本后，内核不再依赖于这个单独的自旋锁，而是由专门的自旋锁保护内核中的数据结构，从而允许多个处理器在内核中并发地执行程序。</p><p>&emsp;&emsp;BKL是一个名为<code>kernel_flag</code>的自旋锁，持有该锁的进程仍可以睡眠，因为内核中规定当任务无法调度的时候，该睡眠任务所持有的BKL锁才会被自动释放，该任务被重新调度的时候，该锁又会被重新获取，但是并不提倡让持有该锁的进程去睡眠；另外Linux允许一个进程递归地获取一个BKL锁，也就是说BKL是一种递归锁。代表进程结构的结构体<code>task_struct</code>中有一个成员变量命名为<code>lock_depth</code>，该成员变量就是为了实现让一个进程可以多次获取一个大内核锁而设定的。如果进程不需要获得BKL锁，则将该成员变量<code>lock_depth</code>的值设为-1；该进程每次获得BKL锁，就会使<code>lock_depth</code>加1，<code>lock_depth</code>表示该进程获得了多少次锁，当然，在该进程释放锁的时候，也必须调用同样次数的释放锁的函数，否则，该锁是不会被真正释放的。</p><p>&emsp;&emsp;在内核中不鼓励使用BKL，事实上，在新内核的代码中不再使用BKL，但是这种锁仍然在部分旧代码中被保留下来。BKL操作函数如下：</p><table><thead><tr><th>函数原型</th><th>描述</th></tr></thead><tbody><tr><td>lock_kernel()</td><td>获得大内核锁BKL</td></tr><tr><td>unlock_kernel()</td><td>释放大内核锁BKL</td></tr><tr><td>kernel_locked()</td><td>如果锁被持有返回非0值，否则返回0</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、每个处理器变量&quot;&gt;&lt;a href=&quot;#一、每个处理器变量&quot; class=&quot;headerlink&quot; title=&quot;一、每个处理器变量&quot;&gt;&lt;/a&gt;一、每个处理器变量&lt;/h2&gt;&lt;p&gt;&amp;emsp;&amp;emsp;最后的同步机制就是不需要同步，因为所有的同步机制不仅需要浪费
      
    
    </summary>
    
      <category term="Linux内核" scheme="http://wanqbin.xyz/categories/Linux%E5%86%85%E6%A0%B8/"/>
    
    
      <category term="操作系统" scheme="http://wanqbin.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Linux内核同步机制" scheme="http://wanqbin.xyz/tags/Linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/"/>
    
      <category term="每个处理器变量" scheme="http://wanqbin.xyz/tags/%E6%AF%8F%E4%B8%AA%E5%A4%84%E7%90%86%E5%99%A8%E5%8F%98%E9%87%8F/"/>
    
      <category term="禁止内核中断" scheme="http://wanqbin.xyz/tags/%E7%A6%81%E6%AD%A2%E5%86%85%E6%A0%B8%E4%B8%AD%E6%96%AD/"/>
    
      <category term="BKL" scheme="http://wanqbin.xyz/tags/BKL/"/>
    
  </entry>
  
  <entry>
    <title>Linux内核同步机制分析——RCU同步机制</title>
    <link href="http://wanqbin.xyz/2019/08/11/Linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90%E2%80%94%E2%80%94RCU%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/"/>
    <id>http://wanqbin.xyz/2019/08/11/Linux内核同步机制分析——RCU同步机制/</id>
    <published>2019-08-11T07:14:00.000Z</published>
    <updated>2019-08-11T07:15:38.356Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;读-复制-更新（Read-Copy-Update，RCU)机制是2.6内核中引入的另外一种新的同步机制。无论是自旋锁机制还是信号量机制都依赖于原子操作完成内核同步工作。但是，随着CPU性能的迅速提高，获得这些锁的开销相对于CPU的速度在成倍地增加，原因很简单——CPU的速度和访问内存的速度差距越来越大，系统的整体性能越来越依赖于高速缓存和流水线的性能；这种依赖于原子操作的不同机制需要使用内存屏障来保障原子操作，而这又会导致处理器流水线停滞和高速缓存的刷新，因此对系统的性能有很大的影响。</p><p>&emsp;&emsp;内核中新引入的RCU机制克服了基于原子操作同步机制的缺点，具有很好的可扩展性。但是，这种锁机制的使用范围比较窄，它只适用于读多写少的情况，如网络路由表的查询更新、设备状态表的维护、数据结构的延迟以及多径I/O设备的维护等。</p><h2 id="一、RCU同步机制原理"><a href="#一、RCU同步机制原理" class="headerlink" title="一、RCU同步机制原理"></a>一、RCU同步机制原理</h2><p>&emsp;&emsp;同步机制的核心思想是将写者的更新过程划分为移除和回收两个独立的步骤；同时要求必须通过指针来引用临界资源。移除步骤首先生成临界资源的一份复制并更新相关的域，然后解除指针对原有临界资源的应用并使之指向新的已经更新的复制件。回收步骤在适当的时机开始完成原有临界资源的回收工作，释放其占用的存储空间。</p><p>&emsp;&emsp;对于被RCU保护的共享数据结构，读者不需要获得任何锁就可以访问它，而写者在访问它时首先复制一个副本，然后对副本进行修改，最后使用回调(callback)机制在适当的时机把指向原来数据的指针重新指向新的被修改的数据。这个时机就是所有引用该数据的CPU都退出对共享数据的操作之时。因此可以把RCU同步机制看成是一种改进的读写自旋锁<code>rwlock</code>。</p><p>&emsp;&emsp;在RCU同步机制中，读者几乎没有什么同步开销，它不需要获得锁，也不使用原子指令，而且在除alpha之外的所有架构上也不需要内存屏障，因此不会导致锁竞争、内存延迟以及流水线停滞，从而大大提高了读者的性能。由于读者不需要获得任何锁，因此死锁问题也就不需要考虑了，这使得RCU同步机制的使用更加简单。RCU同步机制中写者的同步开销比较大，它需要复制被修改的数据结构，也必须使用某种锁机制同步其他并行的写者操作。在RCU同步机制的写者实现时，读者必须提供一个信号给写者以便写者能够确定数据可以被安全地释放或修改的时机。有一个专门的垃圾收集器来探测读者的信号，一旦所有的读者都已经发送信号告知它们都不再使用被RCU保护的数据结构，垃圾收集器就调用回调函数完成最后的数据释放或修改操作。因此RCU写者的同步开销比较大，它比较适用于写操作比较少的同步操作。</p><p>&emsp;&emsp;RCU与rwlock的不同之处是：RCU同步机制既允许多个读者同时访问被保护的数据，又允许多个读者和多个写者同时访问被保护的数据，读者没有任何开销，而写者的同步开销则取决于使用的写者间同步机制。但RCU不能代替rwlock，因为如果写操作比较多时，对读者性能提高不能弥补写者导致的性能损失。</p><h2 id="二、RCU同步机制的实现"><a href="#二、RCU同步机制的实现" class="headerlink" title="二、RCU同步机制的实现"></a>二、RCU同步机制的实现</h2><p>&emsp;&emsp;内核为RCU同步机制提供了一系列的操作函数，下面只讨论5个主要函数的实现，其他的操作函数都是这些函数的封装，可由这些函数组合而成。</p><ol><li><p><code>rcu_read_lock()</code></p><p>&emsp;&emsp;该操作函数由读者任务调用，表明读者任务以只读方式进入了RCU临界区，开始对RCU临界资源进行访问。代码如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rcu_read_lock()\</span></span><br><span class="line"><span class="keyword">do</span>&#123;\</span><br><span class="line">preempt_disable();\</span><br><span class="line">_acquire(RCU);\</span><br><span class="line">rcu_read_acquire();\</span><br><span class="line">&#125;<span class="keyword">while</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>其中，<code>_acquire()</code>函数和<code>rcu_read_acquire()</code>函数都是编译器上的选择信息，<code>preempt_disable()</code>禁止内核抢占，即RCU同步机制中获取读锁只禁止当前处理器上的内核抢占，不需要获得任何形式的锁。读者任务进入RCU临界区后，不能进入睡眠状态。</p></li><li><p><code>rcu_read_unlock()</code></p><p>&emsp;&emsp;该操作函数由读者任务调用，表明读者完成了对临界资源的访问，离开了RCU临界区。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rcu_read_unlock()\</span></span><br><span class="line"><span class="keyword">do</span>(\</span><br><span class="line">rcu_read_release();\</span><br><span class="line">_release(RCU);\</span><br><span class="line">preempt_enable();\</span><br><span class="line">)<span class="keyword">while</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>该函数与<code>rcu_read_lock()</code>函数类似，主要调用<code>preempt_enable()</code>函数使能当前处理器的内核抢占。</p></li><li><p><code>rcu_dereference()</code></p><p>&emsp;&emsp;该函数由读者任务调用，用于获取指向RCU临界资源的指针，因此RCU机制限制所有的临界资源都应该以指针方式进行间接访问。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rcu_dereference(&#123;\</span></span><br><span class="line">typeof(p) __p1=ACCESS_ONCE(p);\</span><br><span class="line">smp_read_barrier_depends();\</span><br><span class="line">(__p1);\</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>该宏定义实现的功能看似多余，实则不然。这里通过为指针p创建一个新的复制件<code>__p1</code>，使读者任务在通过复制<code>__p1</code>访问RCU资源的同时，不妨碍写者对原有指针变量p的修改。</p></li><li><p><code>rcu_assign_pointer()</code></p><p>&emsp;&emsp;该操作函数由写者任务调用，在读者任务更新临界资源的移除阶段，用于重置RCU临界资源的指针，使之指向新版本的临界资源。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rcu_assign_pointer(p,v)(&#123;\</span></span><br><span class="line">smp_wmb();\</span><br><span class="line">(p)=(v);\</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></li><li><p><code>synchronize_rcu()</code></p><p>&emsp;&emsp;该函数由写者任务调用，在写者任务完成移除工作之后，调用该函数进入睡眠状态，等待所有的读者进程完成对旧版本临界资源的访问。在所有读者任务不再引用旧版本数据之后，内核负责将写者任务唤醒，接下来写者任务完成旧版本临界资源的访问。在所有读者任务不再引用旧版本数据之后，内核负责将写者任务唤醒，接下来写者任务完成旧版本临界资源的回收工作。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">synchronize_rcu</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">rcu_synchronize</span> <span class="title">rcu</span>;</span></span><br><span class="line">    init_completion(&amp;rcu.completion);</span><br><span class="line">    call_rcu(&amp;rcu.head,wakeme_after_rcu);</span><br><span class="line">    wait_for_completion(&amp;rcu.completion);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><code>call_rcu()</code></p><p>&emsp;&emsp;该函数由写者任务调用，在写者任务完成移除工作之后，调用该函数向系统注册一个资源“回收”处理函数，在所有读者任务不再引用旧版本数据之后，内核调用该处理函数完成旧版本临界资源的回收工作。与<code>synchronize_rcu()</code>函数相比，该函数不会阻塞，可用于中断上下文中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> fastcall <span class="title">call_rcu</span><span class="params">(struct rcu_head *head,<span class="keyword">void</span>(*func)(struct rcu_head *rcu))</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">rcu_data</span> *<span class="title">rdp</span>;</span></span><br><span class="line">    </span><br><span class="line">    head-&gt;func=func;</span><br><span class="line">    head-&gt;next=<span class="literal">NULL</span>;</span><br><span class="line">    local_irq_save(flags);</span><br><span class="line">    rdp=&amp;_get_cpu_var(rcu_data);</span><br><span class="line">    *rdp-&gt;nxtail=head;</span><br><span class="line">    rdp-&gt;nxttail=&amp;head-&gt;next;</span><br><span class="line">    <span class="keyword">if</span>(unlikely(++rdp-&gt;qlen&gt;qhimark))</span><br><span class="line">    &#123;</span><br><span class="line">        rdp-&gt;blimit=INT_MAX;</span><br><span class="line">        force_quiescent_state(rdp,&amp;rcu_ctrlblk);</span><br><span class="line">    &#125;</span><br><span class="line">    local_irq_restore(flags);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;emsp;&amp;emsp;读-复制-更新（Read-Copy-Update，RCU)机制是2.6内核中引入的另外一种新的同步机制。无论是自旋锁机制还是信号量机制都依赖于原子操作完成内核同步工作。但是，随着CPU性能的迅速提高，获得这些锁的开销相对于CPU的速度在成倍地增加，原
      
    
    </summary>
    
      <category term="Linux内核" scheme="http://wanqbin.xyz/categories/Linux%E5%86%85%E6%A0%B8/"/>
    
    
      <category term="操作系统" scheme="http://wanqbin.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Linux内核同步" scheme="http://wanqbin.xyz/tags/Linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"/>
    
      <category term="RCU同步机制" scheme="http://wanqbin.xyz/tags/RCU%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/"/>
    
      <category term="读-复制-更新" scheme="http://wanqbin.xyz/tags/%E8%AF%BB-%E5%A4%8D%E5%88%B6-%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>Linux内核同步机制分析——信号量机制</title>
    <link href="http://wanqbin.xyz/2019/08/11/Linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%E4%BF%A1%E5%8F%B7%E9%87%8F%E6%9C%BA%E5%88%B6/"/>
    <id>http://wanqbin.xyz/2019/08/11/Linux内核同步机制分析——信号量机制/</id>
    <published>2019-08-11T04:50:00.000Z</published>
    <updated>2019-08-11T04:50:54.793Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;自旋锁同步机制是一种“忙-等待”机制，在临界资源被锁定的时间很短的情况下非常有效。但是在临界资源被持有时间很长或不确定的情况下，忙-等待机制则会浪费宝贵的CPU时间。针对这种情况，Linux中提供了另外一种实现同步的机制——信号量。实际上在Linux提供了两种信号量，即内核信号量（供内核代码使用）和System V IPC信号量（供用户进程间通信使用）。下面我们讨论内核信号量。</p><p>&emsp;&emsp;信号量与自旋锁最大的不同点在于，当一个任务试图去获取一个已经被占用的信号量的时候，该任务不会像在自旋锁机制中那样，不断地进行“自旋”直到获得该锁，相反在信号量机制中，如果该任务发现它申请的信号量正在被占用，也就是它发现它现在不可以获取该信号量，那么该任务会被添加到一个等待队列中去睡眠，当持有信号量的进程释放信号量以后，处于等待队列中的那个任务将被唤醒，并获得该信号量。因此，也称Linux中的内核信号量是一种睡眠锁。这也就是说持有信号量的函数可能会睡眠，这就要求只有可以睡眠的函数才可以使用信号量，这也就意味着不可以在中断处理程序中使用信号量，因为它是不可以睡眠的。</p><p>&emsp;&emsp;信号量与自旋锁还有一点区别就是信号量允许被多个任务持有，而自旋锁在同一时刻只允许一个任务持有它。根据信号量是否可以被多个任务所持有，可以将信号量分为互斥信号量和计数信号量。互斥信号量表示，在任意时刻至多允许一个任务持有，通常用于多个任务互斥地访问某一临界资源时。而计数信号量允许在一个时刻至多有count个任务持有，count为信号到来时计数器的初始值，其取值在信号量初始化时确定。计数信号量用于对特定代码加以限制，内核中使用它的机会不多，内核中使用的信号量基本上都是互斥信号量。</p><h2 id="一、普通信号量"><a href="#一、普通信号量" class="headerlink" title="一、普通信号量"></a>一、普通信号量</h2><p>&emsp;&emsp;信号量同步机制由DijKstra提出，之后它逐渐成为了一种常用的锁机制。在长期且广泛的应用中，信号量机制又得到了很大的发展，出现了基于该思想的各种变体。现在信号量机制广泛应用于各种操作系统之中。除了初始化之外，信号量只能通过两个原子操作P()和V()访问。前者是测试操作，后者是增加操作。后来的系统把这两种操作分别叫做<code>down()</code>和<code>up()</code>，Linux也遵循这种叫法。</p><p>&emsp;&emsp;<code>down()</code>操作通过对信号量计数器减1来请求获得一个信号量。如果结果是0或大于0，获得信号量锁，任务就可以进入临界区；如果结果是负数，任务就会被放入等待队列中，处理器执行其他任务。相反，当临界区中的操作完成后，可以调用<code>up()</code>操作来释放信号量，它会增加信号量的计数器。如果在该信号量上的等待队列不为空，那么处于队列中等待的任务在被唤醒的同时会获得该信号量。</p><p>&emsp;&emsp;信号量机制的实现与体系结构有关，下面主要讨论在32位的x86体系结构下信号量的实现。普通信号量的数据结构使用<code>struct semaphore</code>来表示，该结构定义在<code>include/asm-x86/semaphore_32.h</code>中，结构如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">semaphore</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">atomic_t</span> count;</span><br><span class="line">    <span class="keyword">int</span> sleepers;</span><br><span class="line">    <span class="keyword">wait_queue_head_t</span> wait;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>count</code>：成员变量时信号量的计数器，该变量定义为<code>atomic_t</code>结构，从而保证了对该变量的操作为原子操作。当<code>count</code>大于0时，表示该信号量此时是空闲的，可以使用；当<code>count</code>等于0时，表示该信号量现在不可以用，但是并没有其他进程在等待这个信号量被释放；当<code>count</code>小于0时，表示该信号量现在不可以用，并且至少有一个任务也在等待该信号量被释放。</p><p>&emsp;&emsp;信号量与自旋锁的不同点的第二条就是它可以同时允许任意数量的锁持有者，而这正是通过设置该成员变量的值来实现的，当初始化一个信号量的时候，可以用<code>count</code>的值来指定有多少个任务可以同时持有该信号量。</p><p>&emsp;&emsp;<code>sleepers</code>：该成员变量用来存放一个标志，表示是否有任务在该信号量的等待队列上睡眠，当没有任务在该信号量的等待队列上睡眠的时候被设置为0，否则设置为1.</p><p>&emsp;&emsp;<code>wait</code>：该成员变量是一个链表头，用来将所有等待该信号量的睡眠进程组织成一个链表结构。</p><p>&emsp;&emsp;Linux内核为普通信号量同步机制提供了一系列的操作函数，操作函数原型及其描述如下：</p><table><thead><tr><th>函数原型</th><th>描述</th></tr></thead><tbody><tr><td>sema_init(struct semaphore *sem,int val)</td><td>初始化执行的信号量sem的计数器初始值为val，并初始化信号量的其他两个成员变量</td></tr><tr><td>init_MUTEX(struct semaphore *sem)</td><td>初始化指定的信号量sem为一个互斥信号量</td></tr><tr><td>int_MUTEX_LOCKED(struct semaphore *)</td><td>初始化指定的信号量sem为一个互斥信号量，同时将count的值赋为0，即该信号量初始状态为加锁状态</td></tr><tr><td>down(struct semaphore *sem)</td><td>试图去获取指定的信号量sem，如果发现该信号量当前不可以获取，则进入不可中断睡眠状态</td></tr><tr><td>down_interruptible(struct semaphore*)</td><td>试图获取指定的信号量sem，如果发现该信号量当前不可以获取，则进入可中断睡眠状态</td></tr><tr><td>down_trylock(struct semaphore * sem)</td><td>试图获取指定的信号量sem，如果发现该信号量当前不可以获取，则立即返回一个非0值</td></tr><tr><td>up(struct semaphore *sem)</td><td>释放指定的信号量sem，同时如果该信号量的等待队列不为空的话，就唤醒其中的一个等待进程</td></tr></tbody></table><p>&emsp;&emsp;信号量的获取和释放过程分别由函数<code>down()</code>和<code>up()</code>完成。</p><ol><li><h3 id="获取信号量的处理过程"><a href="#获取信号量的处理过程" class="headerlink" title="获取信号量的处理过程"></a>获取信号量的处理过程</h3><p>&emsp;&emsp;普通信号量的获取是由函数<code>down()</code>完成的，该函数定义在<code>include/asm-x86/semaphore_32.h</code>中，代码如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">down</span><span class="params">(struct sempahore *sem)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    might_sleep();</span><br><span class="line">    _asm__volatile_(</span><br><span class="line">    <span class="string">"# atomic down operation\n\t"</span></span><br><span class="line">    LOCK_PREFIX<span class="string">"decl %0\n\t"</span>/</span><br><span class="line">    <span class="string">"jns 2f/n"</span></span><br><span class="line">    <span class="string">"\tlea %0,%%eax\n\t"</span></span><br><span class="line">    <span class="string">"call_down_failed\n"</span></span><br><span class="line">    <span class="string">"2:"</span></span><br><span class="line">    :<span class="string">"+m"</span>(sem-&gt;count)</span><br><span class="line">    :</span><br><span class="line">    :<span class="string">"memory"</span>,<span class="string">"ax"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第3行代码中的<code>might_sleep()</code>函数检查是否需要重新调度。如果是，则调用<code>schedule()</code>函数进行重新调度。</p><p>将第5~10行内嵌汇编代码展开后，对应的汇编代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#atomic down operation</span><br><span class="line">LOCK_PREFIX decl %0</span><br><span class="line">jns 2f</span><br><span class="line">lea %0,%%eax</span><br><span class="line">call_down_failed</span><br><span class="line">2:</span><br></pre></td></tr></table></figure><p>第2~3行以原子的方式从信号量计数器count上减1，然后判断运算结果是否为负值。如果结果不为负，跳转到标号名称为2的位置，即第105行，从该函数中退出；当结构为负值时，表示该信号量不可用，则执行第4-5行代码。</p><p>第4~5行代码首先使用<code>lea</code>汇编指令将信号量<code>sem</code>的地址保存到寄存器<code>%eax</code>中（结构的第一个成员变量的地址就是该结构的地址），然后调用<code>_down_failed()</code>函数进行处理，当该函数返回时，任务也就获得了信号量的使用权。</p><p>原代码中第11~13行为内嵌汇编代码的输入、输出列表以及破坏性描述部分。</p><p><code>_down_failed()</code>函数在获取信号量失败时被调用，负责将任务插入到信号量<code>sem</code>的等待队列中，然后调用调度器，释放处理器的使用权。该函数定义在<code>arch/x86/lib/semaphore_32.S</code>中，代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">ENTRY(_down_failed)</span><br><span class="line">    CFI_STARTPROC</span><br><span class="line">    FRAME</span><br><span class="line">    push %edx</span><br><span class="line">    CFI_ADJUST_CFA_OFFSET 4</span><br><span class="line">    CFI_REL_OFFSET edx,0</span><br><span class="line">    pushl %ecx</span><br><span class="line">    CFI_ADJUST_CFA_OFFSET 4</span><br><span class="line">    CFI_REL_OFFSET ecx,0</span><br><span class="line">    call _down</span><br><span class="line">    popl %ecx</span><br><span class="line">    CFI_ADJUST_CFA_OFFSET -4</span><br><span class="line">    CFI_RESTORE ecx</span><br><span class="line">    popl %edx</span><br><span class="line">    CFI_ADJUST_CFA_OFFSET -4</span><br><span class="line">    CFI_RESTORE ecx</span><br><span class="line">    popl %edx</span><br><span class="line">    CFI_ADJUST_CFA_OFFSET -4</span><br><span class="line">    CFI_RESTORE edx</span><br><span class="line">    ENDFRAME</span><br><span class="line">    ret</span><br><span class="line">    CFI_ENDPROC</span><br><span class="line">END(_down_failed)</span><br></pre></td></tr></table></figure><p>在第2、3、5、6、8、9、12、13、15、16、18~20、22行代码用于记录Linux系统内核的调试信息。</p><p>第4、7、11、14、17行代码保存寄存器<code>%edx</code>,<code>%ecx</code>的值，然后调用<code>_down()</code>函数完成在获取信号量失败时的具体1处理过程，最后恢复寄存器<code>%edx</code>,<code>%ecx</code>的值。</p><p>从对<code>_down_failed()</code>函数的汇编代码分析可知，<code>_down_failed()</code>函数实际上是<code>_down()</code>函数的封装，获取信号量失败时，由<code>_down()</code>函数完成具体的处理过程，<code>_down()</code>函数定义在<code>lib/semaphore-sleepers.c</code>中，代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">fastcall <span class="keyword">void</span> _sched_down(struct semaphore *sem)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">tsk</span>=<span class="title">currrent</span>;</span></span><br><span class="line">    DECLARE_WAITQUEUE(wait,tsk);</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line">    </span><br><span class="line">    tsk-&gt;state=TASK_UNINTERRUPTIBLE;</span><br><span class="line">    spin_lock_irqsave(&amp;sem-&gt;wait.lock,flags);</span><br><span class="line">    add_wait_queue_exclusive_locked(&amp;sem-&gt;wait,&amp;wait);</span><br><span class="line">    </span><br><span class="line">    sem-&gt;sleepers++;</span><br><span class="line">    <span class="keyword">for</span>(;;)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> sleepers=sem-&gt;sleepers;</span><br><span class="line">        <span class="keyword">if</span>(!atomic_add_negative(sleepers<span class="number">-1</span>,&amp;sem-&gt;count))</span><br><span class="line">        &#123;</span><br><span class="line">            sem-&gt;sleepers=<span class="number">0</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        sem-&gt;sleepers=<span class="number">1</span>;</span><br><span class="line">        spin_unlock_irqrestore(&amp;sem-&gt;wait.lock,flags);</span><br><span class="line">        schedule();</span><br><span class="line">        spin_lock_irqsave(&amp;sem-&gt;wait.lock,flags);</span><br><span class="line">        tsk-&gt;state=TASK_UNINTERRUPTIBLE;</span><br><span class="line">    &#125;</span><br><span class="line">    remove_wait_queue_locked(&amp;sem-&gt;wait,&amp;wait);</span><br><span class="line">    wake_up_locked(&amp;sem-&gt;wait);</span><br><span class="line">    spin_unlock_irqstore(&amp;sem-&gt;wait.lock,flags);</span><br><span class="line">    tsk-&gt;state=TASK_RUNNING;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第3~5行代码声明了该函数中将要使用的局部变量。其中，指针变量<code>tsk</code>被初始化为当前任务的进程描述符；而第4行使用宏定义<code>DECLARE_WAITQUEUE()</code>声明了一个名称为<code>wait</code>的等待队列节点。</p><p>第7~9行代码用于将上述几行代码构建的等待队列节点<code>wait</code>插入到信号量<code>sem</code>对应的等待队列队尾。其中，第7行代码设置当前任务的状态为不可中断睡眠状态(<code>TASK_UNINTERRUPTIBLE</code>);第8行代码调用<code>spin_lock_irqqseve()</code>函数获得等待队列所包含的自旋锁，禁止中断响应并将处理器标志寄存器<code>EFLAGS</code>的值保存到<code>flags</code>中，其逆操作在第23行和第28行；第9行代码将等待队列节点<code>wait</code>插入到信号量<code>sem</code>对应的等待队列队尾。</p><p>在第12~25行构成一个for循环，在任务无法获得信号量的情况下，将会一直睡眠在相应的等待队列上。该任务在阻塞过程中可能被唤醒，当该任务被唤醒后，通过第15行代码判断是否成功获得信号量的使用权。在成功获得信号量时，执行break语句跳出for循环，并执行第26-29行代码；否则，再次调用调度<code>schedule()</code>函数，释放处理器的使用权，并将任务的当前执行状态设置为不可中断睡眠状态。</p><p>第26~29行代码在任务被唤醒且获得信号量之后执行。其中，第26行将等待队列节点<code>wait</code>从等待队列中移出，第28行释放对等待队列锁包含的自旋锁，恢复处理器的标志寄存器<code>EFLAGS</code>，第29行代码设置当前任务为运行状态。</p></li><li><h3 id="释放信号量的处理过程"><a href="#释放信号量的处理过程" class="headerlink" title="释放信号量的处理过程"></a>释放信号量的处理过程</h3><p>&emsp;&emsp;普通信号量的释放由<code>up()</code>函数完成，该函数负责将信号量计数器<code>count</code>的值加1，表示信号量被释放，在有任务阻塞在该信号量的情况下，唤醒等待队列中睡眠的任务.<code>up()</code>函数定义在<code>include/asm-x86/semaphore_32.h</code>中，代码如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">up</span><span class="params">(struct semaphore *sem)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    _asm__volatile_(</span><br><span class="line">    <span class="string">"#atomic up operation\n\t"</span></span><br><span class="line">    LOCK_PREFIX<span class="string">"incl %0\n\t"</span></span><br><span class="line">    <span class="string">"jg 1f\n\t"</span></span><br><span class="line">    <span class="string">"lea %0,%%eax\n\t"</span></span><br><span class="line">    <span class="string">"call _up_wakeup\n"</span></span><br><span class="line">    <span class="string">"1:"</span></span><br><span class="line">    :<span class="string">"+m"</span>(sem-&gt;count)</span><br><span class="line">    :</span><br><span class="line">    :<span class="string">"memory"</span>,<span class="string">"ax"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;第5~6行代码执行<code>down()</code>函数的逆操作，两者的语句内容和格式也非常类似。第5行代码负责以原子方式将信号量计数器<code>count</code>的值加1.第6行代码判断是否有任务阻塞在该信号量上，如果没有，则跳转到标号名称为1的位置，从函数中退出；否则，执行第7-8行代码。</p><p>&emsp;&emsp;第7~8行的代码首先将信号量的地址保存到寄存器<code>%eax</code>中，该参数在函数调用的过程中，作为参数被传递给<code>_up_wakeup()</code>函数，由<code>_up_wakeup()</code>函数负责进一步的处理。</p><p>&emsp;&emsp;<code>_up_wakeup()</code>函数与<code>_down_failed()</code>函数相似，<code>_up_wakeup()</code>函数定义在<code>arch/x86/lib/semaphore_32.S</code>中，该函数实际上是<code>_up()</code>函数的封装，<code>_up()</code>函数定义在<code>lib/semaphore-sleepers.c</code>中，它直接调用<code>wake_up()</code>函数完成等待队列上任务的唤醒工作。</p><p>&emsp;&emsp;通过对普通信号量的获取和释放函数的分析可知，普通信号量基于原子变量和等待队列这两个变量来完成同步工作，其中的原子变量用于计数器，记录信号量的当前状态；而等待队列用于组织阻塞在该信号量上的睡眠任务。</p></li></ol><h2 id="二、读写信号量"><a href="#二、读写信号量" class="headerlink" title="二、读写信号量"></a>二、读写信号量</h2><p>&emsp;&emsp;读写信号量是在Linux2.4内核中引入的一种机制，它与自旋锁类似，将信号量也区分为读和写两种类型。读写信号量的引入提高了内核的并发度，对整个系统的性能提高有一定的帮助。</p><p>&emsp;&emsp;读写信号量在内核中是由结构体<code>rw_semophore</code>来表示的，该结构体定义在文件<code>include/asm-x86/rwsem.h</code>中，形式如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rw_semphore</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">signed</span> <span class="keyword">long</span> count;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RWSEM_UNLOCKED_VALUE 0X00000000</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RWSEM_ACTIVE_BIAS 0X00000001</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RWSEM_ACTIVE_MASK 0x0000ffff</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RWSEM_WAITINT_BIAS (-0x00010000)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RWSEM_ACTIVE_READ_BAS RWSEM_ACTIVE_BIAS</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RWSEM_ACTIVE_WRITE_BIAS (RWSEM_WAITING_BIAS+RWSEM_ACTIVE_BIAS)</span></span><br><span class="line">    <span class="keyword">spinlock_t</span> wait_lock;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">wait_list</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_DEBUG_LOCK_ALLLOC</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">lockdep_map</span> <span class="title">dep_map</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>count</code>：该成员变量用于存放两个16位的计数器</p><p><code>wait_lock</code>:该成员变量是一个自旋锁，用于保护等待队列和<code>rw_semaphore</code>结构体本身。</p><p><code>wait_list</code>:该成员变量指向等待队列的链表，该链表中的每一个元素都是一个<code>rwsem_waiter</code>结构体，该结构体中包含三个成员变量，一个是指向睡眠进程的描述符的指针，另外一个是用来标识该进程是为读需要的信号量还是为写需要信号量的标志。最后一个就是用来将这些结构体连接成为一个链表结构的链表结构体。</p><p>内核同样提供了一些与读写信号量相对应的操作函数，这些操作函数的原型和描述如下：</p><table><thead><tr><th>函数原型</th><th>描述</th></tr></thead><tbody><tr><td>init_rwsem(sem)</td><td>初始化指定的读写信号量sem</td></tr><tr><td>down_read(struct rw_semaphore *sem)</td><td>用于获取指定的读锁sem，如果成功获得，直接返回，否则读者进入睡眠状态</td></tr><tr><td>up_read(struct rw_semaphore *sem)</td><td>释放持有的读锁sem</td></tr><tr><td>down_read_trylock(struct rw_semaphore *sem)</td><td>试图获得锁定的读锁sem，如果不成功，立即返回，返回值为0，否则锁定成功，返回值为1</td></tr><tr><td>down_write(struct rw_semaphore *sem)</td><td>用于获得指定的写锁sem，如果锁定成功，直接返回，否则，写者进入睡眠状态</td></tr><tr><td>up_write(struct rw_semaphore *sem)</td><td>释放指定的写锁sem</td></tr><tr><td>dwon_write_trylock(struct rw_semaphore *sem)</td><td>试图获得指定的写锁sem，如果不成功，立即返回，返回值为0，否则锁定成功，返回值为1</td></tr></tbody></table><p>&emsp;&emsp;关于读写信号量最后还需要注意的是，内核是按照先进先出(FIFO)的顺序来处理等待读写信号量的任务，Linux中是这样规定的，如果一个任务去试图获取一个信号量时，它发现该信号量现在是不可获取的，于是该任务就被添加到信号量等待队列的末尾，当信号量被释放的时候，内核会首先检查等待队列中的第一个任务，并且唤醒任务，此时，如果被唤醒的任务是一个写者任务，那么该任务获得写信号量，同时其他任务继续在等待队列中睡眠；而如果被唤醒的任务是一个读者任务，那么紧跟在该任务之后的所有读者任务都会被唤醒并获得读锁，不过该操作时不可以跳跃进行的，也就是说在写者任务之后排队的任务即使是读者任务，也不会被唤醒并拥有锁。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;emsp;&amp;emsp;自旋锁同步机制是一种“忙-等待”机制，在临界资源被锁定的时间很短的情况下非常有效。但是在临界资源被持有时间很长或不确定的情况下，忙-等待机制则会浪费宝贵的CPU时间。针对这种情况，Linux中提供了另外一种实现同步的机制——信号量。实际上在Linux
      
    
    </summary>
    
      <category term="Linux内核" scheme="http://wanqbin.xyz/categories/Linux%E5%86%85%E6%A0%B8/"/>
    
    
      <category term="操作系统" scheme="http://wanqbin.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Linux内核同步" scheme="http://wanqbin.xyz/tags/Linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"/>
    
      <category term="信号量" scheme="http://wanqbin.xyz/tags/%E4%BF%A1%E5%8F%B7%E9%87%8F/"/>
    
      <category term="普通信号量" scheme="http://wanqbin.xyz/tags/%E6%99%AE%E9%80%9A%E4%BF%A1%E5%8F%B7%E9%87%8F/"/>
    
      <category term="读写信号量" scheme="http://wanqbin.xyz/tags/%E8%AF%BB%E5%86%99%E4%BF%A1%E5%8F%B7%E9%87%8F/"/>
    
  </entry>
  
</feed>
